import streamlit as st
import pandas as pd
import os
import smtplib
import time
import io
import traceback
import threading
import uuid
import re
import sqlite3
import json
import random
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, date, timedelta
from datetime import timezone
import pytz
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
from streamlit.runtime.scriptrunner import add_script_run_ctx, get_script_run_ctx
from PIL import Image, ImageOps

# --- 1. ç¶²é è¨­å®š ---
st.set_page_config(page_title="ä¸­å£¢å®¶å•†ï¼Œè¡›æ„›è€Œç”Ÿ V4.8", layout="wide", page_icon="ğŸ§¹")

# --- 2. æ ¸å¿ƒåƒæ•¸èˆ‡å…¨åŸŸè¨­å®š ---
try:
    TW_TZ = pytz.timezone('Asia/Taipei')
    MAX_IMAGE_BYTES = 10 * 1024 * 1024
    QUEUE_DB_PATH = "task_queue_v4_wal.db"
    IMG_DIR = "evidence_photos"
    os.makedirs(IMG_DIR, exist_ok=True)
    
    SHEET_URL = "https://docs.google.com/spreadsheets/d/11BXtN3aevJls6Q2IR_IbT80-9XvhBkjbTCgANmsxqkg/edit"
    SHEET_TABS = {
        "main": "main_data", "settings": "settings", "roster": "roster",
        "inspectors": "inspectors", "duty": "duty",
        "appeals": "appeals", "holidays": "holidays", "service_hours": "service_hours",
        "office_areas": "office_areas"
    }

    EXPECTED_COLUMNS = [
        "æ—¥æœŸ", "é€±æ¬¡", "ç­ç´š", "è©•åˆ†é …ç›®", "æª¢æŸ¥äººå“¡",
        "å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸",
        "å‚™è¨»", "é•è¦ç´°é …", "ç…§ç‰‡è·¯å¾‘", "ç™»éŒ„æ™‚é–“", "ä¿®æ­£", "æ™¨æƒæœªåˆ°è€…", "ç´€éŒ„ID"
    ]
    APPEAL_COLUMNS = ["ç”³è¨´æ—¥æœŸ", "ç­ç´š", "é•è¦æ—¥æœŸ", "é•è¦é …ç›®", "åŸå§‹æ‰£åˆ†", "ç”³è¨´ç†ç”±", "ä½è­‰ç…§ç‰‡", "è™•ç†ç‹€æ…‹", "ç™»éŒ„æ™‚é–“", "å°æ‡‰ç´€éŒ„ID", "å¯©æ ¸å›è¦†"]

    # ==========================================
    # SRE Utils: é‡è©¦æ©Ÿåˆ¶
    # ==========================================
    def execute_with_retry(func, max_retries=5, base_delay=1.0):
        for attempt in range(max_retries):
            try:
                time.sleep(0.3 + random.uniform(0, 0.2)) 
                return func()
            except Exception as e:
                error_str = str(e).lower()
                is_retryable = any(x in error_str for x in ['429', '500', '503', 'quota', 'rate limit', 'timed out', 'connection'])
                if is_retryable and attempt < max_retries - 1:
                    sleep_time = (base_delay * (2 ** attempt)) + random.uniform(0, 1)
                    time.sleep(sleep_time)
                else: raise e

    # ==========================================
    # Google é€£ç·šèˆ‡åœ–ç‰‡å£“ç¸®
    # ==========================================
    @st.cache_resource
    def get_credentials():
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        if "gcp_service_account" not in st.secrets:
            st.error("âŒ æ‰¾ä¸åˆ° secrets è¨­å®š")
            return None
        return ServiceAccountCredentials.from_json_keyfile_dict(dict(st.secrets["gcp_service_account"]), scope)

    def get_gspread_client():
        creds = get_credentials()
        return gspread.authorize(creds) if creds else None

    def get_drive_service():
        creds = get_credentials()
        return build('drive', 'v3', credentials=creds, cache_discovery=False) if creds else None

    def get_worksheet(tab_name):
        client = get_gspread_client()
        if not client: return None
        for attempt in range(4):
            try:
                sheet = client.open_by_url(SHEET_URL)
                try: 
                    return sheet.worksheet(tab_name)
                except gspread.WorksheetNotFound:
                    cols = 20 if tab_name != "appeals" else 15
                    ws = sheet.add_worksheet(title=tab_name, rows=500, cols=cols)
                    if tab_name == "appeals": ws.append_row(APPEAL_COLUMNS)
                    if tab_name == "service_hours": ws.append_row(["æ—¥æœŸ", "å­¸è™Ÿ", "ç­ç´š", "é¡åˆ¥", "æ™‚æ•¸", "ç´€éŒ„ID"])
                    if tab_name == "holidays": ws.append_row(["æ—¥æœŸ", "èªªæ˜"])
                    if tab_name == "office_areas": ws.append_row(["å€åŸŸåç¨±", "è² è²¬ç­ç´š"])
                    return ws
            except Exception as e:
                if "429" in str(e): 
                    time.sleep(2 * (attempt + 1) + random.uniform(0, 1))
                    continue
                else: return None
        return None

    def compress_image_bytes(file_bytes, quality=70):
        try:
            img = Image.open(io.BytesIO(file_bytes))
            img = ImageOps.exif_transpose(img)
            if img.mode != "RGB": img = img.convert("RGB")
            if img.width > 1600:
                ratio = 1600 / float(img.width)
                img = img.resize((1600, int(img.height * ratio)), Image.Resampling.LANCZOS)
            out_buffer = io.BytesIO()
            img.save(out_buffer, format="JPEG", quality=quality, optimize=True)
            out_buffer.seek(0)
            return out_buffer
        except: return io.BytesIO(file_bytes)

    def upload_image_to_drive(file_obj, filename):
        def _upload_action():
            service = get_drive_service()
            folder_id = st.secrets["system_config"]["drive_folder_id"]
            file = service.files().create(
                body={'name': filename, 'parents': [folder_id]},
                media_body=MediaIoBaseUpload(file_obj, mimetype='image/jpeg', resumable=True),
                fields='id', supportsAllDrives=True
            ).execute()
            try: service.permissions().create(fileId=file.get('id'), body={'role': 'reader', 'type': 'anyone'}).execute()
            except: pass 
            return f"https://drive.google.com/thumbnail?id={file.get('id')}&sz=w1000"
        return execute_with_retry(_upload_action)

    def clean_id(val):
        try: return str(int(float(val))).strip()
        except: return str(val).strip()

    # ==========================================
    # SQLite èƒŒæ™¯ä½‡åˆ—
    # ==========================================
    _queue_lock = threading.Lock()

    @st.cache_resource
    def get_queue_connection():
        conn = sqlite3.connect(QUEUE_DB_PATH, check_same_thread=False, timeout=30.0, isolation_level="IMMEDIATE")
        try: conn.execute("PRAGMA journal_mode=WAL;"); conn.execute("PRAGMA busy_timeout=30000;")
        except: pass
        conn.execute("CREATE TABLE IF NOT EXISTS task_queue (id TEXT PRIMARY KEY, task_type TEXT, created_ts TEXT, payload_json TEXT, status TEXT, attempts INTEGER, last_error TEXT)")
        conn.commit()
        return conn

    def enqueue_task(task_type, payload):
        conn = get_queue_connection()
        task_id = str(uuid.uuid4())
        with _queue_lock:
            conn.execute("INSERT INTO task_queue VALUES (?, ?, ?, ?, 'PENDING', 0, NULL)",
                (task_id, task_type, datetime.now(timezone.utc).isoformat(), json.dumps(payload, ensure_ascii=False)))
            conn.commit()
        return task_id

    def get_queue_metrics():
        conn = get_queue_connection()
        metrics = {"pending": 0, "retry": 0, "failed": 0, "oldest_pending_sec": 0, "recent_errors": []}
        with _queue_lock:
            cur = conn.cursor()
            cur.execute("SELECT status, COUNT(*) FROM task_queue GROUP BY status")
            for s, c in cur.fetchall():
                if s == 'PENDING': metrics["pending"] = c
                elif s == 'RETRY': metrics["retry"] = c
                elif s == 'FAILED': metrics["failed"] = c
            
            cur.execute("SELECT MIN(created_ts) FROM task_queue WHERE status IN ('PENDING', 'RETRY')")
            oldest = cur.fetchone()[0]
            if oldest:
                try: metrics["oldest_pending_sec"] = (datetime.now(pytz.utc) - datetime.fromisoformat(oldest.replace("Z", "+00:00"))).total_seconds()
                except: pass
            cur.execute("SELECT last_error, created_ts FROM task_queue WHERE status='FAILED' OR status='RETRY' ORDER BY created_ts DESC LIMIT 5")
            metrics["recent_errors"] = cur.fetchall()
        return metrics

    def fetch_next_task(max_attempts=6):
        conn = get_queue_connection()
        with _queue_lock:
            cur = conn.cursor()
            cur.execute("SELECT id, task_type, created_ts, payload_json, status, attempts, last_error FROM task_queue WHERE status IN ('PENDING', 'RETRY') AND attempts < ? ORDER BY created_ts ASC LIMIT 1", (max_attempts,))
            row = cur.fetchone()
            if not row: return None
            cur.execute("UPDATE task_queue SET status = 'IN_PROGRESS', attempts = attempts + 1 WHERE id = ?", (row[0],))
            conn.commit()
            return {"id": row[0], "task_type": row[1], "payload": json.loads(row[3]) if row[3] else {}, "attempts": row[5] + 1}

    def update_task_status(task_id, status, attempts, last_error):
        with _queue_lock:
            get_queue_connection().execute("UPDATE task_queue SET status = ?, attempts = ?, last_error = ? WHERE id = ?", (status, attempts, last_error, task_id))
            get_queue_connection().commit()

    # ==========================================
    # èƒŒæ™¯è™•ç†é‚è¼¯
    # ==========================================
    def _append_main_entry_row(entry):
        def _action():
            ws = get_worksheet(SHEET_TABS["main"])
            if not ws: return
            all_vals = ws.get_all_values()
            if not all_vals: ws.append_row(EXPECTED_COLUMNS)
            row = []
            for col in EXPECTED_COLUMNS:
                val = entry.get(col, "")
                if isinstance(val, bool): val = str(val).upper()
                if col == "æ—¥æœŸ": val = str(val)
                row.append(val)
            ws.append_row(row)
        execute_with_retry(_action)
    
    def _append_service_row_unique(entry):
        def _action():
            ws = get_worksheet(SHEET_TABS["service_hours"])
            if not ws: return
            all_vals = ws.get_all_values()
            
            t_date = str(entry.get("æ—¥æœŸ", ""))
            t_sid = str(entry.get("å­¸è™Ÿ", ""))
            t_cat = str(entry.get("é¡åˆ¥", ""))
            
            for row in reversed(all_vals):
                if len(row) >= 4:
                    if row[0] == t_date and row[1] == t_sid and row[3] == t_cat:
                        return 
                        
            new_row = [
                t_date, t_sid, str(entry.get("ç­ç´š", "")),
                t_cat, str(entry.get("æ™‚æ•¸", "")), str(entry.get("ç´€éŒ„ID", ""))
            ]
            ws.append_row(new_row)
        execute_with_retry(_action)

    def process_task(task):
        task_type, payload = task["task_type"], task["payload"]
        
        if task_type == "service_hours_only":
            try:
                for sid in payload.get("student_list", []):
                    log_entry = {
                        "æ—¥æœŸ": payload.get("date", str(date.today())), "å­¸è™Ÿ": sid,
                        "ç­ç´š": payload.get("class_name", ""), "é¡åˆ¥": payload.get("category", ""), 
                        "æ™‚æ•¸": payload.get("hours", 0.5), "ç´€éŒ„ID": uuid.uuid4().hex[:8]
                    }
                    _append_service_row_unique(log_entry) 
                return True, None
            except Exception as e:
                return False, str(e)

        entry = payload.get("entry", {})
        try:
            image_paths, filenames, drive_links = payload.get("image_paths", []), payload.get("filenames", []), []
            for path, fname in zip(image_paths, filenames):
                if os.path.exists(path):
                    with open(path, "rb") as f:
                        drive_links.append(upload_image_to_drive(compress_image_bytes(f.read()), fname) or "UPLOAD_FAILED_API")
            if drive_links: entry["ç…§ç‰‡è·¯å¾‘"] = ";".join(drive_links)

            if task_type in ["main_entry", "volunteer_report"]:
                _append_main_entry_row(entry)

                inspector_name = entry.get("æª¢æŸ¥äººå“¡", "")
                if "å­¸è™Ÿ:" in inspector_name:
                    sid = inspector_name.split("å­¸è™Ÿ:")[1].strip()
                    log_entry = {
                        "æ—¥æœŸ": entry.get("æ—¥æœŸ"), "å­¸è™Ÿ": sid,
                        "ç­ç´š": "", "é¡åˆ¥": "æ•´æ½”è©•åˆ†ç³¾å¯Ÿ", "æ™‚æ•¸": 0.25, "ç´€éŒ„ID": uuid.uuid4().hex[:8]
                    }
                    _append_service_row_unique(log_entry) 
                
                if task_type == "volunteer_report":
                    for sid in payload.get("student_list", []):
                        v_entry = {
                            "æ—¥æœŸ": entry.get("æ—¥æœŸ", str(date.today())), "å­¸è™Ÿ": sid, 
                            "ç­ç´š": entry.get("ç­ç´š", ""), "é¡åˆ¥": payload.get("custom_category", "æ™¨æƒå¿—å·¥"), 
                            "æ™‚æ•¸": payload.get("custom_hours", 0.5), "ç´€éŒ„ID": uuid.uuid4().hex[:8]
                        }
                        _append_service_row_unique(v_entry)

            elif task_type == "appeal_entry":
                image_info = payload.get("image_file")
                if image_info and os.path.exists(image_info["path"]):
                    with open(image_info["path"], "rb") as f:
                        entry["ä½è­‰ç…§ç‰‡"] = upload_image_to_drive(compress_image_bytes(f.read()), image_info["filename"])
                execute_with_retry(lambda: get_worksheet(SHEET_TABS["appeals"]).append_row([str(entry.get(c, "")) for c in APPEAL_COLUMNS]))
            return True, None
        except Exception as e: return False, str(e)

    def background_worker(stop_event=None):
        try: add_script_run_ctx(threading.current_thread(), get_script_run_ctx())
        except: pass
        while True:
            if stop_event and stop_event.is_set(): break
            try:
                task = fetch_next_task()
                if not task: time.sleep(2.0); continue
                ok, err = process_task(task)
                
                try:
                    paths = task["payload"].get("image_paths", []) + ([task["payload"]["image_file"]["path"]] if "image_file" in task["payload"] else [])
                    for p in paths:
                        if p and os.path.exists(p): os.remove(p)
                except: pass

                update_task_status(task["id"], "DONE" if ok else ("FAILED" if task["attempts"] >= 6 else "RETRY"), task["attempts"], err)
                time.sleep(0.5)
            except Exception as e: time.sleep(3.0)

    @st.cache_resource
    def ensure_worker_started():
        stop_event = threading.Event()
        t = threading.Thread(target=background_worker, args=(stop_event,), daemon=True)
        add_script_run_ctx(t)
        t.start()
        return stop_event
    _ = ensure_worker_started()

    # ==========================================
    # å‰ç«¯è³‡æ–™è®€å– 
    # ==========================================
    @st.cache_data(ttl=21600)
    def load_holidays():
        ws = get_worksheet(SHEET_TABS["holidays"])
        if not ws: return []
        try: return [pd.to_datetime(str(r.get("æ—¥æœŸ", "")).strip()).date() for r in ws.get_all_records() if str(r.get("æ—¥æœŸ", "")).strip()]
        except: return []

    def is_within_appeal_period(violation_date, appeal_days=3):
        vd = pd.to_datetime(violation_date).date() if isinstance(violation_date, str) else violation_date
        holidays, today, current_date, workdays = load_holidays(), date.today(), vd, 0
        for _ in range(14): 
            if workdays >= appeal_days: break
            current_date += timedelta(days=1)
            if current_date.weekday() < 5 and current_date not in holidays: workdays += 1
        return today <= current_date

    @st.cache_data(ttl=300)
    def load_main_data():
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return pd.DataFrame(columns=EXPECTED_COLUMNS)
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return pd.DataFrame(columns=EXPECTED_COLUMNS)
            if "ç­ç´š" in df.columns: df["ç­ç´š"] = df["ç­ç´š"].astype(str).str.strip()
            for col in EXPECTED_COLUMNS:
                if col not in df.columns: df[col] = ""
            if "ç´€éŒ„ID" not in df.columns: df["ç´€éŒ„ID"] = df.index.astype(str)
            for col in ["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸", "é€±æ¬¡"]:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
            if "ä¿®æ­£" in df.columns: df["ä¿®æ­£"] = df["ä¿®æ­£"].astype(str).apply(lambda x: True if x.upper() == "TRUE" else False)
            return df[EXPECTED_COLUMNS]
        except: return pd.DataFrame(columns=EXPECTED_COLUMNS)

    @st.cache_data(ttl=21600)
    def load_roster_dict():
        ws = get_worksheet(SHEET_TABS["roster"])
        if not ws: return {}
        try:
            df = pd.DataFrame(ws.get_all_records())
            id_c, cls_c = next((c for c in df.columns if "å­¸è™Ÿ" in c), None), next((c for c in df.columns if "ç­ç´š" in c), None)
            return {clean_id(row[id_c]): str(row[cls_c]).strip() for _, row in df.iterrows()} if id_c and cls_c else {}
        except: return {}
    
    @st.cache_data(ttl=3600)
    def load_sorted_classes():
        ws = get_worksheet(SHEET_TABS["roster"])
        if not ws: return [], []
        try:
            records = ws.get_all_records()
            if not records:
                all_vals = ws.get_all_values()
                if len(all_vals) > 1: records = [dict(zip(all_vals[0], row)) for row in all_vals[1:]]
            df = pd.DataFrame(records)
            class_col = next((c for c in df.columns if "ç­ç´š" in str(c).strip()), None)
            if not class_col: return [], []
            unique = [c for c in df[class_col].astype(str).str.strip().unique().tolist() if c]
            dept_order = {"å•†": 1, "è‹±": 2, "è³‡": 3, "å®¶": 4, "æœ": 5}
            def get_sort_key(n):
                g = 1 if "ä¸€" in n or "1" in n else (2 if "äºŒ" in n or "2" in n else (3 if "ä¸‰" in n or "3" in n else 99))
                return (g, next((v for k, v in dept_order.items() if k in n), 99), n)
            sorted_all = sorted(unique, key=get_sort_key)
            return sorted_all, [{"grade": f"{get_sort_key(c)[0]}å¹´ç´š" if get_sort_key(c)[0]!=99 else "å…¶ä»–", "name": c} for c in sorted_all]
        except: return [], []

    @st.cache_data(ttl=60)
    def get_daily_duty(target_date):
        ws = get_worksheet(SHEET_TABS["duty"])
        if not ws: return pd.DataFrame(), "error"
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return pd.DataFrame(), "no_data"
            date_col = next((c for c in df.columns if "æ—¥æœŸ" in c), None)
            if date_col:
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.date
                return df[df[date_col] == (target_date if isinstance(target_date, date) else target_date.date())], "success"
            return pd.DataFrame(), "missing_cols"
        except: return pd.DataFrame(), "error"

    @st.cache_data(ttl=3600)
    def load_office_area_map():
        ws = get_worksheet(SHEET_TABS["office_areas"])
        if not ws: return {}
        try: return {str(r.get("å€åŸŸåç¨±", "")).strip(): str(r.get("è² è²¬ç­ç´š", "")).strip() for r in ws.get_all_records() if str(r.get("å€åŸŸåç¨±", "")).strip()}
        except: return {}

    @st.cache_data(ttl=21600)
    def load_settings():
        ws = get_worksheet(SHEET_TABS["settings"])
        config = {"semester_start": "2025-08-25", "standard_n": 4}
        if ws:
            try:
                for row in ws.get_all_values():
                    if len(row)>=2: config[row[0]] = int(row[1]) if row[0] == "standard_n" else row[1]
            except: pass
        return config

    def save_setting(key, val):
        ws = get_worksheet(SHEET_TABS["settings"])
        if ws:
            try:
                cell = ws.find(key)
                if cell: ws.update_cell(cell.row, cell.col+1, val)
                else: ws.append_row([key, val])
                st.cache_data.clear(); return True
            except: return False
        return False

    @st.cache_data(ttl=60)
    def load_appeals():
        ws = get_worksheet(SHEET_TABS["appeals"])
        if not ws: return pd.DataFrame(columns=APPEAL_COLUMNS)
        try:
            df = pd.DataFrame(ws.get_all_records())
            for col in APPEAL_COLUMNS:
                if col not in df.columns: df[col] = "å¾…è™•ç†" if col == "è™•ç†ç‹€æ…‹" else ""
            return df[APPEAL_COLUMNS]
        except: return pd.DataFrame(columns=APPEAL_COLUMNS)

    def save_appeal(entry, proof_file=None):
        image_info = None
        if proof_file:
            try:
                data = proof_file.read()
                if len(data) > MAX_IMAGE_BYTES: st.error("ç…§ç‰‡éå¤§"); return False
                fname = f"Appeal_{entry.get('ç­ç´š', '')}_{datetime.now(TW_TZ).strftime('%H%M%S')}.jpg"
                l_path = os.path.join(IMG_DIR, f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}_{fname}")
                with open(l_path, "wb") as f: f.write(data)
                image_info = {"path": l_path, "filename": fname}
            except Exception as e: st.error(f"å¯«å…¥å¤±æ•—: {e}"); return False

        entry.update({"ç”³è¨´æ—¥æœŸ": entry.get("ç”³è¨´æ—¥æœŸ", datetime.now(TW_TZ).strftime("%Y-%m-%d")), "è™•ç†ç‹€æ…‹": entry.get("è™•ç†ç‹€æ…‹", "å¾…è™•ç†"),
                      "ç™»éŒ„æ™‚é–“": entry.get("ç™»éŒ„æ™‚é–“", datetime.now(TW_TZ).strftime("%Y-%m-%d %H:%M:%S")), 
                      "ç”³è¨´ID": entry.get("ç”³è¨´ID", datetime.now(TW_TZ).strftime("%Y%m%d%H%M%S") + "_" + uuid.uuid4().hex[:4]),
                      "ä½è­‰ç…§ç‰‡": entry.get("ä½è­‰ç…§ç‰‡", "")})
        enqueue_task("appeal_entry", {"entry": entry, "image_file": image_info})
        st.success("ğŸ“© ç”³è¨´å·²æ’å…¥èƒŒæ™¯è™•ç†")
        return True
    
    def update_appeal_status(idx, status, record_id, reply_text=""):
        ws_appeals, ws_main = get_worksheet(SHEET_TABS["appeals"]), get_worksheet(SHEET_TABS["main"])
        try:
            data = ws_appeals.get_all_records()
            t_row = next((i + 2 for i, r in enumerate(data) if str(r.get("å°æ‡‰ç´€éŒ„ID")) == str(record_id) and str(r.get("è™•ç†ç‹€æ…‹")) == "å¾…è™•ç†"), None)
            if t_row:
                ws_appeals.update_cell(t_row, APPEAL_COLUMNS.index("è™•ç†ç‹€æ…‹") + 1, status)
                if "å¯©æ ¸å›è¦†" in APPEAL_COLUMNS:
                    ws_appeals.update_cell(t_row, APPEAL_COLUMNS.index("å¯©æ ¸å›è¦†") + 1, reply_text)
                    
                if status == "å·²æ ¸å¯":
                    m_data = ws_main.get_all_records()
                    m_row = next((j + 2 for j, mr in enumerate(m_data) if str(mr.get("ç´€éŒ„ID")) == str(record_id)), None)
                    if m_row: ws_main.update_cell(m_row, EXPECTED_COLUMNS.index("ä¿®æ­£") + 1, "TRUE")
                st.cache_data.clear(); return True, "æ›´æ–°æˆåŠŸ"
            return False, "æ‰¾ä¸åˆ°å°æ‡‰çš„ç”³è¨´åˆ—"
        except Exception as e: return False, str(e)

    def delete_rows_by_ids(ids):
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return False
        try:
            rows = sorted([i + 2 for i, r in enumerate(ws.get_all_records()) if str(r.get("ç´€éŒ„ID")) in ids], reverse=True)
            for r in rows: ws.delete_rows(r)
            time.sleep(0.8); st.cache_data.clear(); return True
        except Exception as e: st.error(f"åˆªé™¤å¤±æ•—: {e}"); return False

    @st.cache_data(ttl=21600)
    def load_inspector_list():
        ws = get_worksheet(SHEET_TABS["inspectors"])
        default = [{"label": "æ¸¬è©¦äººå“¡", "allowed_roles": ["å…§æƒæª¢æŸ¥"], "assigned_classes": [], "id_prefix": "æ¸¬", "raw_role": "å…§æƒ"}]
        if not ws: return default
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return default
            inspectors, id_c, r_c, s_c = [], next((c for c in df.columns if "å­¸è™Ÿ" in c or "ç·¨è™Ÿ" in c), None), next((c for c in df.columns if "è² è²¬" in c or "é …ç›®" in c), None), next((c for c in df.columns if "ç­ç´š" in c or "ç¯„åœ" in c), None)
            if id_c:
                for _, row in df.iterrows():
                    sid, s_role = clean_id(row[id_c]), str(row[r_c]).strip() if r_c else ""
                    
                    allowed = []
                    if "çµ„é•·" in s_role:
                        allowed = ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥", "æ™¨é–“æ‰“æƒ"]
                    else:
                        if "å¤–æƒ" in s_role: allowed.append("å¤–æƒæª¢æŸ¥")
                        if "åƒåœ¾" in s_role or "å›æ”¶" in s_role: allowed.append("åƒåœ¾/å›æ”¶æª¢æŸ¥")
                        if "æ™¨" in s_role: allowed.append("æ™¨é–“æ‰“æƒ")
                        if "å…§æƒ" in s_role: allowed.append("å…§æƒæª¢æŸ¥")
                        
                        if "è¡›ç”Ÿç³¾å¯ŸéšŠé•·" in s_role or "æ©Ÿå‹•" in s_role:
                            allowed = [r for r in allowed if r != "åƒåœ¾/å›æ”¶æª¢æŸ¥"]
                            if not allowed: allowed = ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥"]
                        elif "ç’°ä¿ç³¾å¯ŸéšŠé•·" in s_role:
                            allowed = [r for r in allowed if r not in ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥"]]
                            if "åƒåœ¾/å›æ”¶æª¢æŸ¥" not in allowed: allowed.append("åƒåœ¾/å›æ”¶æª¢æŸ¥")
                            
                        if not allowed: allowed = ["å…§æƒæª¢æŸ¥"]

                    s_classes = [c.strip() for c in str(row[s_c]).replace("ã€", ";").replace(",", ";").split(";") if c.strip()] if s_c and str(row[s_c]) else []
                    
                    inspectors.append({
                        "label": f"å­¸è™Ÿ: {sid}", "allowed_roles": allowed, 
                        "assigned_classes": s_classes, "id_prefix": sid[0] if sid else "X",
                        "raw_role": s_role
                    })
            return inspectors or default
        except: return default

    def check_duplicate_record(df, check_date, inspector, role, target_class=None):
        if df.empty: return False
        try:
            mask = (df["æ—¥æœŸ"].astype(str) == str(check_date)) & (df["æª¢æŸ¥äººå“¡"] == inspector) & (df["è©•åˆ†é …ç›®"] == role)
            if target_class: mask &= (df["ç­ç´š"] == target_class)
            return not df[mask].empty
        except: return False

    def save_entry(new_entry, uploaded_files=None, student_list=None, custom_hours=0.5, custom_category="æ™¨æƒå¿—å·¥"):
        new_entry["æ—¥æœŸ"] = str(new_entry.get("æ—¥æœŸ", str(date.today())))
        new_entry["ç´€éŒ„ID"] = new_entry.get("ç´€éŒ„ID", f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}")
        if "ç™»éŒ„æ™‚é–“" not in new_entry or not new_entry["ç™»éŒ„æ™‚é–“"]:
            new_entry["ç™»éŒ„æ™‚é–“"] = datetime.now(TW_TZ).strftime("%Y-%m-%d %H:%M:%S")

        image_paths, file_names = [], []
        if uploaded_files:
            for i, up_file in enumerate(uploaded_files):
                if not up_file: continue
                try:
                    data = up_file.getvalue()
                    if len(data) > MAX_IMAGE_BYTES: st.warning(f"æª”æ¡ˆç•¥é (éå¤§): {up_file.name}"); continue
                    fname = f"{new_entry['ç´€éŒ„ID']}_{i}.jpg"
                    local_path = os.path.join(IMG_DIR, fname)
                    with open(local_path, "wb") as f: f.write(data)
                    image_paths.append(local_path); file_names.append(fname)
                except Exception as e: print(f"Save Error: {e}")

        payload = {
            "entry": new_entry, "image_paths": image_paths, "filenames": file_names,
            "student_list": student_list or [], "custom_hours": custom_hours, "custom_category": custom_category
        }
        return enqueue_task("volunteer_report" if student_list is not None else "main_entry", payload)

    @st.cache_data(ttl=300)
    def load_full_semester_data_for_export():
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return pd.DataFrame(columns=EXPECTED_COLUMNS)
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return pd.DataFrame(columns=EXPECTED_COLUMNS)
            for col in EXPECTED_COLUMNS:
                if col not in df.columns: df[col] = ""
            for col in ["å‚™è¨»", "é•è¦ç´°é …", "ç­ç´š", "æª¢æŸ¥äººå“¡", "ä¿®æ­£", "æ™¨æƒæœªåˆ°è€…", "ç…§ç‰‡è·¯å¾‘", "ç´€éŒ„ID"]:
                if col in df.columns: df[col] = df[col].fillna("").astype(str)
            for col in ["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸", "é€±æ¬¡"]:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)
            return df[EXPECTED_COLUMNS]
        except: return pd.DataFrame()

    # ==========================================
    # 3. ä¸»ç¨‹å¼ UI å•Ÿå‹•å‰æº–å‚™
    # ==========================================
    now_tw = datetime.now(TW_TZ)
    today_tw = now_tw.date()
    
    # [V4.8] åˆå§‹åŒ–é˜²é€£é» Session State
    if "last_action_time" not in st.session_state:
        st.session_state.last_action_time = 0
    
    SYSTEM_CONFIG, ROSTER_DICT, INSPECTOR_LIST = load_settings(), load_roster_dict(), load_inspector_list()
    all_classes, structured_classes = load_sorted_classes()
    if not all_classes: all_classes, structured_classes = ["æ¸¬è©¦ç­ç´š"], [{"grade": "å…¶ä»–", "name": "æ¸¬è©¦ç­ç´š"}]
    grades = sorted(list(set([c["grade"] for c in structured_classes])))
    
    def get_week_num(d):
        try:
            start = datetime.strptime(SYSTEM_CONFIG["semester_start"], "%Y-%m-%d").date()
            if isinstance(d, datetime): d = d.date()
            return max(0, ((d - start).days // 7) + 1)
        except: return 0

    st.sidebar.title("ğŸ« åŠŸèƒ½é¸å–®")
    app_mode = st.sidebar.radio("è«‹é¸æ“‡æ¨¡å¼", ["ç³¾å¯Ÿåº•å®¶ğŸ‘€", "ç­ç´šè² è²¬äººğŸ¥¸", "æ™¨æƒå¿—å·¥éšŠğŸ§¹", "çµ„é•·ã„‰çª©ğŸ’ƒ"])

    # --- Mode 1: ç³¾å¯Ÿè©•åˆ† ---
    if app_mode == "ç³¾å¯Ÿåº•å®¶ğŸ‘€":
        st.title("ğŸ“ è¡›ç”Ÿç³¾å¯Ÿè©•åˆ†ç³»çµ±")
        if "team_logged_in" not in st.session_state: st.session_state["team_logged_in"] = False
        
        # [V4.8] æ”¹ç‚ºç›´æ¥æŒ‰ Enter ç™»å…¥
        if not st.session_state["team_logged_in"]:
            with st.expander("ğŸ” èº«ä»½é©—è­‰", expanded=True):
                pwd_input = st.text_input("è«‹è¼¸å…¥éšŠä¼é€šè¡Œç¢¼", type="password", key="m1_login_pwd")
                if pwd_input:
                    if pwd_input == st.secrets["system_config"]["team_password"]:
                        st.session_state["team_logged_in"] = True
                        st.rerun()
                    else:
                        st.error("é€šè¡Œç¢¼éŒ¯èª¤")
        
        if st.session_state["team_logged_in"]:
            prefixes = sorted(list(set([p["id_prefix"] for p in INSPECTOR_LIST])))
            if not prefixes: st.warning("æ‰¾ä¸åˆ°ç³¾å¯Ÿåå–®")
            else:
                sel_p = st.radio("æ­¥é©Ÿ 1ï¼šé¸æ“‡é–‹é ­", [f"{p}é–‹é ­" for p in prefixes], horizontal=True, key="m1_p_radio")[0]
                inspector_name = st.radio("æ­¥é©Ÿ 2ï¼šé»é¸èº«ä»½", [p["label"] for p in INSPECTOR_LIST if p["id_prefix"] == sel_p], key="m1_name_radio")
                curr_inspector = next((p for p in INSPECTOR_LIST if p["label"] == inspector_name), {})
                allowed_roles = [r for r in curr_inspector.get("allowed_roles", ["å…§æƒæª¢æŸ¥"]) if r != "æ™¨é–“æ‰“æƒ"] or ["å…§æƒæª¢æŸ¥"]
                
                st.markdown("---")
                c_d, c_r = st.columns(2)
                input_date = c_d.date_input("æª¢æŸ¥æ—¥æœŸ", today_tw)
                role = c_r.radio("æª¢æŸ¥é …ç›®", allowed_roles, horizontal=True, key="m1_role_radio") if len(allowed_roles)>1 else allowed_roles[0]
                week_num = get_week_num(input_date)
                main_df = load_main_data()

                if role == "åƒåœ¾/å›æ”¶æª¢æŸ¥":
                    st.info("ğŸ—‘ï¸ è³‡æºå›æ”¶èˆ‡åƒåœ¾æª¢æŸ¥ (æ¯æ—¥æ¯ç­æ­¤é …ç›®ç¸½æ‰£åˆ†ä¸Šé™2åˆ†å°‡æ–¼çµç®—æ™‚è‡ªå‹•å¡æ§)")
                    
                    step_a = st.radio("æ­¥é©Ÿ A: é¸æ“‡åƒåœ¾é¡åˆ¥", ["ä¸€èˆ¬åƒåœ¾", "ç´™é¡", "ç¶²è¢‹akaå¡‘è† éµé‹", "å…¶ä»–"], horizontal=True, key="m1_trash_a")
                    sel_filter = st.radio("æ­¥é©Ÿ B: ç¯©é¸æª¢æŸ¥å°è±¡", ["å„è™•å®¤ (å¤–æƒ)"] + grades, horizontal=True, key="m1_trash_b")
                    
                    today_records = main_df[(main_df["æ—¥æœŸ"].astype(str) == str(input_date)) & (main_df["è©•åˆ†é …ç›®"] == "åƒåœ¾/å›æ”¶æª¢æŸ¥") & (main_df["é•è¦ç´°é …"] == step_a)] if not main_df.empty else pd.DataFrame()
                    rows = []
                    
                    if sel_filter == "å„è™•å®¤ (å¤–æƒ)":
                        office_map = load_office_area_map()
                        target_list = list(office_map.keys()) or ["æ•™å‹™è™•", "å­¸å‹™è™•", "ç¸½å‹™è™•", "è¼”å°å®¤", "åœ–æ›¸é¤¨"]
                        for off_name in target_list:
                            cls_name = office_map.get(off_name, "æœªè¨­å®š")
                            
                            is_dump_bad = any(f"å¤–æƒ({off_name})" in str(r["å‚™è¨»"]) and "æœªå€’åƒåœ¾" in str(r["å‚™è¨»"]) for _, r in today_records.iterrows()) if not today_records.empty else False
                            is_sort_bad = any(f"å¤–æƒ({off_name})" in str(r["å‚™è¨»"]) and "æœªåšå¥½åˆ†é¡" in str(r["å‚™è¨»"]) for _, r in today_records.iterrows()) if not today_records.empty else False
                            
                            row_data = {"è™•å®¤/å€åŸŸ": off_name, "è² è²¬ç­ç´š": cls_name, "æœªåšå¥½åˆ†é¡": is_sort_bad}
                            if step_a != "ä¸€èˆ¬åƒåœ¾": row_data["æœªå€’åƒåœ¾"] = is_dump_bad
                            rows.append(row_data)
                            
                        col_config = {"è™•å®¤/å€åŸŸ": st.column_config.TextColumn(disabled=True), "è² è²¬ç­ç´š": st.column_config.TextColumn(disabled=True)}
                        if step_a != "ä¸€èˆ¬åƒåœ¾": col_config["æœªå€’åƒåœ¾"] = st.column_config.CheckboxColumn("ğŸ—‘ï¸ æœªå€’åƒåœ¾", help="æ‰£1åˆ†")
                        col_config["æœªåšå¥½åˆ†é¡"] = st.column_config.CheckboxColumn("â™»ï¸ æœªåšå¥½åˆ†é¡", help="æ‰£1åˆ†")
                        
                        edited_df = st.data_editor(pd.DataFrame(rows), column_config=col_config, hide_index=True, width="stretch", key="ed_offices")
                        
                        if st.button(f"ğŸ’¾ ç™»è¨˜é•è¦ ({step_a} - å„è™•å®¤)"):
                            # [V4.8 é˜²é€£é»ä¿è­·]
                            if time.time() - st.session_state.last_action_time < 3:
                                st.warning("âš ï¸ ç³»çµ±è™•ç†ä¸­ï¼Œè«‹å‹¿é€£çºŒé»æ“Šï¼")
                            else:
                                st.session_state.last_action_time = time.time()
                                cnt = 0
                                for _, row in edited_df.iterrows():
                                    off, cls = row["è™•å®¤/å€åŸŸ"], row["è² è²¬ç­ç´š"]
                                    b_sort = row.get("æœªåšå¥½åˆ†é¡", False)
                                    b_dump = row.get("æœªå€’åƒåœ¾", False)
                                    
                                    orig = next((x for x in rows if x["è™•å®¤/å€åŸŸ"] == off), None)
                                    v_list = []
                                    if b_dump and not orig.get("æœªå€’åƒåœ¾", False): v_list.append("æœªå€’åƒåœ¾")
                                    if b_sort and not orig.get("æœªåšå¥½åˆ†é¡", False): v_list.append("æœªåšå¥½åˆ†é¡")
                                    
                                    if v_list:
                                        score = len(v_list)
                                        base = {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ç­ç´š": cls, "è©•åˆ†é …ç›®": role, "åƒåœ¾å…§æƒåŸå§‹åˆ†": 0, "åƒåœ¾å¤–æƒåŸå§‹åˆ†": score}
                                        save_entry({**base, "å‚™è¨»": f"å¤–æƒ({off})-{step_a}({','.join(v_list)})", "é•è¦ç´°é …": step_a})
                                        cnt += 1
                                if cnt: st.success(f"âœ… å·²ç™»è¨˜ {cnt} ç­†é•è¦ï¼"); time.sleep(1.5); st.rerun()

                    else:
                        for cls_name in [c["name"] for c in structured_classes if c["grade"] == sel_filter]:
                            cls_rec = today_records[today_records["ç­ç´š"] == cls_name] if not today_records.empty else pd.DataFrame()
                            
                            is_dump_bad = any("å…§æƒ" in str(r["å‚™è¨»"]) and "æœªå€’åƒåœ¾" in str(r["å‚™è¨»"]) for _, r in cls_rec.iterrows()) if not cls_rec.empty else False
                            is_sort_bad = any("å…§æƒ" in str(r["å‚™è¨»"]) and "æœªåšå¥½åˆ†é¡" in str(r["å‚™è¨»"]) for _, r in cls_rec.iterrows()) if not cls_rec.empty else False
                            
                            row_data = {"ç­ç´š": cls_name, "æœªåšå¥½åˆ†é¡": is_sort_bad}
                            if step_a != "ä¸€èˆ¬åƒåœ¾": row_data["æœªå€’åƒåœ¾"] = is_dump_bad
                            rows.append(row_data)
                            
                        col_config = {"ç­ç´š": st.column_config.TextColumn(disabled=True)}
                        if step_a != "ä¸€èˆ¬åƒåœ¾": col_config["æœªå€’åƒåœ¾"] = st.column_config.CheckboxColumn("ğŸ—‘ï¸ æœªå€’åƒåœ¾", help="æ‰£1åˆ†")
                        col_config["æœªåšå¥½åˆ†é¡"] = st.column_config.CheckboxColumn("â™»ï¸ æœªåšå¥½åˆ†é¡", help="æ‰£1åˆ†")
                            
                        edited_df = st.data_editor(pd.DataFrame(rows), column_config=col_config, hide_index=True, width="stretch", key=f"ed_{sel_filter}")
                        
                        if st.button(f"ğŸ’¾ ç™»è¨˜é•è¦ ({step_a} - {sel_filter})"):
                            # [V4.8 é˜²é€£é»ä¿è­·]
                            if time.time() - st.session_state.last_action_time < 3:
                                st.warning("âš ï¸ ç³»çµ±è™•ç†ä¸­ï¼Œè«‹å‹¿é€£çºŒé»æ“Šï¼")
                            else:
                                st.session_state.last_action_time = time.time()
                                cnt = 0
                                for _, row in edited_df.iterrows():
                                    cls = row["ç­ç´š"]
                                    b_sort = row.get("æœªåšå¥½åˆ†é¡", False)
                                    b_dump = row.get("æœªå€’åƒåœ¾", False)
                                    
                                    orig = next((x for x in rows if x["ç­ç´š"] == cls), None)
                                    v_list = []
                                    if b_dump and not orig.get("æœªå€’åƒåœ¾", False): v_list.append("æœªå€’åƒåœ¾")
                                    if b_sort and not orig.get("æœªåšå¥½åˆ†é¡", False): v_list.append("æœªåšå¥½åˆ†é¡")
                                    
                                    if v_list:
                                        score = len(v_list)
                                        base = {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ç­ç´š": cls, "è©•åˆ†é …ç›®": role, "åƒåœ¾å…§æƒåŸå§‹åˆ†": score, "åƒåœ¾å¤–æƒåŸå§‹åˆ†": 0}
                                        save_entry({**base, "å‚™è¨»": f"å…§æƒ-{step_a}({','.join(v_list)})", "é•è¦ç´°é …": step_a})
                                        cnt += 1
                                if cnt: st.success(f"âœ… å·²ç™»è¨˜ {cnt} ç­†é•è¦ï¼"); time.sleep(1.5); st.rerun()

                else:
                    assigned_classes = curr_inspector.get("assigned_classes", [])
                    if assigned_classes:
                        sel_cls = st.radio("é¸æ“‡è² è²¬ç­ç´š", assigned_classes, key="m1_cls_assigned")
                    else:
                        temp_g = st.radio("æ­¥é©Ÿ A: é¸æ“‡å¹´ç´š", grades, horizontal=True, key="m1_grade_select")
                        f_cls_list = [c["name"] for c in structured_classes if c["grade"] == temp_g]
                        sel_cls = st.radio("æ­¥é©Ÿ B: é¸æ“‡ç­ç´š", f_cls_list, horizontal=True, key="m1_cls_select") if f_cls_list else None

                    if sel_cls:
                        st.divider()
                        if check_duplicate_record(main_df, input_date, inspector_name, role, sel_cls): st.warning(f"âš ï¸ ä»Šæ—¥å·²è©•é {sel_cls}ï¼")
                        with st.form("score_form", clear_on_submit=True):
                            in_s, out_s, ph_c, note = 0, 0, 0, ""
                            if st.radio("æª¢æŸ¥çµæœ", ["âŒ é•è¦", "âœ¨ ä¹¾æ·¨"], horizontal=True) == "âŒ é•è¦":
                                if role == "å…§æƒæª¢æŸ¥":
                                    in_s = st.number_input("å…§æƒæ‰£åˆ†", 0)
                                    note = " ".join([x for x in [st.selectbox("å€å¡Š", ["", "èµ°å»Š", "é»‘æ¿", "åœ°æ¿"]), st.selectbox("ç‹€æ³", ["", "é«’äº‚", "æ²’æ‹–åœ°"]), st.text_input("è£œå……")] if x])
                                else:
                                    out_s = st.number_input("å¤–æƒæ‰£åˆ†", 0)
                                    note = " ".join([x for x in [st.selectbox("å€åŸŸ", ["", "èµ°å»Š", "æ¨“æ¢¯", "å»æ‰€", "æ“å ´"]), st.selectbox("ç‹€æ³", ["", "å¾ˆé«’", "æ²’æƒ"]), st.text_input("è£œå……")] if x])
                            is_fix = st.checkbox("ğŸš© é€™æ˜¯ä¿®æ­£å–®")
                            files = st.file_uploader("ğŸ“¸ é•è¦ç…§ç‰‡", accept_multiple_files=True)
                            
                            if st.form_submit_button("é€å‡º"):
                                # [V4.8 é˜²é€£é»ä¿è­·]
                                if time.time() - st.session_state.last_action_time < 3:
                                    st.warning("âš ï¸ ç³»çµ±è™•ç†ä¸­ï¼Œè«‹å‹¿é€£çºŒé»æ“Šï¼")
                                else:
                                    st.session_state.last_action_time = time.time()
                                    if (in_s + out_s) > 0 and not files: 
                                        st.error("æ‰£åˆ†éœ€ç…§ç‰‡")
                                    else:
                                        save_entry({"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ä¿®æ­£": is_fix, "ç­ç´š": sel_cls, "è©•åˆ†é …ç›®": role, "å…§æƒåŸå§‹åˆ†": in_s, "å¤–æƒåŸå§‹åˆ†": out_s, "æ‰‹æ©Ÿäººæ•¸": ph_c, "å‚™è¨»": note}, uploaded_files=files)
                                        st.success("âœ… é€å‡ºæˆåŠŸï¼ç³»çµ±å°‡è‡ªå‹•æ’ç¨‹ç™¼æ”¾æœ¬æ—¥ 0.25 å°æ™‚ã€‚")
                                        time.sleep(1.5)
                                        st.rerun()

    # --- Mode 2: ç­ç´šè² è²¬äºº ---
    elif app_mode == "ç­ç´šè² è²¬äººğŸ¥¸":
        st.title("ğŸ” ç­ç´šæˆç¸¾æŸ¥è©¢")
        df, appeals_df = load_main_data(), load_appeals()
        appeal_map = {str(r.get("å°æ‡‰ç´€éŒ„ID")): {"status": str(r.get("è™•ç†ç‹€æ…‹", "")), "reply": str(r.get("å¯©æ ¸å›è¦†", ""))} for _, r in appeals_df.iterrows()} if not appeals_df.empty else {}
        
        sel_grade_m2 = st.radio("é¸æ“‡å¹´ç´š", grades, horizontal=True, key="m2_grade_select")
        cls_opts = [c["name"] for c in structured_classes if c["grade"] == sel_grade_m2]
        
        if cls_opts:
            cls = st.selectbox("é¸æ“‡ç­ç´š", cls_opts, key="m2_cls_select")
            if cls and not df.empty:
                for idx, r in df[df["ç­ç´š"] == cls].sort_values("ç™»éŒ„æ™‚é–“", ascending=False).iterrows():
                    trash_score = r['åƒåœ¾å…§æƒåŸå§‹åˆ†'] + r['åƒåœ¾å¤–æƒåŸå§‹åˆ†']
                    if trash_score == 0: trash_score = r['åƒåœ¾åŸå§‹åˆ†']
                    
                    tot = r['å…§æƒåŸå§‹åˆ†'] + r['å¤–æƒåŸå§‹åˆ†'] + trash_score + r['æ™¨é–“æ‰“æƒåŸå§‹åˆ†']
                    rid = str(r['ç´€éŒ„ID'])
                    ap_info = appeal_map.get(rid, {})
                    ap_st = ap_info.get("status")
                    ap_reply = ap_info.get("reply")
                    
                    icon = "âœ…" if ap_st=="å·²æ ¸å¯" else "ğŸš«" if ap_st=="å·²é§å›" else "â³" if ap_st=="å¾…è™•ç†" else "ğŸ› ï¸" if str(r['ä¿®æ­£'])=="TRUE" else ""
                    
                    disp_time = str(r.get('ç™»éŒ„æ™‚é–“', ''))
                    time_str = disp_time.split(' ')[-1] if disp_time else ''
                    with st.expander(f"{icon} {r['æ—¥æœŸ']} {time_str} - {r['è©•åˆ†é …ç›®']} (æ‰£:{tot})"):
                        st.caption(f"ç™»éŒ„æ™‚é–“ï¼š{disp_time if disp_time else 'æœªç´€éŒ„'}") 
                        st.write(f"ğŸ§‘â€âœˆï¸ **è©•åˆ†äººå“¡:** {r.get('æª¢æŸ¥äººå“¡', 'æœªçŸ¥')}")
                        st.write(f"ğŸ“ **å‚™è¨»:** {r['å‚™è¨»']}")
                        
                        if ap_st:
                            if ap_st == "å¾…è™•ç†": st.info("â³ ç”³è¨´å¯©æ ¸ä¸­...")
                            elif ap_st == "å·²æ ¸å¯": st.success(f"âœ… ç”³è¨´æˆåŠŸã€‚çµ„é•·å›è¦†: {ap_reply if ap_reply else 'ç„¡'}")
                            elif ap_st == "å·²é§å›": st.error(f"ğŸš« ç”³è¨´é§å›ã€‚çµ„é•·å›è¦†: {ap_reply if ap_reply else 'ç„¡'}")
                            
                        if str(r['ç…§ç‰‡è·¯å¾‘']) and "http" in str(r['ç…§ç‰‡è·¯å¾‘']): st.image([p for p in str(r['ç…§ç‰‡è·¯å¾‘']).split(";") if "http" in p], width=200)
                        if not ap_st and is_within_appeal_period(r['æ—¥æœŸ']) and (tot > 0 or r['æ‰‹æ©Ÿäººæ•¸'] > 0):
                            with st.form(f"ap_{rid}"):
                                rsn, pf = st.text_area("ç†ç”±"), st.file_uploader("ä½è­‰", type=['jpg','png'])
                                if st.form_submit_button("ç”³è¨´") and rsn and pf:
                                    # [V4.8 é˜²é€£é»ä¿è­·]
                                    if time.time() - st.session_state.last_action_time < 3:
                                        st.warning("âš ï¸ ç³»çµ±è™•ç†ä¸­ï¼Œè«‹å‹¿é€£çºŒé»æ“Šï¼")
                                    else:
                                        st.session_state.last_action_time = time.time()
                                        save_appeal({"ç­ç´š": cls, "é•è¦æ—¥æœŸ": str(r["æ—¥æœŸ"]), "é•è¦é …ç›®": r['è©•åˆ†é …ç›®'], "åŸå§‹æ‰£åˆ†": str(tot), "ç”³è¨´ç†ç”±": rsn, "å°æ‡‰ç´€éŒ„ID": rid}, pf)
                                        time.sleep(1.5)
                                        st.rerun()

    # --- Mode 3: æ™¨æƒå¿—å·¥éšŠ ---
    elif app_mode == "æ™¨æƒå¿—å·¥éšŠğŸ§¹":
        st.title("ğŸ§¹ æ™¨æƒå¿—å·¥å›å ±å°ˆå€")
        if now_tw.hour >= 16: st.error("ğŸš« ä»Šæ—¥å›å ±å·²æˆªæ­¢ (16:00)")
        else:
            my_cls = st.selectbox("é¸æ“‡ç­ç´š", all_classes, key="m3_cls_select")
            main_df = load_main_data()
            if not main_df[(main_df["æ—¥æœŸ"].astype(str)==str(today_tw)) & (main_df["ç­ç´š"]==my_cls) & (main_df["è©•åˆ†é …ç›®"]=="æ™¨é–“æ‰“æƒ")].empty: st.warning(f"âš ï¸ {my_cls} å·²å›å ±ï¼")
            else:
                duty_df, _ = get_daily_duty(today_tw)
                area_name = "ç„¡"
                n_std = 4
                if not duty_df.empty:
                    m_d = duty_df[duty_df["è² è²¬ç­ç´š"]==my_cls]
                    if not m_d.empty:
                        area_name = m_d.iloc[0].get('æƒåœ°å€åŸŸ', 'ç„¡')
                        try: n_std = int(m_d.iloc[0].get('æ¨™æº–äººæ•¸', 4))
                        except: n_std = 4
                
                st.info(f"ğŸ“ ä»»å‹™: {area_name} (æ‡‰åˆ°:{n_std}äºº)")
                with st.form("vol_form"):
                    present = st.multiselect("âœ… å¯¦åˆ°åŒå­¸", [s for s, c in ROSTER_DICT.items() if c == my_cls])
                    files = st.file_uploader("ğŸ“¸ æˆæœç…§ç‰‡", accept_multiple_files=True, type=['jpg','png'])
                    if st.form_submit_button("é€å‡º"):
                        # [V4.8 é˜²é€£é»ä¿è­·]
                        if time.time() - st.session_state.last_action_time < 3:
                            st.warning("âš ï¸ ç³»çµ±è™•ç†ä¸­ï¼Œè«‹å‹¿é€£çºŒé»æ“Šï¼")
                        elif present and files:
                            st.session_state.last_action_time = time.time()
                            save_entry({"æ—¥æœŸ": str(today_tw), "ç­ç´š": my_cls, "è©•åˆ†é …ç›®": "æ™¨é–“æ‰“æƒ", "æª¢æŸ¥äººå“¡": f"å¿—å·¥(å¯¦åˆ°:{len(present)})", "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": 0, "å‚™è¨»": f"åå–®:{','.join(present)}"}, uploaded_files=files, student_list=present, custom_hours=0.5, custom_category="æ™¨æƒå¿—å·¥")
                            st.success("âœ… å›å ±æˆåŠŸï¼")
                            time.sleep(1.5)
                            st.rerun()
                        else:
                            st.error("è«‹å‹¾é¸åå–®ä¸¦ä¸Šå‚³ç…§ç‰‡")

    # --- Mode 4: çµ„é•·å¾Œå° ---
    elif app_mode == "çµ„é•·ã„‰çª©ğŸ’ƒ":
        st.title("âš™ï¸ ç®¡ç†å¾Œå°")
        metrics = get_queue_metrics()
        c1, c2, c3 = st.columns(3)
        c1.metric("å¾…è™•ç†", metrics["pending"])
        c2.metric("å¤±æ•—", metrics["failed"])
        c3.metric("å»¶é²(s)", int(metrics["oldest_pending_sec"]))

        # [V4.8] æ”¹ç‚ºç›´æ¥æŒ‰ Enter ç™»å…¥
        pwd_input = st.text_input("ç®¡ç†å¯†ç¢¼", type="password", key="admin_pwd")
        if pwd_input == st.secrets["system_config"]["admin_password"]:
            
            t_mon, t_rollcall, t4, t_appeal, t2, t1, t_settings, t3 = st.tabs([
                "ğŸ‘€ è¡›ç”Ÿç³¾å¯Ÿ", "ğŸ‘® ç’°ä¿ç³¾å¯Ÿ", "ğŸ“ æ‰£åˆ†æ˜ç´°", "ğŸ“£ ç”³è¨´", "ğŸ“Š æˆç¸¾ç¸½è¡¨", 
                "ğŸ§¹ æ™¨æƒå¯©æ ¸", "âš™ï¸ è¨­å®š", "ğŸ« è¿”æ ¡æ‰“æƒ"
            ])
            
            with t_mon:
                st.subheader("ğŸ•µï¸ ä»Šæ—¥ã€Œè¡›ç”Ÿç³¾å¯Ÿã€é€²åº¦ç›£æ§")
                monitor_date = st.date_input("ç›£æ§æ—¥æœŸ", today_tw, key="monitor_date")
                st.caption(f"ğŸ“… æ­¤å€é¡¯ç¤ºè² è²¬ã€Œå…§æƒã€å¤–æƒã€æ©Ÿå‹•ã€çš„è©•åˆ†ç³¾å¯Ÿé€²åº¦ã€‚")

                df = load_main_data()
                submitted_names = set()
                if not df.empty:
                    today_records = df[df["æ—¥æœŸ"].astype(str) == str(monitor_date)]
                    submitted_names = set(today_records["æª¢æŸ¥äººå“¡"].unique())

                cleaning_inspectors = [p for p in INSPECTOR_LIST if any(x in p.get("raw_role", "") for x in ["å…§æƒ", "å¤–æƒ", "æ©Ÿå‹•", "éšŠé•·", "çµ„é•·"])]
                
                regular_inspectors, mobile_inspectors = [], []
                for p in cleaning_inspectors:
                    p_name = p["label"]
                    is_mobile = len(p.get("assigned_classes", [])) == 0
                    status_obj = {"name": p_name, "role_desc": p.get("raw_role", ""), "done": p_name in submitted_names}
                    if is_mobile: mobile_inspectors.append(status_obj)
                    else: regular_inspectors.append(status_obj)

                col_reg, col_mob = st.columns(2)
                with col_reg:
                    st.write("#### ğŸ”´ ç­ç´šè©•åˆ†å“¡ (æœªå®Œæˆ)")
                    missing_reg = [x for x in regular_inspectors if not x["done"]]
                    if missing_reg:
                        for p in missing_reg: st.error(f"âŒ {p['name']}")
                    else: st.success("ğŸ‰ å…¨å“¡å®Œæˆï¼")
                with col_mob:
                    st.write("#### ğŸŸ  æ©Ÿå‹•/éšŠé•· (æœªå®Œæˆ)")
                    st.caption("æ©Ÿå‹•äººå“¡è‹¥ä»Šæ—¥ç„¡é•è¦ï¼Œå¯èƒ½ä¸æœƒé€å‡ºè³‡æ–™ã€‚")
                    missing_mob = [x for x in mobile_inspectors if not x["done"]]
                    if missing_mob:
                        for p in missing_mob: st.warning(f"âš ï¸ {p['name']} \n ({p['role_desc']})")
                    else: st.success("ğŸ‰ å…¨å“¡å®Œæˆï¼")

            with t_rollcall:
                st.subheader("ğŸ‘® ç’°ä¿ç³¾å¯Ÿ (è³‡æ”¶å ´) å‡ºå‹¤é»å")
                st.info("ğŸ’¡ èªªæ˜ï¼šæ­¤å€å°ˆç‚ºè³‡æ”¶å ´çš„ç’°ä¿ç³¾å¯Ÿè¨­è¨ˆã€‚å‹¾é¸æ²’ä¾†çš„äººï¼Œç³»çµ±æœƒè‡ªå‹•å¹«æœ‰ä¾†çš„äººç™¼æ”¾ 0.25 å°æ™‚ã€‚")
                
                rc_date = st.date_input("å‡ºå‹¤æ—¥æœŸ", today_tw, key="insp_rc_date")
                
                trash_inspectors = [p for p in INSPECTOR_LIST if "åƒåœ¾" in p.get("raw_role", "") or "å›æ”¶" in p.get("raw_role", "") or "ç’°ä¿" in p.get("raw_role", "")]
                insp_names = [p["label"] for p in trash_inspectors]
                
                if not insp_names:
                    st.warning("âš ï¸ ç›®å‰åå–®ä¸­æ²’æœ‰è² è²¬ã€Œç’°ä¿/åƒåœ¾/å›æ”¶ã€çš„ç³¾å¯Ÿã€‚")
                else:
                    with st.form("insp_rc_form"):
                        st.write(f"è³‡æ”¶å ´ç³¾å¯Ÿåå–®å…± {len(insp_names)} äºº")
                        absent_insps = st.multiselect("âŒ å‹¾é¸ã€è«‹å‡ / æœªåˆ°ã€‘çš„ç³¾å¯Ÿ (æ‰£é™¤æ³•)", insp_names)
                        present_insps = [n for n in insp_names if n not in absent_insps]
                        
                        st.write(f"âœ… é è¨ˆç™¼æ”¾å°è±¡ï¼šå…± {len(present_insps)} äºº (æ¯äºº 0.25 å°æ™‚)")
                        
                        if st.form_submit_button("ğŸš€ ç™¼æ”¾ç’°ä¿ç³¾å¯Ÿæ™‚æ•¸"):
                            # [V4.8 é˜²é€£é»ä¿è­·]
                            if time.time() - st.session_state.last_action_time < 3:
                                st.warning("âš ï¸ ç³»çµ±è™•ç†ä¸­ï¼Œè«‹å‹¿é€£çºŒé»æ“Šï¼")
                            else:
                                st.session_state.last_action_time = time.time()
                                present_ids = [name.split("å­¸è™Ÿ:")[1].strip() for name in present_insps if "å­¸è™Ÿ:" in name]
                                if present_ids:
                                    payload = {
                                        "student_list": present_ids,
                                        "date": str(rc_date),
                                        "class_name": "ç³¾å¯ŸéšŠ",
                                        "category": "è³‡æºå›æ”¶ç³¾å¯Ÿ",
                                        "hours": 0.25
                                    }
                                    enqueue_task("service_hours_only", payload)
                                    st.success(f"âœ… å·²æ’ç¨‹ç™¼æ”¾ {len(present_ids)} äººçš„å‡ºå‹¤æ™‚æ•¸ï¼(ç³»çµ±æœƒè‡ªå‹•é˜»æ“‹åŒä¸€å¤©çš„é‡è¤‡ç™¼æ”¾)")
                                    time.sleep(1.5)
                                    st.rerun()
                                else:
                                    st.warning("æ²’æœ‰å¯ç™¼æ”¾æ™‚æ•¸çš„å°è±¡")

            with t4:
                df = load_main_data()
                if not df.empty:
                    st.dataframe(df[["ç™»éŒ„æ™‚é–“", "æ—¥æœŸ", "ç­ç´š", "è©•åˆ†é …ç›®", "æª¢æŸ¥äººå“¡", "å‚™è¨»", "é•è¦ç´°é …", "ç´€éŒ„ID"]].sort_values("ç™»éŒ„æ™‚é–“", ascending=False))

            with t_appeal:
                st.subheader("ğŸ“£ ç”³è¨´å¯©æ ¸")
                ap_df = load_appeals()
                pending_aps = ap_df[ap_df["è™•ç†ç‹€æ…‹"]=="å¾…è™•ç†"]
                
                if pending_aps.empty: 
                    st.success("ç›®å‰ç„¡å¾…å¯©æ ¸çš„ç”³è¨´æ¡ˆä»¶ã€‚")
                else:
                    for i, r in pending_aps.iterrows():
                        with st.container(border=True):
                            c1, c2 = st.columns([3,2])
                            c1.write(f"### {r['ç­ç´š']} | {r['é•è¦é …ç›®']} (æ‰£ {r['åŸå§‹æ‰£åˆ†']} åˆ†)")
                            c1.write(f"**ç”³è¨´ç†ç”±**: {r['ç”³è¨´ç†ç”±']}")
                            c1.caption(f"é•è¦æ—¥æœŸ: {r['é•è¦æ—¥æœŸ']} | ç”³è¨´æ™‚é–“: {r['ç™»éŒ„æ™‚é–“']}")
                            
                            img_urls = str(r.get('ä½è­‰ç…§ç‰‡', ''))
                            if img_urls and "http" in img_urls:
                                c2.image([p for p in img_urls.split(";") if "http" in p], width=250)
                            else:
                                c2.info("ç„¡ä½è­‰ç…§ç‰‡")
                                
                            reply_text = c1.text_input("ğŸ’¬ å¯©æ ¸å›è¦† (å¡«å¯«å¾Œå­¸ç”Ÿå°‡åœ¨æŸ¥è©¢é é¢çœ‹åˆ°æ­¤èªªæ˜)", key=f"reply_{i}")
                            
                            col_btn1, col_btn2 = c1.columns(2)
                            if col_btn1.button("âœ… æ ¸å¯ä¸¦æ’¤éŠ·æ‰£åˆ†", key=f"ok_{i}"): 
                                update_appeal_status(i, "å·²æ ¸å¯", r["å°æ‡‰ç´€éŒ„ID"], reply_text)
                                st.rerun()
                            if col_btn2.button("ğŸš« é§å›ç¶­æŒåŸåˆ¤", key=f"ng_{i}"): 
                                update_appeal_status(i, "å·²é§å›", r["å°æ‡‰ç´€éŒ„ID"], reply_text)
                                st.rerun()

            with t2:
                st.subheader("ğŸ“Š æˆç¸¾ç¸½è¡¨")
                full = load_full_semester_data_for_export()
                
                if full.empty:
                    st.info("ç›®å‰ç„¡è©•åˆ†è³‡æ–™")
                else:
                    tab_week, tab_semester = st.tabs(["ğŸ“… å–®é€±æˆç¸¾çµç®—", "ğŸ† å…¨å­¸æœŸç¸½çµç®—"])
                    
                    with tab_week:
                        available_weeks = sorted([w for w in full["é€±æ¬¡"].unique() if w > 0])
                        if not available_weeks:
                            st.warning("å°šç„¡æœ‰æ•ˆçš„é€±æ¬¡è³‡æ–™")
                        else:
                            sel_week = st.selectbox("è«‹é¸æ“‡çµç®—é€±æ¬¡", available_weeks, index=len(available_weeks)-1)
                            is_fall = (today_tw.month >= 8 or today_tw.month == 1)
                            default_mode = "å¹´ç´š (ä¸Šå­¸æœŸåˆ¶)" if is_fall else "å…¨æ ¡ (ä¸‹å­¸æœŸåˆ¶)"
                            
                            st.info(f"ğŸ’¡ ç³»çµ±åµæ¸¬ç›®å‰ç‚º **{'ä¸Š' if is_fall else 'ä¸‹'}å­¸æœŸ**ï¼Œé è¨­æ¡ç”¨ **{default_mode}** æ’åã€‚")
                            rank_mode = st.radio("æ’åæ–¹å¼ (å¯æ‰‹å‹•æ›´æ”¹)", ["å¹´ç´š", "å…¨æ ¡"], index=0 if is_fall else 1, horizontal=True)
                            
                            if st.button("ğŸš€ è¨ˆç®—ç•¶é€±æˆç¸¾"):
                                week_df = full[full["é€±æ¬¡"] == sel_week].copy()
                                week_df["å…§æƒçµç®—"] = week_df["å…§æƒåŸå§‹åˆ†"].clip(upper=2)
                                week_df["å¤–æƒçµç®—"] = week_df["å¤–æƒåŸå§‹åˆ†"].clip(upper=2)
                                trash_total = week_df["åƒåœ¾å…§æƒåŸå§‹åˆ†"] + week_df["åƒåœ¾å¤–æƒåŸå§‹åˆ†"]
                                trash_total = trash_total.where(trash_total > 0, week_df["åƒåœ¾åŸå§‹åˆ†"])
                                week_df["åƒåœ¾çµç®—"] = trash_total.clip(upper=2)
                                week_df["ç¸½æ‰£åˆ†"] = week_df["å…§æƒçµç®—"]+week_df["å¤–æƒçµç®—"]+week_df["åƒåœ¾çµç®—"]+week_df["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"]+week_df["æ‰‹æ©Ÿäººæ•¸"]
                                
                                rep = week_df.groupby("ç­ç´š")["ç¸½æ‰£åˆ†"].sum().reset_index()
                                cls_df = pd.DataFrame(structured_classes).rename(columns={"grade":"å¹´ç´š","name":"ç­ç´š"})
                                fin = pd.merge(cls_df, rep, on="ç­ç´š", how="left").fillna(0)
                                fin["ç¸½æˆç¸¾"] = 90 - fin["ç¸½æ‰£åˆ†"]
                                
                                if rank_mode == "å…¨æ ¡": st.dataframe(fin.sort_values("ç¸½æˆç¸¾", ascending=False))
                                else:
                                    for g in sorted(fin["å¹´ç´š"].unique()):
                                        if g != "å…¶ä»–": 
                                            st.write(f"#### {g} æ’å")
                                            st.dataframe(fin[fin["å¹´ç´š"]==g].sort_values("ç¸½æˆç¸¾", ascending=False))
                    
                    with tab_semester:
                        st.write("è¨ˆç®—å…¨å­¸æœŸç´¯è¨ˆç¸½æ‰£åˆ†èˆ‡ç¸½æˆç¸¾")
                        sem_rank_mode = st.radio("å­¸æœŸæ’åæ–¹å¼", ["å…¨æ ¡", "å¹´ç´š"], horizontal=True, key="sem_rank")
                        
                        if st.button("ğŸš€ è¨ˆç®—å…¨å­¸æœŸæˆç¸¾", key="sem_btn"):
                            full["å…§æƒçµç®—"] = full["å…§æƒåŸå§‹åˆ†"].clip(upper=2)
                            full["å¤–æƒçµç®—"] = full["å¤–æƒåŸå§‹åˆ†"].clip(upper=2)
                            trash_total = full["åƒåœ¾å…§æƒåŸå§‹åˆ†"] + full["åƒåœ¾å¤–æƒåŸå§‹åˆ†"]
                            trash_total = trash_total.where(trash_total > 0, full["åƒåœ¾åŸå§‹åˆ†"])
                            full["åƒåœ¾çµç®—"] = trash_total.clip(upper=2)
                            full["ç¸½æ‰£åˆ†"] = full["å…§æƒçµç®—"]+full["å¤–æƒçµç®—"]+full["åƒåœ¾çµç®—"]+full["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"]+full["æ‰‹æ©Ÿäººæ•¸"]
                            rep = full.groupby("ç­ç´š")["ç¸½æ‰£åˆ†"].sum().reset_index()
                            cls_df = pd.DataFrame(structured_classes).rename(columns={"grade":"å¹´ç´š","name":"ç­ç´š"})
                            fin = pd.merge(cls_df, rep, on="ç­ç´š", how="left").fillna(0)
                            fin["ç¸½æˆç¸¾"] = 90 - fin["ç¸½æ‰£åˆ†"] 
                            
                            if sem_rank_mode == "å…¨æ ¡": st.dataframe(fin.sort_values("ç¸½æˆç¸¾", ascending=False))
                            else:
                                for g in sorted(fin["å¹´ç´š"].unique()):
                                    if g != "å…¶ä»–": 
                                        st.write(f"#### {g}")
                                        st.dataframe(fin[fin["å¹´ç´š"]==g].sort_values("ç¸½æˆç¸¾", ascending=False))

            with t1:
                df = load_main_data()
                for i, r in df[(df["è©•åˆ†é …ç›®"]=="æ™¨é–“æ‰“æƒ") & (df["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"]==0) & (df["ä¿®æ­£"]!="TRUE")].iterrows():
                    with st.container(border=True):
                        c1, c2, c3 = st.columns([2,2,1])
                        c1.write(f"**{r['ç­ç´š']}** | {r['æª¢æŸ¥äººå“¡']}")
                        c1.caption(f"ç™»éŒ„æ™‚é–“ï¼š{r['ç™»éŒ„æ™‚é–“']}") 
                        if "http" in str(r['ç…§ç‰‡è·¯å¾‘']): c2.image(str(r['ç…§ç‰‡è·¯å¾‘']).split(";")[0], width=150) 
                        
                        if c3.button("âœ… é€šé(+2)", key=f"p_{r['ç´€éŒ„ID']}"): 
                            ws = get_worksheet(SHEET_TABS["main"])
                            id_list = ws.col_values(EXPECTED_COLUMNS.index("ç´€éŒ„ID")+1)
                            if str(r["ç´€éŒ„ID"]) in id_list:
                                ridx = id_list.index(str(r["ç´€éŒ„ID"])) + 1
                                ws.update_cell(ridx, EXPECTED_COLUMNS.index("æ™¨é–“æ‰“æƒåŸå§‹åˆ†")+1, 2)
                                st.cache_data.clear(); st.rerun()
                        if c3.button("ğŸ—‘ï¸ é§å›", key=f"r_{r['ç´€éŒ„ID']}"): delete_rows_by_ids([str(r["ç´€éŒ„ID"])]); st.rerun()

            with t_settings:
                st.subheader("âš™ï¸ ç³»çµ±è¨­å®šèˆ‡ç¶­è­·")
                curr = SYSTEM_CONFIG.get("semester_start")
                nd = st.date_input("é–‹å­¸æ—¥", datetime.strptime(curr, "%Y-%m-%d").date() if curr else today_tw)
                if st.button("æ›´æ–°é–‹å­¸æ—¥"): save_setting("semester_start", str(nd))
                
                st.markdown("---")
                st.write("ğŸ”§ ç³»çµ±é€£ç·šç‹€æ…‹")
                if get_gspread_client(): st.success("âœ… Google Sheets é€£ç·šæ­£å¸¸")
                else: st.error("âŒ Google Sheets é€£ç·šå¤±æ•—")
                st.info("è‹¥éœ€ä¿®æ”¹åå–®è«‹ç›´æ¥è‡³ Google Sheet ä¿®æ”¹ inspectors / roster / office_areas åˆ†é ")
                if st.button("ğŸ”„ é‡è®€åå–® (æ¸…é™¤å¿«å–)"): st.cache_data.clear(); st.success("å·²æ¸…é™¤å¿«å–ï¼")

            with t3:
                c1, c2 = st.columns(2)
                rd, rc = c1.date_input("æ—¥æœŸ", today_tw, key="ret_date"), c2.selectbox("ç­ç´š", all_classes, key="ret_cls")
                mems = [s for s, c in ROSTER_DICT.items() if c == rc]
                if mems:
                    with st.form("ret_clean"):
                        absent = st.multiselect("ç¼ºå¸­åå–®", mems)
                        pool = [m for m in mems if m not in absent]
                        base_h = st.number_input("åŸºç¤æ™‚æ•¸", value=2.0, step=0.5)
                        spec = st.multiselect("åŠ å¼·çµ„", pool)
                        spec_h = st.number_input("ç‰¹åˆ¥æ™‚æ•¸", value=3.0, step=0.5)
                        pf = st.file_uploader("ç…§ç‰‡", type=['jpg','png'])
                        
                        if st.form_submit_button("ç™¼æ”¾"):
                            # [V4.8 é˜²é€£é»ä¿è­·]
                            if time.time() - st.session_state.last_action_time < 3:
                                st.warning("âš ï¸ ç³»çµ±è™•ç†ä¸­ï¼Œè«‹å‹¿é€£çºŒé»æ“Šï¼")
                            elif pf:
                                st.session_state.last_action_time = time.time()
                                pf.seek(0); fb = pf.read()
                                norm = [m for m in pool if m not in spec]
                                if norm: pf_n = io.BytesIO(fb); pf_n.name="p.jpg"; save_entry({"æ—¥æœŸ": str(rd), "ç­ç´š": rc, "è©•åˆ†é …ç›®": "è¿”æ ¡æ‰“æƒ", "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S")}, [pf_n], norm, base_h, "è¿”æ ¡æ‰“æƒ(ä¸€èˆ¬)")
                                if spec: pf_s = io.BytesIO(fb); pf_s.name="p.jpg"; save_entry({"æ—¥æœŸ": str(rd), "ç­ç´š": rc, "è©•åˆ†é …ç›®": "è¿”æ ¡æ‰“æƒ", "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S")}, [pf_s], spec, spec_h, "è¿”æ ¡æ‰“æƒ(åŠ å¼·)")
                                st.success("å·²ç™»è¨˜ï¼"); time.sleep(1.5); st.rerun()
                            else:
                                st.error("éœ€ä¸Šå‚³ç…§ç‰‡")

        elif pwd_input != "":
            st.error("å¯†ç¢¼éŒ¯èª¤")

except Exception as e:
    st.error(f"âŒ ç³»çµ±ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    st.code(traceback.format_exc())
