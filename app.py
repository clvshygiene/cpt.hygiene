import streamlit as st
import pandas as pd
import os
import smtplib
import time
import io
import traceback
import threading
import uuid
import re
import sqlite3
import json
import random
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, date, timedelta
from datetime import timezone
import pytz
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
from streamlit.runtime.scriptrunner import add_script_run_ctx, get_script_run_ctx
from PIL import Image

# --- 1. ç¶²é è¨­å®š ---
st.set_page_config(page_title="ä¸­å£¢å®¶å•†ï¼Œè¡›æ„›è€Œç”Ÿ V3.9", layout="wide", page_icon="ğŸ§¹")

# --- 2. æ ¸å¿ƒåƒæ•¸èˆ‡å…¨åŸŸè¨­å®š ---
try:
    TW_TZ = pytz.timezone('Asia/Taipei')
    MAX_IMAGE_BYTES = 10 * 1024 * 1024
    QUEUE_DB_PATH = "task_queue_v4_wal.db"
    IMG_DIR = "evidence_photos"
    os.makedirs(IMG_DIR, exist_ok=True)
    
    SHEET_URL = "https://docs.google.com/spreadsheets/d/11BXtN3aevJls6Q2IR_IbT80-9XvhBkjbTCgANmsxqkg/edit"
    SHEET_TABS = {
        "main": "main_data", "settings": "settings", "roster": "roster",
        "inspectors": "inspectors", "duty": "duty", "teachers": "teachers",
        "appeals": "appeals", "holidays": "holidays", "service_hours": "service_hours",
        "office_areas": "office_areas"
    }

    EXPECTED_COLUMNS = [
        "æ—¥æœŸ", "é€±æ¬¡", "ç­ç´š", "è©•åˆ†é …ç›®", "æª¢æŸ¥äººå“¡",
        "å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸",
        "å‚™è¨»", "é•è¦ç´°é …", "ç…§ç‰‡è·¯å¾‘", "ç™»éŒ„æ™‚é–“", "ä¿®æ­£", "æ™¨æƒæœªåˆ°è€…", "ç´€éŒ„ID"
    ]
    APPEAL_COLUMNS = ["ç”³è¨´æ—¥æœŸ", "ç­ç´š", "é•è¦æ—¥æœŸ", "é•è¦é …ç›®", "åŸå§‹æ‰£åˆ†", "ç”³è¨´ç†ç”±", "ä½è­‰ç…§ç‰‡", "è™•ç†ç‹€æ…‹", "ç™»éŒ„æ™‚é–“", "å°æ‡‰ç´€éŒ„ID"]

    # ==========================================
    # SRE Utils: é‡è©¦æ©Ÿåˆ¶
    # ==========================================
    def execute_with_retry(func, max_retries=5, base_delay=1.0):
        for attempt in range(max_retries):
            try:
                time.sleep(0.3 + random.uniform(0, 0.2)) 
                return func()
            except Exception as e:
                error_str = str(e).lower()
                is_retryable = any(x in error_str for x in ['429', '500', '503', 'quota', 'rate limit', 'timed out', 'connection'])
                if is_retryable and attempt < max_retries - 1:
                    sleep_time = (base_delay * (2 ** attempt)) + random.uniform(0, 1)
                    time.sleep(sleep_time)
                else: raise e

    # ==========================================
    # Google é€£ç·šèˆ‡åœ–ç‰‡å£“ç¸®
    # ==========================================
    @st.cache_resource
    def get_credentials():
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        if "gcp_service_account" not in st.secrets:
            st.error("âŒ æ‰¾ä¸åˆ° secrets è¨­å®š")
            return None
        return ServiceAccountCredentials.from_json_keyfile_dict(dict(st.secrets["gcp_service_account"]), scope)

    def get_gspread_client():
        creds = get_credentials()
        return gspread.authorize(creds) if creds else None

    def get_drive_service():
        creds = get_credentials()
        return build('drive', 'v3', credentials=creds, cache_discovery=False) if creds else None

    def get_worksheet(tab_name):
        client = get_gspread_client()
        if not client: return None
        sheet = client.open_by_url(SHEET_URL)
        for attempt in range(3):
            try:
                try: return sheet.worksheet(tab_name)
                except gspread.WorksheetNotFound:
                    cols = 20 if tab_name != "appeals" else 15
                    ws = sheet.add_worksheet(title=tab_name, rows=500, cols=cols)
                    if tab_name == "appeals": ws.append_row(APPEAL_COLUMNS)
                    if tab_name == "service_hours": ws.append_row(["æ—¥æœŸ", "å­¸è™Ÿ", "ç­ç´š", "é¡åˆ¥", "æ™‚æ•¸", "ç´€éŒ„ID"])
                    if tab_name == "holidays": ws.append_row(["æ—¥æœŸ", "èªªæ˜"])
                    if tab_name == "office_areas": ws.append_row(["å€åŸŸåç¨±", "è² è²¬ç­ç´š"])
                    return ws
            except Exception as e:
                if "429" in str(e): time.sleep(2 * (attempt + 1)); continue
                else: return None
        return None

    def compress_image_bytes(file_bytes, quality=70):
        try:
            img = Image.open(io.BytesIO(file_bytes))
            if img.mode != "RGB": img = img.convert("RGB")
            if img.width > 1600:
                ratio = 1600 / float(img.width)
                img = img.resize((1600, int(img.height * ratio)), Image.Resampling.LANCZOS)
            out_buffer = io.BytesIO()
            img.save(out_buffer, format="JPEG", quality=quality, optimize=True)
            out_buffer.seek(0)
            return out_buffer
        except: return io.BytesIO(file_bytes)

    def upload_image_to_drive(file_obj, filename):
        def _upload_action():
            service = get_drive_service()
            folder_id = st.secrets["system_config"]["drive_folder_id"]
            file = service.files().create(
                body={'name': filename, 'parents': [folder_id]},
                media_body=MediaIoBaseUpload(file_obj, mimetype='image/jpeg', resumable=True),
                fields='id', supportsAllDrives=True
            ).execute()
            try: service.permissions().create(fileId=file.get('id'), body={'role': 'reader', 'type': 'anyone'}).execute()
            except: pass 
            return f"https://drive.google.com/thumbnail?id={file.get('id')}&sz=w1000"
        return execute_with_retry(_upload_action)

    def clean_id(val):
        try: return str(int(float(val))).strip()
        except: return str(val).strip()

    # ==========================================
    # SQLite èƒŒæ™¯ä½‡åˆ—
    # ==========================================
    _queue_lock = threading.Lock()

    @st.cache_resource
    def get_queue_connection():
        conn = sqlite3.connect(QUEUE_DB_PATH, check_same_thread=False, timeout=30.0, isolation_level="IMMEDIATE")
        try: conn.execute("PRAGMA journal_mode=WAL;"); conn.execute("PRAGMA busy_timeout=30000;")
        except: pass
        conn.execute("CREATE TABLE IF NOT EXISTS task_queue (id TEXT PRIMARY KEY, task_type TEXT, created_ts TEXT, payload_json TEXT, status TEXT, attempts INTEGER, last_error TEXT)")
        conn.commit()
        return conn

    def enqueue_task(task_type, payload):
        conn = get_queue_connection()
        task_id = str(uuid.uuid4())
        with _queue_lock:
            conn.execute("INSERT INTO task_queue VALUES (?, ?, ?, ?, 'PENDING', 0, NULL)",
                (task_id, task_type, datetime.now(timezone.utc).isoformat(), json.dumps(payload, ensure_ascii=False)))
            conn.commit()
        return task_id

    def get_queue_metrics():
        conn = get_queue_connection()
        metrics = {"pending": 0, "retry": 0, "failed": 0, "oldest_pending_sec": 0, "recent_errors": []}
        with _queue_lock:
            cur = conn.cursor()
            cur.execute("SELECT status, COUNT(*) FROM task_queue GROUP BY status")
            for s, c in cur.fetchall():
                if s == 'PENDING': metrics["pending"] = c
                elif s == 'RETRY': metrics["retry"] = c
                elif s == 'FAILED': metrics["failed"] = c
            
            cur.execute("SELECT MIN(created_ts) FROM task_queue WHERE status IN ('PENDING', 'RETRY')")
            oldest = cur.fetchone()[0]
            if oldest:
                try: metrics["oldest_pending_sec"] = (datetime.now(pytz.utc) - datetime.fromisoformat(oldest.replace("Z", "+00:00"))).total_seconds()
                except: pass
            cur.execute("SELECT last_error, created_ts FROM task_queue WHERE status='FAILED' OR status='RETRY' ORDER BY created_ts DESC LIMIT 5")
            metrics["recent_errors"] = cur.fetchall()
        return metrics

    def fetch_next_task(max_attempts=6):
        conn = get_queue_connection()
        with _queue_lock:
            cur = conn.cursor()
            cur.execute("SELECT id, task_type, created_ts, payload_json, status, attempts, last_error FROM task_queue WHERE status IN ('PENDING', 'RETRY') AND attempts < ? ORDER BY created_ts ASC LIMIT 1", (max_attempts,))
            row = cur.fetchone()
            if not row: return None
            cur.execute("UPDATE task_queue SET status = 'IN_PROGRESS', attempts = attempts + 1 WHERE id = ?", (row[0],))
            conn.commit()
            return {"id": row[0], "task_type": row[1], "payload": json.loads(row[3]) if row[3] else {}, "attempts": row[5] + 1}

    def update_task_status(task_id, status, attempts, last_error):
        with _queue_lock:
            get_queue_connection().execute("UPDATE task_queue SET status = ?, attempts = ?, last_error = ? WHERE id = ?", (status, attempts, last_error, task_id))
            get_queue_connection().commit()

    # ==========================================
    # èƒŒæ™¯è™•ç†é‚è¼¯
    # ==========================================
    def process_task(task):
        task_type, payload = task["task_type"], task["payload"]
        entry = payload.get("entry", {})

        try:
            image_paths, filenames, drive_links = payload.get("image_paths", []), payload.get("filenames", []), []
            for path, fname in zip(image_paths, filenames):
                if os.path.exists(path):
                    with open(path, "rb") as f:
                        drive_links.append(upload_image_to_drive(compress_image_bytes(f.read()), fname) or "UPLOAD_FAILED_API")
            if drive_links: entry["ç…§ç‰‡è·¯å¾‘"] = ";".join(drive_links)

            if task_type in ["main_entry", "volunteer_report"]:
                def _main_act():
                    ws = get_worksheet(SHEET_TABS["main"])
                    if not ws.get_all_values(): ws.append_row(EXPECTED_COLUMNS)
                    ws.append_row([str(entry.get(col, "")).upper() if isinstance(entry.get(col, ""), bool) else str(entry.get(col, "")) for col in EXPECTED_COLUMNS])
                execute_with_retry(_main_act)

                inspector_name = entry.get("æª¢æŸ¥äººå“¡", "")
                if "å­¸è™Ÿ:" in inspector_name:
                    sid = inspector_name.split("å­¸è™Ÿ:")[1].strip()
                    execute_with_retry(lambda: get_worksheet(SHEET_TABS["service_hours"]).append_row([entry.get("æ—¥æœŸ"), sid, "", "è¡›ç”Ÿç³¾å¯Ÿ", 0.5, uuid.uuid4().hex[:8]]))
                
                if task_type == "volunteer_report":
                    for sid in payload.get("student_list", []):
                        execute_with_retry(lambda: get_worksheet(SHEET_TABS["service_hours"]).append_row([entry.get("æ—¥æœŸ", str(date.today())), sid, entry.get("ç­ç´š", ""), payload.get("custom_category", "æ™¨æƒå¿—å·¥"), payload.get("custom_hours", 0.5), uuid.uuid4().hex[:8]]))

            elif task_type == "appeal_entry":
                image_info = payload.get("image_file")
                if image_info and os.path.exists(image_info["path"]):
                    with open(image_info["path"], "rb") as f:
                        entry["ä½è­‰ç…§ç‰‡"] = upload_image_to_drive(compress_image_bytes(f.read()), image_info["filename"])
                execute_with_retry(lambda: get_worksheet(SHEET_TABS["appeals"]).append_row([str(entry.get(c, "")) for c in APPEAL_COLUMNS]))
            return True, None
        except Exception as e: return False, str(e)

    def background_worker(stop_event=None):
        try: add_script_run_ctx(threading.current_thread(), get_script_run_ctx())
        except: pass
        while True:
            if stop_event and stop_event.is_set(): break
            try:
                task = fetch_next_task()
                if not task: time.sleep(2.0); continue
                ok, err = process_task(task)
                
                try:
                    paths = task["payload"].get("image_paths", []) + ([task["payload"]["image_file"]["path"]] if "image_file" in task["payload"] else [])
                    for p in paths:
                        if p and os.path.exists(p): os.remove(p)
                except: pass

                update_task_status(task["id"], "DONE" if ok else ("FAILED" if task["attempts"] >= 6 else "RETRY"), task["attempts"], err)
                time.sleep(0.5)
            except Exception as e: time.sleep(3.0)

    @st.cache_resource
    def ensure_worker_started():
        stop_event = threading.Event()
        t = threading.Thread(target=background_worker, args=(stop_event,), daemon=True)
        add_script_run_ctx(t)
        t.start()
        return stop_event
    _ = ensure_worker_started()

    # ==========================================
    # å‰ç«¯è³‡æ–™è®€å–
    # ==========================================
    @st.cache_data(ttl=21600)
    def load_holidays():
        ws = get_worksheet(SHEET_TABS["holidays"])
        if not ws: return []
        try: return [pd.to_datetime(str(r.get("æ—¥æœŸ", "")).strip()).date() for r in ws.get_all_records() if str(r.get("æ—¥æœŸ", "")).strip()]
        except: return []

    def is_within_appeal_period(violation_date, appeal_days=3):
        vd = pd.to_datetime(violation_date).date() if isinstance(violation_date, str) else violation_date
        holidays, today, current_date, workdays = load_holidays(), date.today(), vd, 0
        for _ in range(14): 
            if workdays >= appeal_days: break
            current_date += timedelta(days=1)
            if current_date.weekday() < 5 and current_date not in holidays: workdays += 1
        return today <= current_date

    @st.cache_data(ttl=300)
    def load_main_data():
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return pd.DataFrame(columns=EXPECTED_COLUMNS)
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return pd.DataFrame(columns=EXPECTED_COLUMNS)
            if "ç­ç´š" in df.columns: df["ç­ç´š"] = df["ç­ç´š"].astype(str).str.strip()
            for col in EXPECTED_COLUMNS:
                if col not in df.columns: df[col] = ""
            if "ç´€éŒ„ID" not in df.columns: df["ç´€éŒ„ID"] = df.index.astype(str)
            for col in ["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸", "é€±æ¬¡"]:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
            if "ä¿®æ­£" in df.columns: df["ä¿®æ­£"] = df["ä¿®æ­£"].astype(str).apply(lambda x: True if x.upper() == "TRUE" else False)
            return df[EXPECTED_COLUMNS]
        except: return pd.DataFrame(columns=EXPECTED_COLUMNS)

    @st.cache_data(ttl=21600)
    def load_roster_dict():
        ws = get_worksheet(SHEET_TABS["roster"])
        if not ws: return {}
        try:
            df = pd.DataFrame(ws.get_all_records())
            id_c, cls_c = next((c for c in df.columns if "å­¸è™Ÿ" in c), None), next((c for c in df.columns if "ç­ç´š" in c), None)
            return {clean_id(row[id_c]): str(row[cls_c]).strip() for _, row in df.iterrows()} if id_c and cls_c else {}
        except: return {}
    
    @st.cache_data(ttl=3600)
    def load_sorted_classes():
        ws = get_worksheet(SHEET_TABS["roster"])
        if not ws: return [], []
        try:
            records = ws.get_all_records()
            if not records:
                all_vals = ws.get_all_values()
                if len(all_vals) > 1: records = [dict(zip(all_vals[0], row)) for row in all_vals[1:]]
            df = pd.DataFrame(records)
            class_col = next((c for c in df.columns if "ç­ç´š" in str(c).strip()), None)
            if not class_col: return [], []
            unique = [c for c in df[class_col].astype(str).str.strip().unique().tolist() if c]
            dept_order = {"å•†": 1, "è‹±": 2, "è³‡": 3, "å®¶": 4, "æœ": 5}
            def get_sort_key(n):
                g = 1 if "ä¸€" in n or "1" in n else (2 if "äºŒ" in n or "2" in n else (3 if "ä¸‰" in n or "3" in n else 99))
                return (g, next((v for k, v in dept_order.items() if k in n), 99), n)
            sorted_all = sorted(unique, key=get_sort_key)
            return sorted_all, [{"grade": f"{get_sort_key(c)[0]}å¹´ç´š" if get_sort_key(c)[0]!=99 else "å…¶ä»–", "name": c} for c in sorted_all]
        except: return [], []

    @st.cache_data(ttl=60)
    def get_daily_duty(target_date):
        ws = get_worksheet(SHEET_TABS["duty"])
        if not ws: return pd.DataFrame(), "error"
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return pd.DataFrame(), "no_data"
            date_col = next((c for c in df.columns if "æ—¥æœŸ" in c), None)
            if date_col:
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.date
                return df[df[date_col] == (target_date if isinstance(target_date, date) else target_date.date())], "success"
            return pd.DataFrame(), "missing_cols"
        except: return pd.DataFrame(), "error"

    @st.cache_data(ttl=3600)
    def load_office_area_map():
        ws = get_worksheet(SHEET_TABS["office_areas"])
        if not ws: return {}
        try: return {str(r.get("å€åŸŸåç¨±", "")).strip(): str(r.get("è² è²¬ç­ç´š", "")).strip() for r in ws.get_all_records() if str(r.get("å€åŸŸåç¨±", "")).strip()}
        except: return {}

    @st.cache_data(ttl=21600)
    def load_settings():
        ws = get_worksheet(SHEET_TABS["settings"])
        config = {"semester_start": "2025-08-25", "standard_n": 4}
        if ws:
            try:
                for row in ws.get_all_values():
                    if len(row)>=2: config[row[0]] = int(row[1]) if row[0] == "standard_n" else row[1]
            except: pass
        return config

    def save_setting(key, val):
        ws = get_worksheet(SHEET_TABS["settings"])
        if ws:
            try:
                cell = ws.find(key)
                if cell: ws.update_cell(cell.row, cell.col+1, val)
                else: ws.append_row([key, val])
                st.cache_data.clear(); return True
            except: return False
        return False

    @st.cache_data(ttl=60)
    def load_appeals():
        ws = get_worksheet(SHEET_TABS["appeals"])
        if not ws: return pd.DataFrame(columns=APPEAL_COLUMNS)
        try:
            df = pd.DataFrame(ws.get_all_records())
            for col in APPEAL_COLUMNS:
                if col not in df.columns: df[col] = "å¾…è™•ç†" if col == "è™•ç†ç‹€æ…‹" else ""
            return df[APPEAL_COLUMNS]
        except: return pd.DataFrame(columns=APPEAL_COLUMNS)

    def save_appeal(entry, proof_file=None):
        image_info = None
        if proof_file:
            try:
                data = proof_file.read()
                if len(data) > MAX_IMAGE_BYTES: st.error("ç…§ç‰‡éå¤§"); return False
                fname = f"Appeal_{entry.get('ç­ç´š', '')}_{datetime.now(TW_TZ).strftime('%H%M%S')}.jpg"
                l_path = os.path.join(IMG_DIR, f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}_{fname}")
                with open(l_path, "wb") as f: f.write(data)
                image_info = {"path": l_path, "filename": fname}
            except Exception as e: st.error(f"å¯«å…¥å¤±æ•—: {e}"); return False

        entry.update({"ç”³è¨´æ—¥æœŸ": entry.get("ç”³è¨´æ—¥æœŸ", datetime.now(TW_TZ).strftime("%Y-%m-%d")), "è™•ç†ç‹€æ…‹": entry.get("è™•ç†ç‹€æ…‹", "å¾…è™•ç†"),
                      "ç™»éŒ„æ™‚é–“": entry.get("ç™»éŒ„æ™‚é–“", datetime.now(TW_TZ).strftime("%Y-%m-%d %H:%M:%S")), 
                      "ç”³è¨´ID": entry.get("ç”³è¨´ID", datetime.now(TW_TZ).strftime("%Y%m%d%H%M%S") + "_" + uuid.uuid4().hex[:4]),
                      "ä½è­‰ç…§ç‰‡": entry.get("ä½è­‰ç…§ç‰‡", "")})
        enqueue_task("appeal_entry", {"entry": entry, "image_file": image_info})
        st.success("ğŸ“© ç”³è¨´å·²æ’å…¥èƒŒæ™¯è™•ç†")
        return True
    
    def update_appeal_status(idx, status, record_id):
        ws_appeals, ws_main = get_worksheet(SHEET_TABS["appeals"]), get_worksheet(SHEET_TABS["main"])
        try:
            data = ws_appeals.get_all_records()
            t_row = next((i + 2 for i, r in enumerate(data) if str(r.get("å°æ‡‰ç´€éŒ„ID")) == str(record_id) and str(r.get("è™•ç†ç‹€æ…‹")) == "å¾…è™•ç†"), None)
            if t_row:
                ws_appeals.update_cell(t_row, APPEAL_COLUMNS.index("è™•ç†ç‹€æ…‹") + 1, status)
                if status == "å·²æ ¸å¯":
                    m_data = ws_main.get_all_records()
                    m_row = next((j + 2 for j, mr in enumerate(m_data) if str(mr.get("ç´€éŒ„ID")) == str(record_id)), None)
                    if m_row: ws_main.update_cell(m_row, EXPECTED_COLUMNS.index("ä¿®æ­£") + 1, "TRUE")
                st.cache_data.clear(); return True, "æ›´æ–°æˆåŠŸ"
            return False, "æ‰¾ä¸åˆ°å°æ‡‰çš„ç”³è¨´åˆ—"
        except Exception as e: return False, str(e)
    
    @st.cache_data(ttl=21600)
    def load_teacher_emails():
        ws = get_worksheet(SHEET_TABS["teachers"])
        if not ws: return {}
        try:
            df = pd.DataFrame(ws.get_all_records())
            c_col, m_col, n_col = next((c for c in df.columns if "ç­ç´š" in c), None), next((c for c in df.columns if "Email" in c or "ä¿¡ç®±" in c), None), next((c for c in df.columns if "å°å¸«" in c or "å§“å" in c), None)
            return {str(row[c_col]).strip(): {"email": str(row[m_col]).strip(), "name": str(row[n_col]).strip() if n_col else "è€å¸«"} for _, row in df.iterrows() if c_col and m_col and "@" in str(row[m_col])}
        except: return {}

    def send_bulk_emails(email_list):
        s_email, s_pwd = st.secrets["system_config"]["smtp_email"], st.secrets["system_config"]["smtp_password"]
        if not s_email or not s_pwd: return 0, "Secrets æœªè¨­å®š Email"
        cnt = 0
        try:
            server = smtplib.SMTP('smtp.gmail.com', 587); server.starttls(); server.login(s_email, s_pwd)
            for item in email_list:
                try:
                    msg = MIMEMultipart()
                    msg['From'], msg['To'], msg['Subject'] = s_email, item['email'], item['subject']
                    msg.attach(MIMEText(item['body'], 'plain'))
                    server.sendmail(s_email, item['email'], msg.as_string())
                    cnt += 1
                except: pass
            server.quit(); return cnt, "ç™¼é€ä½œæ¥­çµæŸ"
        except Exception as e: return cnt, str(e)

    def delete_rows_by_ids(ids):
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return False
        try:
            rows = sorted([i + 2 for i, r in enumerate(ws.get_all_records()) if str(r.get("ç´€éŒ„ID")) in ids], reverse=True)
            for r in rows: ws.delete_rows(r)
            time.sleep(0.8); st.cache_data.clear(); return True
        except Exception as e: st.error(f"åˆªé™¤å¤±æ•—: {e}"); return False

    @st.cache_data(ttl=21600)
    def load_inspector_list():
        ws = get_worksheet(SHEET_TABS["inspectors"])
        default = [{"label": "æ¸¬è©¦äººå“¡", "allowed_roles": ["å…§æƒæª¢æŸ¥"], "assigned_classes": [], "id_prefix": "æ¸¬"}]
        if not ws: return default
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return default
            inspectors, id_c, r_c, s_c = [], next((c for c in df.columns if "å­¸è™Ÿ" in c or "ç·¨è™Ÿ" in c), None), next((c for c in df.columns if "è² è²¬" in c or "é …ç›®" in c), None), next((c for c in df.columns if "ç­ç´š" in c or "ç¯„åœ" in c), None)
            if id_c:
                for _, row in df.iterrows():
                    sid, s_role = clean_id(row[id_c]), str(row[r_c]).strip() if r_c else ""
                    allowed = ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥", "æ™¨é–“æ‰“æƒ"] if "çµ„é•·" in s_role else (["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥"] if "æ©Ÿå‹•" in s_role else [r for r in ["å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥", "æ™¨é–“æ‰“æƒ", "å…§æƒæª¢æŸ¥"] if r[:2] in s_role])
                    s_classes = [c.strip() for c in str(row[s_c]).replace("ã€", ";").replace(",", ";").split(";") if c.strip()] if s_c and str(row[s_c]) else []
                    inspectors.append({"label": f"å­¸è™Ÿ: {sid}", "allowed_roles": allowed or ["å…§æƒæª¢æŸ¥"], "assigned_classes": s_classes, "id_prefix": sid[0] if sid else "X"})
            return inspectors or default
        except: return default

    def check_duplicate_record(df, check_date, inspector, role, target_class=None):
        if df.empty: return False
        try:
            mask = (df["æ—¥æœŸ"].astype(str) == str(check_date)) & (df["æª¢æŸ¥äººå“¡"] == inspector) & (df["è©•åˆ†é …ç›®"] == role)
            if target_class: mask &= (df["ç­ç´š"] == target_class)
            return not df[mask].empty
        except: return False

    def save_entry(new_entry, uploaded_files=None, student_list=None, custom_hours=0.5, custom_category="æ™¨æƒå¿—å·¥"):
        new_entry["æ—¥æœŸ"] = str(new_entry.get("æ—¥æœŸ", str(date.today())))
        new_entry["ç´€éŒ„ID"] = new_entry.get("ç´€éŒ„ID", f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}")

        image_paths, file_names = [], []
        if uploaded_files:
            for i, up_file in enumerate(uploaded_files):
                if not up_file: continue
                try:
                    data = up_file.getvalue()
                    if len(data) > MAX_IMAGE_BYTES: st.warning(f"æª”æ¡ˆç•¥é (éå¤§): {up_file.name}"); continue
                    fname = f"{new_entry['ç´€éŒ„ID']}_{i}.jpg"
                    local_path = os.path.join(IMG_DIR, fname)
                    with open(local_path, "wb") as f: f.write(data)
                    image_paths.append(local_path); file_names.append(fname)
                except Exception as e: print(f"Save Error: {e}")

        payload = {
            "entry": new_entry, "image_paths": image_paths, "filenames": file_names,
            "student_list": student_list or [], "custom_hours": custom_hours, "custom_category": custom_category
        }
        return enqueue_task("volunteer_report" if student_list is not None else "main_entry", payload)

    def load_full_semester_data_for_export():
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return pd.DataFrame(columns=EXPECTED_COLUMNS)
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return pd.DataFrame(columns=EXPECTED_COLUMNS)
            for col in EXPECTED_COLUMNS:
                if col not in df.columns: df[col] = ""
            for col in ["å‚™è¨»", "é•è¦ç´°é …", "ç­ç´š", "æª¢æŸ¥äººå“¡", "ä¿®æ­£", "æ™¨æƒæœªåˆ°è€…", "ç…§ç‰‡è·¯å¾‘", "ç´€éŒ„ID"]:
                if col in df.columns: df[col] = df[col].fillna("").astype(str)
            for col in ["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸", "é€±æ¬¡"]:
                if col in df.columns: df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)
            return df[EXPECTED_COLUMNS]
        except: return pd.DataFrame()

    # ==========================================
    # 3. ä¸»ç¨‹å¼ UI å•Ÿå‹•å‰æº–å‚™
    # ==========================================
    
    # ğŸš¨ [ä¿®æ­£é» 1] è£œå›è¢«åˆªæ‰çš„ now_tw å®šç¾©
    now_tw = datetime.now(TW_TZ)
    today_tw = now_tw.date()
    
    SYSTEM_CONFIG, ROSTER_DICT, INSPECTOR_LIST, TEACHER_MAILS = load_settings(), load_roster_dict(), load_inspector_list(), load_teacher_emails()
    all_classes, structured_classes = load_sorted_classes()
    if not all_classes: all_classes, structured_classes = ["æ¸¬è©¦ç­ç´š"], [{"grade": "å…¶ä»–", "name": "æ¸¬è©¦ç­ç´š"}]
    grades = sorted(list(set([c["grade"] for c in structured_classes])))
    
    def get_week_num(d):
        try:
            start = datetime.strptime(SYSTEM_CONFIG["semester_start"], "%Y-%m-%d").date()
            if isinstance(d, datetime): d = d.date()
            return max(0, ((d - start).days // 7) + 1)
        except: return 0

    st.sidebar.title("ğŸ« åŠŸèƒ½é¸å–®")
    app_mode = st.sidebar.radio("è«‹é¸æ“‡æ¨¡å¼", ["ç³¾å¯Ÿåº•å®¶ğŸ‘€", "ç­ç´šè² è²¬äººğŸ¥¸", "æ™¨æƒå¿—å·¥éšŠğŸ§¹", "çµ„é•·ã„‰çª©ğŸ’ƒ"])

    with st.sidebar.expander("ğŸ”§ ç³»çµ±ç‹€æ…‹ (åå–®ç•°å¸¸è«‹é»æ­¤)", expanded=True):
        if get_gspread_client(): st.success("âœ… Google Sheets é€£ç·šæ­£å¸¸")
        else: st.error("âŒ Google Sheets é€£ç·šå¤±æ•—")
        if st.button("ğŸ”„ é‡è®€åå–® (æ¸…é™¤å¿«å–)"): st.cache_data.clear(); st.rerun()

    # --- Mode 1: ç³¾å¯Ÿè©•åˆ† ---
    if app_mode == "ç³¾å¯Ÿåº•å®¶ğŸ‘€":
        st.title("ğŸ“ è¡›ç”Ÿç³¾å¯Ÿè©•åˆ†ç³»çµ±")
        if "team_logged_in" not in st.session_state: st.session_state["team_logged_in"] = False
        
        if not st.session_state["team_logged_in"]:
            with st.expander("ğŸ” èº«ä»½é©—è­‰", expanded=True):
                if st.button("ç™»å…¥") if st.text_input("è«‹è¼¸å…¥éšŠä¼é€šè¡Œç¢¼", type="password") == st.secrets["system_config"]["team_password"] else False:
                    st.session_state["team_logged_in"] = True; st.rerun()
        
        if st.session_state["team_logged_in"]:
            prefixes = sorted(list(set([p["id_prefix"] for p in INSPECTOR_LIST])))
            if not prefixes: st.warning("æ‰¾ä¸åˆ°ç³¾å¯Ÿåå–®")
            else:
                sel_p = st.radio("æ­¥é©Ÿ 1ï¼šé¸æ“‡é–‹é ­", [f"{p}é–‹é ­" for p in prefixes], horizontal=True, key="m1_p_radio")[0]
                inspector_name = st.radio("æ­¥é©Ÿ 2ï¼šé»é¸èº«ä»½", [p["label"] for p in INSPECTOR_LIST if p["id_prefix"] == sel_p], key="m1_name_radio")
                curr_inspector = next((p for p in INSPECTOR_LIST if p["label"] == inspector_name), {})
                allowed_roles = [r for r in curr_inspector.get("allowed_roles", ["å…§æƒæª¢æŸ¥"]) if r != "æ™¨é–“æ‰“æƒ"] or ["å…§æƒæª¢æŸ¥"]
                
                st.markdown("---")
                c_d, c_r = st.columns(2)
                input_date = c_d.date_input("æª¢æŸ¥æ—¥æœŸ", today_tw)
                role = c_r.radio("æª¢æŸ¥é …ç›®", allowed_roles, horizontal=True, key="m1_role_radio") if len(allowed_roles)>1 else allowed_roles[0]
                week_num = get_week_num(input_date)
                main_df = load_main_data()

                if role == "åƒåœ¾/å›æ”¶æª¢æŸ¥":
                    st.info("ğŸ—‘ï¸ è³‡æ”¶å ´å°ˆç”¨ï¼šè² é¢è¡¨åˆ—æ¨¡å¼ (æœ‰é•è¦æ‰æ‰“å‹¾ï¼Œç³»çµ±å°‡è‡ªå‹•è¨˜éŒ„æ‰£åˆ†)")
                    
                    sel_filter = st.radio("ç¯©é¸æª¢æŸ¥å°è±¡", ["å„è™•å®¤ (å¤–æƒ)"] + grades, horizontal=True, key="m1_trash_filter")
                    today_records = main_df[(main_df["æ—¥æœŸ"].astype(str) == str(input_date)) & (main_df["è©•åˆ†é …ç›®"] == "åƒåœ¾/å›æ”¶æª¢æŸ¥")] if not main_df.empty else pd.DataFrame()
                    rows = []
                    
                    if sel_filter == "å„è™•å®¤ (å¤–æƒ)":
                        office_map = load_office_area_map()
                        for off_name in list(office_map.keys()) or ["æ•™å‹™è™•", "å­¸å‹™è™•", "ç¸½å‹™è™•", "è¼”å°å®¤", "åœ–æ›¸é¤¨"]:
                            cls_name = office_map.get(off_name, "æœªè¨­å®š")
                            is_gen_bad = any(f"å¤–æƒ({off_name})" in str(r["å‚™è¨»"]) and "æœªåˆ†é¡" in str(r["å‚™è¨»"]) and "ä¸€èˆ¬" in str(r["å‚™è¨»"]) for _, r in today_records.iterrows()) if not today_records.empty else False
                            is_recyc_bad = any(f"å¤–æƒ({off_name})" in str(r["å‚™è¨»"]) and ("æœªåˆ†é¡" in str(r["å‚™è¨»"]) or "æœªå€’" in str(r["å‚™è¨»"])) and "å›æ”¶" in str(r["å‚™è¨»"]) for _, r in today_records.iterrows()) if not today_records.empty else False
                            rows.append({"è™•å®¤/å€åŸŸ": off_name, "è² è²¬ç­ç´š": cls_name, "ä¸€èˆ¬-æœªåˆ†é¡": is_gen_bad, "å›æ”¶-æœªå€’/æœªåˆ†é¡": is_recyc_bad})
                            
                        edited_df = st.data_editor(pd.DataFrame(rows), column_config={"è™•å®¤/å€åŸŸ": st.column_config.TextColumn(disabled=True), "è² è²¬ç­ç´š": st.column_config.TextColumn(disabled=True)}, hide_index=True, use_container_width=True, key="ed_offices")
                        if st.button("ğŸ’¾ ç™»è¨˜é•è¦ (å„è™•å®¤)"):
                            cnt = 0
                            for _, row in edited_df.iterrows():
                                off, cls, gen_bad, recyc_bad = row["è™•å®¤/å€åŸŸ"], row["è² è²¬ç­ç´š"], row["ä¸€èˆ¬-æœªåˆ†é¡"], row["å›æ”¶-æœªå€’/æœªåˆ†é¡"]
                                orig = next((x for x in rows if x["è™•å®¤/å€åŸŸ"] == off), None)
                                base = {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç­ç´š": cls, "è©•åˆ†é …ç›®": role, "åƒåœ¾å…§æƒåŸå§‹åˆ†": 0, "åƒåœ¾å¤–æƒåŸå§‹åˆ†": 1}
                                if gen_bad and not orig["ä¸€èˆ¬-æœªåˆ†é¡"]: save_entry({**base, "å‚™è¨»": f"å¤–æƒ({off})-ä¸€èˆ¬æœªåˆ†é¡", "é•è¦ç´°é …": "ä¸€èˆ¬åƒåœ¾"}); cnt += 1
                                if recyc_bad and not orig["å›æ”¶-æœªå€’/æœªåˆ†é¡"]: save_entry({**base, "å‚™è¨»": f"å¤–æƒ({off})-å›æ”¶æœªå€’/æœªåˆ†é¡", "é•è¦ç´°é …": "è³‡æºå›æ”¶"}); cnt += 1
                            if cnt: st.success(f"âœ… å·²ç™»è¨˜ {cnt} ç­†é•è¦ï¼"); time.sleep(1); st.rerun()

                    else:
                        for cls_name in [c["name"] for c in structured_classes if c["grade"] == sel_filter]:
                            cls_rec = today_records[today_records["ç­ç´š"] == cls_name] if not today_records.empty else pd.DataFrame()
                            is_gen_bad = any("å…§æƒ" in str(r["å‚™è¨»"]) and "æœªåˆ†é¡" in str(r["å‚™è¨»"]) and "ä¸€èˆ¬" in str(r["å‚™è¨»"]) for _, r in cls_rec.iterrows()) if not cls_rec.empty else False
                            is_recyc_bad = any("å…§æƒ" in str(r["å‚™è¨»"]) and ("æœªåˆ†é¡" in str(r["å‚™è¨»"]) or "æœªå€’" in str(r["å‚™è¨»"])) and "å›æ”¶" in str(r["å‚™è¨»"]) for _, r in cls_rec.iterrows()) if not cls_rec.empty else False
                            rows.append({"ç­ç´š": cls_name, "ä¸€èˆ¬-æœªåˆ†é¡": is_gen_bad, "å›æ”¶-æœªå€’/æœªåˆ†é¡": is_recyc_bad})
                            
                        edited_df = st.data_editor(pd.DataFrame(rows), column_config={"ç­ç´š": st.column_config.TextColumn(disabled=True)}, hide_index=True, use_container_width=True, key=f"ed_{sel_filter}")
                        if st.button(f"ğŸ’¾ ç™»è¨˜é•è¦ ({sel_filter})"):
                            cnt = 0
                            for _, row in edited_df.iterrows():
                                cls, gen_bad, recyc_bad = row["ç­ç´š"], row["ä¸€èˆ¬-æœªåˆ†é¡"], row["å›æ”¶-æœªå€’/æœªåˆ†é¡"]
                                orig = next((x for x in rows if x["ç­ç´š"] == cls), None)
                                base = {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç­ç´š": cls, "è©•åˆ†é …ç›®": role, "åƒåœ¾å…§æƒåŸå§‹åˆ†": 1, "åƒåœ¾å¤–æƒåŸå§‹åˆ†": 0}
                                if gen_bad and not orig["ä¸€èˆ¬-æœªåˆ†é¡"]: save_entry({**base, "å‚™è¨»": "å…§æƒ-ä¸€èˆ¬æœªåˆ†é¡", "é•è¦ç´°é …": "ä¸€èˆ¬åƒåœ¾"}); cnt += 1
                                if recyc_bad and not orig["å›æ”¶-æœªå€’/æœªåˆ†é¡"]: save_entry({**base, "å‚™è¨»": "å…§æƒ-å›æ”¶æœªå€’/æœªåˆ†é¡", "é•è¦ç´°é …": "è³‡æºå›æ”¶"}); cnt += 1
                            if cnt: st.success(f"âœ… å·²ç™»è¨˜ {cnt} ç­†é•è¦ï¼"); time.sleep(1); st.rerun()

                else:
                    assigned_classes = curr_inspector.get("assigned_classes", [])
                    
                    # ğŸš¨ [ä¿®æ­£é» 2] è§£é–‹å°è‡´ç•¶æ©Ÿçš„ list comprehension radio å¯«æ³•
                    if assigned_classes:
                        sel_cls = st.radio("é¸æ“‡è² è²¬ç­ç´š", assigned_classes, key="m1_cls_assigned")
                    else:
                        temp_g = st.radio("æ­¥é©Ÿ A: é¸æ“‡å¹´ç´š", grades, horizontal=True, key="m1_grade_select")
                        f_cls_list = [c["name"] for c in structured_classes if c["grade"] == temp_g]
                        sel_cls = st.radio("æ­¥é©Ÿ B: é¸æ“‡ç­ç´š", f_cls_list, horizontal=True, key="m1_cls_select") if f_cls_list else None

                    if sel_cls:
                        st.divider()
                        if check_duplicate_record(main_df, input_date, inspector_name, role, sel_cls): st.warning(f"âš ï¸ ä»Šæ—¥å·²è©•é {sel_cls}ï¼")
                        with st.form("score_form", clear_on_submit=True):
                            in_s, out_s, ph_c, note = 0, 0, 0, ""
                            if st.radio("æª¢æŸ¥çµæœ", ["âŒ é•è¦", "âœ¨ ä¹¾æ·¨"], horizontal=True) == "âŒ é•è¦":
                                if role == "å…§æƒæª¢æŸ¥":
                                    in_s = st.number_input("å…§æƒæ‰£åˆ†", 0)
                                    note = " ".join([x for x in [st.selectbox("å€å¡Š", ["", "èµ°å»Š", "é»‘æ¿", "åœ°æ¿"]), st.selectbox("ç‹€æ³", ["", "é«’äº‚", "æ²’æ‹–åœ°"]), st.text_input("è£œå……")] if x])
                                else:
                                    out_s = st.number_input("å¤–æƒæ‰£åˆ†", 0)
                                    note = " ".join([x for x in [st.selectbox("å€åŸŸ", ["", "èµ°å»Š", "æ¨“æ¢¯", "å»æ‰€", "æ“å ´"]), st.selectbox("ç‹€æ³", ["", "å¾ˆé«’", "æ²’æƒ"]), st.text_input("è£œå……")] if x])
                            is_fix = st.checkbox("ğŸš© é€™æ˜¯ä¿®æ­£å–®")
                            files = st.file_uploader("ğŸ“¸ é•è¦ç…§ç‰‡", accept_multiple_files=True)
                            if st.form_submit_button("é€å‡º"):
                                if (in_s + out_s) > 0 and not files: st.error("æ‰£åˆ†éœ€ç…§ç‰‡")
                                else:
                                    save_entry({"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ä¿®æ­£": is_fix, "ç­ç´š": sel_cls, "è©•åˆ†é …ç›®": role, "å…§æƒåŸå§‹åˆ†": in_s, "å¤–æƒåŸå§‹åˆ†": out_s, "æ‰‹æ©Ÿäººæ•¸": ph_c, "å‚™è¨»": note}, uploaded_files=files)
                                    st.success("âœ… é€å‡ºæˆåŠŸï¼"); st.rerun()

    # --- Mode 2: ç­ç´šè² è²¬äºº ---
    elif app_mode == "ç­ç´šè² è²¬äººğŸ¥¸":
        st.title("ğŸ” ç­ç´šæˆç¸¾æŸ¥è©¢")
        df, appeals_df = load_main_data(), load_appeals()
        appeal_map = {str(r.get("å°æ‡‰ç´€éŒ„ID")): r.get("è™•ç†ç‹€æ…‹") for _, r in appeals_df.iterrows()} if not appeals_df.empty else {}
        
        # ğŸš¨ [ä¿®æ­£é» 2] è§£é–‹å°è‡´ç•¶æ©Ÿçš„ list comprehension radio å¯«æ³•
        sel_grade_m2 = st.radio("é¸æ“‡å¹´ç´š", grades, horizontal=True, key="m2_grade_select")
        cls_opts = [c["name"] for c in structured_classes if c["grade"] == sel_grade_m2]
        
        if cls_opts:
            cls = st.selectbox("é¸æ“‡ç­ç´š", cls_opts, key="m2_cls_select")
            if cls and not df.empty:
                for idx, r in df[df["ç­ç´š"] == cls].sort_values("ç™»éŒ„æ™‚é–“", ascending=False).iterrows():
                    trash_score = r['åƒåœ¾å…§æƒåŸå§‹åˆ†'] + r['åƒåœ¾å¤–æƒåŸå§‹åˆ†']
                    if trash_score == 0: trash_score = r['åƒåœ¾åŸå§‹åˆ†']
                    
                    tot = r['å…§æƒåŸå§‹åˆ†'] + r['å¤–æƒåŸå§‹åˆ†'] + trash_score + r['æ™¨é–“æ‰“æƒåŸå§‹åˆ†']
                    rid, ap_st = str(r['ç´€éŒ„ID']), appeal_map.get(str(r['ç´€éŒ„ID']))
                    icon = "âœ…" if ap_st=="å·²æ ¸å¯" else "ğŸš«" if ap_st=="å·²é§å›" else "â³" if ap_st=="å¾…è™•ç†" else "ğŸ› ï¸" if str(r['ä¿®æ­£'])=="TRUE" else ""
                    with st.expander(f"{icon} {r['æ—¥æœŸ']} - {r['è©•åˆ†é …ç›®']} (æ‰£:{tot})"):
                        st.write(f"å‚™è¨»: {r['å‚™è¨»']}")
                        if str(r['ç…§ç‰‡è·¯å¾‘']) and "http" in str(r['ç…§ç‰‡è·¯å¾‘']): st.image([p for p in str(r['ç…§ç‰‡è·¯å¾‘']).split(";") if "http" in p], width=200)
                        if not ap_st and is_within_appeal_period(r['æ—¥æœŸ']) and (tot > 0 or r['æ‰‹æ©Ÿäººæ•¸'] > 0):
                            with st.form(f"ap_{rid}"):
                                rsn, pf = st.text_area("ç†ç”±"), st.file_uploader("ä½è­‰", type=['jpg','png'])
                                if st.form_submit_button("ç”³è¨´") and rsn and pf:
                                    save_appeal({"ç­ç´š": cls, "é•è¦æ—¥æœŸ": str(r["æ—¥æœŸ"]), "é•è¦é …ç›®": r['è©•åˆ†é …ç›®'], "åŸå§‹æ‰£åˆ†": str(tot), "ç”³è¨´ç†ç”±": rsn, "å°æ‡‰ç´€éŒ„ID": rid}, pf)
                                    st.rerun()

    # --- Mode 3: æ™¨æƒå¿—å·¥éšŠ ---
    elif app_mode == "æ™¨æƒå¿—å·¥éšŠğŸ§¹":
        st.title("ğŸ§¹ æ™¨æƒå¿—å·¥å›å ±å°ˆå€")
        if now_tw.hour >= 16: st.error("ğŸš« ä»Šæ—¥å›å ±å·²æˆªæ­¢ (16:00)")
        else:
            my_cls = st.selectbox("é¸æ“‡ç­ç´š", all_classes, key="m3_cls_select")
            main_df = load_main_data()
            if not main_df[(main_df["æ—¥æœŸ"].astype(str)==str(today_tw)) & (main_df["ç­ç´š"]==my_cls) & (main_df["è©•åˆ†é …ç›®"]=="æ™¨é–“æ‰“æƒ")].empty: st.warning(f"âš ï¸ {my_cls} å·²å›å ±ï¼")
            else:
                duty_df, _ = get_daily_duty(today_tw)
                area_name = "ç„¡"
                n_std = 4
                if not duty_df.empty:
                    m_d = duty_df[duty_df["è² è²¬ç­ç´š"]==my_cls]
                    if not m_d.empty:
                        area_name = m_d.iloc[0].get('æƒåœ°å€åŸŸ', 'ç„¡')
                        # åŠ å…¥é˜²éŒ¯æ©Ÿåˆ¶ï¼Œå³ä½¿ N è¢«åˆªæ‰ä¹Ÿèƒ½æŠ“åˆ°å°æ‡‰æ¬„ä½
                        try:
                            n_std = int(m_d.iloc[0].get('æ¨™æº–äººæ•¸', 4))
                        except:
                            n_std = 4
                
                st.info(f"ğŸ“ ä»»å‹™: {area_name} (æ‡‰åˆ°:{n_std}äºº)")
                with st.form("vol_form"):
                    present = st.multiselect("âœ… å¯¦åˆ°åŒå­¸", [s for s, c in ROSTER_DICT.items() if c == my_cls])
                    files = st.file_uploader("ğŸ“¸ æˆæœç…§ç‰‡", accept_multiple_files=True, type=['jpg','png'])
                    if st.form_submit_button("é€å‡º") and present and files:
                        save_entry({"æ—¥æœŸ": str(today_tw), "ç­ç´š": my_cls, "è©•åˆ†é …ç›®": "æ™¨é–“æ‰“æƒ", "æª¢æŸ¥äººå“¡": f"å¿—å·¥(å¯¦åˆ°:{len(present)})", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": 0, "å‚™è¨»": f"åå–®:{','.join(present)}"}, uploaded_files=files, student_list=present, custom_hours=0.5, custom_category="æ™¨æƒå¿—å·¥")
                        st.success("âœ… å›å ±æˆåŠŸï¼"); st.rerun()

    # --- Mode 4: çµ„é•·å¾Œå° ---
    elif app_mode == "çµ„é•·ã„‰çª©ğŸ’ƒ":
        st.title("âš™ï¸ ç®¡ç†å¾Œå°")
        metrics = get_queue_metrics()
        c1, c2, c3 = st.columns(3)
        c1.metric("å¾…è™•ç†", metrics["pending"])
        c2.metric("å¤±æ•—", metrics["failed"])
        c3.metric("å»¶é²(s)", int(metrics["oldest_pending_sec"]))

        if st.text_input("ç®¡ç†å¯†ç¢¼", type="password", key="admin_pwd") == st.secrets["system_config"]["admin_password"]:
            t1, t2, t3, t4, t5, t6, t7 = st.tabs(["ğŸ§¹ æ™¨æƒå¯©æ ¸", "ğŸ“Š æˆç¸¾ç¸½è¡¨", "ğŸ« è¿”æ ¡æ‰“æƒ", "ğŸ“ æ‰£åˆ†æ˜ç´°", "ğŸ“§ å¯„ä¿¡", "ğŸ“£ ç”³è¨´", "âš™ï¸ è¨­å®š"])
            
            with t1:
                df = load_main_data()
                for i, r in df[(df["è©•åˆ†é …ç›®"]=="æ™¨é–“æ‰“æƒ") & (df["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"]==0) & (df["ä¿®æ­£"]!="TRUE")].iterrows():
                    with st.container(border=True):
                        c1, c2, c3 = st.columns([2,2,1])
                        c1.write(f"**{r['ç­ç´š']}** | {r['æª¢æŸ¥äººå“¡']}"); c2.image(str(r['ç…§ç‰‡è·¯å¾‘']).split(";")[0], width=150) if "http" in str(r['ç…§ç‰‡è·¯å¾‘']) else None
                        
                        if c3.button("âœ… é€šé", key=f"p_{r['ç´€éŒ„ID']}"): 
                            ws = get_worksheet(SHEET_TABS["main"])
                            id_list = ws.col_values(EXPECTED_COLUMNS.index("ç´€éŒ„ID")+1)
                            if str(r["ç´€éŒ„ID"]) in id_list:
                                ridx = id_list.index(str(r["ç´€éŒ„ID"])) + 1
                                ws.update_cell(ridx, EXPECTED_COLUMNS.index("æ™¨é–“æ‰“æƒåŸå§‹åˆ†")+1, 2)
                                st.cache_data.clear()
                                st.rerun()
                        if c3.button("ğŸ—‘ï¸ é§å›", key=f"r_{r['ç´€éŒ„ID']}"): delete_rows_by_ids([str(r["ç´€éŒ„ID"])]); st.rerun()

            with t2:
                if st.button("ğŸš€ è¨ˆç®—å…¨å­¸æœŸæˆç¸¾"):
                    full = load_full_semester_data_for_export()
                    full["ç¸½æ‰£åˆ†"] = full["å…§æƒåŸå§‹åˆ†"].clip(upper=2) + full["å¤–æƒåŸå§‹åˆ†"].clip(upper=2) + (full["åƒåœ¾å…§æƒåŸå§‹åˆ†"]+full["åƒåœ¾å¤–æƒåŸå§‹åˆ†"]).where((full["åƒåœ¾å…§æƒåŸå§‹åˆ†"]+full["åƒåœ¾å¤–æƒåŸå§‹åˆ†"])>0, full["åƒåœ¾åŸå§‹åˆ†"]).clip(upper=2) + full["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"] + full["æ‰‹æ©Ÿäººæ•¸"]
                    fin = pd.merge(pd.DataFrame(structured_classes).rename(columns={"grade":"å¹´ç´š","name":"ç­ç´š"}), full.groupby("ç­ç´š")["ç¸½æ‰£åˆ†"].sum().reset_index(), on="ç­ç´š", how="left").fillna(0)
                    fin["ç¸½æˆç¸¾"] = 90 - fin["ç¸½æ‰£åˆ†"]
                    st.dataframe(fin.sort_values("ç¸½æˆç¸¾", ascending=False))

            with t3:
                c1, c2 = st.columns(2)
                rd, rc = c1.date_input("æ—¥æœŸ", today_tw, key="ret_date"), c2.selectbox("ç­ç´š", all_classes, key="ret_cls")
                mems = [s for s, c in ROSTER_DICT.items() if c == rc]
                if mems:
                    with st.form("ret_clean"):
                        absent = st.multiselect("ç¼ºå¸­åå–®", mems)
                        pool = [m for m in mems if m not in absent]
                        base_h = st.number_input("åŸºç¤æ™‚æ•¸", value=2.0, step=0.5)
                        spec = st.multiselect("åŠ å¼·çµ„", pool)
                        spec_h = st.number_input("ç‰¹åˆ¥æ™‚æ•¸", value=3.0, step=0.5)
                        pf = st.file_uploader("ç…§ç‰‡", type=['jpg','png'])
                        if st.form_submit_button("ç™¼æ”¾") and pf:
                            pf.seek(0); fb = pf.read()
                            norm = [m for m in pool if m not in spec]
                            if norm: pf_n = io.BytesIO(fb); pf_n.name="p.jpg"; save_entry({"æ—¥æœŸ": str(rd), "ç­ç´š": rc, "è©•åˆ†é …ç›®": "è¿”æ ¡æ‰“æƒ"}, [pf_n], norm, base_h, "è¿”æ ¡æ‰“æƒ(ä¸€èˆ¬)")
                            if spec: pf_s = io.BytesIO(fb); pf_s.name="p.jpg"; save_entry({"æ—¥æœŸ": str(rd), "ç­ç´š": rc, "è©•åˆ†é …ç›®": "è¿”æ ¡æ‰“æƒ"}, [pf_s], spec, spec_h, "è¿”æ ¡æ‰“æƒ(åŠ å¼·)")
                            st.success("å·²ç™»è¨˜ï¼"); st.rerun()

            with t4: st.dataframe(load_main_data())
            with t6:
                ap_df = load_appeals()
                for i, r in ap_df[ap_df["è™•ç†ç‹€æ…‹"]=="å¾…è™•ç†"].iterrows():
                    with st.container(border=True):
                        c1, c2 = st.columns([3,1])
                        c1.write(f"{r['ç­ç´š']} | {r['ç”³è¨´ç†ç”±']}")
                        if c1.button("æ ¸å¯", key=f"ok_{i}"): update_appeal_status(i, "å·²æ ¸å¯", r["å°æ‡‰ç´€éŒ„ID"]); st.rerun()
                        if c1.button("é§å›", key=f"ng_{i}"): update_appeal_status(i, "å·²é§å›", r["å°æ‡‰ç´€éŒ„ID"]); st.rerun()

            with t7:
                st.info("ç³»çµ±ç¶­è­·å€")
                if st.button("æ¸…é™¤å¿«å–"): st.cache_data.clear(); st.success("Done")

except Exception as e:
    st.error(f"âŒ ç³»çµ±ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    st.code(traceback.format_exc())
