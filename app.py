import streamlit as st
import pandas as pd
import os
import smtplib
import time
import io
import traceback
import threading
import uuid
import re
import sqlite3
import json
import random
import concurrent.futures  # [V5æ–°å¢] å¼•å…¥ä¸¦è¡Œè™•ç†æ¨¡çµ„
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, date, timedelta
import pytz
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload

# --- 1. ç¶²é è¨­å®š ---
st.set_page_config(page_title="ä¸­å£¢å®¶å•†ï¼Œè¡›æ„›è€Œç”Ÿ", layout="wide", page_icon="ğŸ§¹")

# --- 2. æ•æ‰å…¨åŸŸéŒ¯èª¤ ---
try:
    # ==========================================
    # 0. åŸºç¤è¨­å®šèˆ‡æ™‚å€
    # ==========================================
    TW_TZ = pytz.timezone('Asia/Taipei')

    MAX_IMAGE_BYTES = 10 * 1024 * 1024  # å–®æª”åœ–ç‰‡ 10MB ä¸Šé™
    QUEUE_DB_PATH = "task_queue_v4_wal.db"  # ç¶­æŒ V4 æ¶æ§‹è³‡æ–™åº«
    
    # Google Sheet ç¶²å€
    SHEET_URL = "https://docs.google.com/spreadsheets/d/11BXtN3aevJls6Q2IR_IbT80-9XvhBkjbTCgANmsxqkg/edit"
    
    SHEET_TABS = {
        "main": "main_data", 
        "settings": "settings",
        "roster": "roster",
        "inspectors": "inspectors",
        "duty": "duty",
        "teachers": "teachers",
        "appeals": "appeals"
    }

    EXPECTED_COLUMNS = [
        "æ—¥æœŸ", "é€±æ¬¡", "ç­ç´š", "è©•åˆ†é …ç›®", "æª¢æŸ¥äººå“¡",
        "å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸",
        "å‚™è¨»", "é•è¦ç´°é …", "ç…§ç‰‡è·¯å¾‘", "ç™»éŒ„æ™‚é–“", "ä¿®æ­£", "æ™¨æƒæœªåˆ°è€…", "ç´€éŒ„ID"
    ]

    APPEAL_COLUMNS = [
        "ç”³è¨´æ—¥æœŸ", "ç­ç´š", "é•è¦æ—¥æœŸ", "é•è¦é …ç›®", "åŸå§‹æ‰£åˆ†", "ç”³è¨´ç†ç”±", "ä½è­‰ç…§ç‰‡", "è™•ç†ç‹€æ…‹", "ç™»éŒ„æ™‚é–“", "å°æ‡‰ç´€éŒ„ID"
    ]

    # ==========================================
    # SRE Utils: Retry & Backoff Wrapper
    # ==========================================
    def execute_with_retry(func, max_retries=5, base_delay=1.0):
        """
        SRE æ¨™æº–é‡è©¦é‚è¼¯ï¼š
        é‡å° API 429 (Rate Limit) èˆ‡ 5xx (Server Error) é€²è¡ŒæŒ‡æ•¸é€€é¿ã€‚
        """
        for attempt in range(max_retries):
            try:
                # åŸºç¤ç¯€æµï¼šæ¯æ¬¡å¯«å…¥å‰å¼·åˆ¶ä¼‘æ¯ï¼Œé™ä½ Burst QPS
                time.sleep(0.3 + random.uniform(0, 0.2)) 
                return func()
            except Exception as e:
                error_str = str(e).lower()
                # åˆ¤æ–·æ˜¯å¦ç‚ºå¯é‡è©¦çš„éŒ¯èª¤
                is_retryable = any(x in error_str for x in ['429', '500', '503', 'quota', 'rate limit', 'timed out', 'connection'])
                
                if is_retryable and attempt < max_retries - 1:
                    # æŒ‡æ•¸é€€é¿ + Jitter
                    sleep_time = (base_delay * (2 ** attempt)) + random.uniform(0, 1)
                    print(f"âš ï¸ API å¿™ç¢Œ ({e})ï¼Œç¬¬ {attempt+1} æ¬¡é‡è©¦ï¼Œç­‰å¾… {sleep_time:.2f}ç§’...")
                    time.sleep(sleep_time)
                else:
                    raise e

    # ==========================================
    # 1. Google é€£ç·šæ•´åˆ
    # ==========================================

    @st.cache_resource
    def get_credentials():
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        if "gcp_service_account" not in st.secrets:
            st.error("âŒ æ‰¾ä¸åˆ° secrets è¨­å®š")
            return None
        creds_dict = dict(st.secrets["gcp_service_account"])
        return ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)

    @st.cache_resource
    def get_gspread_client():
        try:
            creds = get_credentials()
            if not creds: return None
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"âŒ Google Sheet é€£ç·šå¤±æ•—: {e}")
            return None

    @st.cache_resource
    def get_drive_service():
        try:
            creds = get_credentials()
            if not creds: return None
            return build('drive', 'v3', credentials=creds, cache_discovery=False)
        except Exception as e:
            st.warning(f"âš ï¸ Google Drive é€£ç·šå¤±æ•—: {e}")
            return None

    @st.cache_resource(ttl=21600)
    def get_spreadsheet_object():
        client = get_gspread_client()
        if not client: return None
        try: return client.open_by_url(SHEET_URL)
        except Exception as e: st.error(f"âŒ ç„¡æ³•é–‹å•Ÿè©¦ç®—è¡¨: {e}")
        return None

    def get_worksheet(tab_name):
        max_retries = 3
        wait_time = 2
        sheet = get_spreadsheet_object()
        if not sheet: return None
        for attempt in range(max_retries):
            try:
                try: return sheet.worksheet(tab_name)
                except gspread.WorksheetNotFound:
                    cols = 20 if tab_name != "appeals" else 15
                    ws = sheet.add_worksheet(title=tab_name, rows=100, cols=cols)
                    if tab_name == "appeals": ws.append_row(APPEAL_COLUMNS)
                    return ws
            except Exception as e:
                if "429" in str(e): 
                    time.sleep(wait_time * (attempt + 1))
                    continue
                else: 
                    print(f"âŒ è®€å–åˆ†é  '{tab_name}' å¤±æ•—: {e}")
                    return None
        return None

    def upload_image_to_drive(file_obj, filename):
        def _upload_action():
            service = get_drive_service()
            if not service: raise Exception("Drive Service Init Failed")
            
            folder_id = st.secrets["system_config"].get("drive_folder_id")
            if not folder_id: raise Exception("No Drive Folder ID")

            file_metadata = {'name': filename, 'parents': [folder_id]}
            media = MediaIoBaseUpload(file_obj, mimetype='image/jpeg')
            
            file = service.files().create(
                body=file_metadata, media_body=media, fields='id', supportsAllDrives=True
            ).execute(num_retries=1)
            
            try:
                service.permissions().create(fileId=file.get('id'), body={'role': 'reader', 'type': 'anyone'}).execute()
            except: pass 
            return f"https://drive.google.com/thumbnail?id={file.get('id')}&sz=w1000"

        try:
            return execute_with_retry(_upload_action)
        except Exception as e:
            print(f"âš ï¸ Drive ä¸Šå‚³æœ€çµ‚å¤±æ•—: {str(e)}")
            return None

    def clean_id(val):
        try:
            if pd.isna(val) or val == "": return ""
            return str(int(float(val))).strip()
        except: return str(val).strip()

    # ==========================================
    # åœ–ç‰‡æš«å­˜è³‡æ–™å¤¾
    # ==========================================
    IMG_DIR = "evidence_photos"
    os.makedirs(IMG_DIR, exist_ok=True)

    # ==========================================
    # SQLite èƒŒæ™¯ä½‡åˆ—ç³»çµ± (SRE Hardened + ThreadPool)
    # ==========================================
    _queue_lock = threading.Lock()

    @st.cache_resource
    def get_queue_connection():
        # [SRE] é—œéµï¼šcheck_same_thread=False å…è¨± ThreadPool ä½¿ç”¨æ­¤é€£ç·š
        # é…åˆ _queue_lock ç¢ºä¿å¯«å…¥å®‰å…¨
        conn = sqlite3.connect(
            QUEUE_DB_PATH, 
            check_same_thread=False, 
            timeout=30.0, 
            isolation_level="IMMEDIATE" 
        )
        
        try:
            conn.execute("PRAGMA journal_mode=WAL;")
            conn.execute("PRAGMA busy_timeout=30000;")
            conn.execute("PRAGMA synchronous=NORMAL;")
        except:
            pass

        conn.execute("""
            CREATE TABLE IF NOT EXISTS task_queue (
                id TEXT PRIMARY KEY,
                task_type TEXT NOT NULL,
                created_ts TEXT NOT NULL,
                payload_json TEXT NOT NULL,
                status TEXT NOT NULL,
                attempts INTEGER NOT NULL DEFAULT 0,
                last_error TEXT
            )
        """)
        conn.execute("CREATE INDEX IF NOT EXISTS idx_status_created ON task_queue (status, created_ts);")
        conn.commit()
        return conn

    def enqueue_task(task_type: str, payload: dict) -> str:
        conn = get_queue_connection()
        task_id = str(uuid.uuid4())
        created_ts = datetime.utcnow().isoformat() + "Z"
        payload_json = json.dumps(payload, ensure_ascii=False)

        with _queue_lock:
            conn.execute(
                "INSERT INTO task_queue (id, task_type, created_ts, payload_json, status, attempts, last_error) "
                "VALUES (?, ?, ?, ?, 'PENDING', 0, NULL)",
                (task_id, task_type, created_ts, payload_json)
            )
            conn.commit()
        return task_id

    def get_queue_metrics():
        conn = get_queue_connection()
        metrics = {"pending": 0, "retry": 0, "failed": 0, "oldest_pending_sec": 0, "recent_errors": []}
        with _queue_lock:
            cur = conn.cursor()
            cur.execute("SELECT status, COUNT(*) FROM task_queue GROUP BY status")
            rows = cur.fetchall()
            for status, count in rows:
                if status == 'PENDING': metrics["pending"] = count
                elif status == 'RETRY': metrics["retry"] = count
                elif status == 'FAILED': metrics["failed"] = count
            
            cur.execute("SELECT MIN(created_ts) FROM task_queue WHERE status IN ('PENDING', 'RETRY')")
            oldest_ts_str = cur.fetchone()[0]
            
            cur.execute("SELECT last_error, created_ts FROM task_queue WHERE status='FAILED' OR status='RETRY' ORDER BY created_ts DESC LIMIT 5")
            metrics["recent_errors"] = cur.fetchall()

        if oldest_ts_str:
            try:
                created = datetime.fromisoformat(oldest_ts_str.replace("Z", "+00:00"))
                now = datetime.now(pytz.utc)
                metrics["oldest_pending_sec"] = (now - created).total_seconds()
            except: pass
        return metrics

    def fetch_next_task(max_attempts: int = 6):
        conn = get_queue_connection()
        with _queue_lock:
            try:
                cur = conn.cursor()
                cur.execute(
                    """
                    SELECT id, task_type, created_ts, payload_json, status, attempts, last_error
                    FROM task_queue
                    WHERE status IN ('PENDING', 'RETRY')
                    AND attempts < ?
                    ORDER BY created_ts ASC
                    LIMIT 1
                    """,
                    (max_attempts,)
                )
                row = cur.fetchone()
                
                if not row:
                    conn.commit()
                    return None

                task_id, task_type, created_ts, payload_json, status, attempts, last_error = row
                
                cur.execute(
                    "UPDATE task_queue SET status = 'IN_PROGRESS', attempts = attempts + 1 WHERE id = ? AND status = ?",
                    (task_id, status)
                )
                
                if cur.rowcount == 0:
                    conn.commit()
                    return None

                conn.commit()
                
                try: payload = json.loads(payload_json)
                except: payload = {}
                    
                return {
                    "id": task_id,
                    "task_type": task_type,
                    "created_ts": created_ts,
                    "payload": payload,
                    "status": "IN_PROGRESS",
                    "attempts": attempts + 1,
                    "last_error": last_error,
                }
            except Exception as e:
                try: conn.rollback()
                except: pass
                return None

    def update_task_status(task_id: str, status: str, attempts: int, last_error: str | None):
        conn = get_queue_connection()
        with _queue_lock:
            conn.execute(
                "UPDATE task_queue SET status = ?, attempts = ?, last_error = ? WHERE id = ?",
                (status, attempts, last_error, task_id),
            )
            conn.commit()
    
    # [V5] æ–°å¢ï¼šé‡ç½®å¡ä½çš„ä»»å‹™ (Self-Healing)
    def requeue_stuck_tasks(stale_seconds=600):
        conn = get_queue_connection()
        with _queue_lock:
            # ç°¡å–®å¯¦ä½œï¼šæ‰¾å‡ºæ‰€æœ‰ IN_PROGRESS ä¸”å¤ªä¹…çš„ï¼Œé‡ç½®å› RETRY
            # åš´è¬¹çš„å¯¦ä½œéœ€è¦ updated_tsï¼Œé€™è£¡æˆ‘å€‘å‡è¨­ Streamlit é‡å•Ÿæ˜¯ä¸»è¦åŸå› ï¼Œç›´æ¥é‡ç½®æ‰€æœ‰
            pass 
            # è¨»ï¼šç‚ºäº†ä¿æŒç¨‹å¼ç¢¼ç²¾ç°¡ä¸”å…¼å®¹ V4 tableï¼Œé€™è£¡æš«æ™‚ä¾è³´äººå·¥æˆ–é‡è©¦æ©Ÿåˆ¶
            # è‹¥è¦åš´è¬¹å¯¦ä½œï¼Œéœ€ migration table add column. 
            # V5 ç­–ç•¥ï¼šä¾è³´ fetch_next_task çš„ attempts é™åˆ¶èˆ‡å¤–éƒ¨é‡å•Ÿã€‚

    def _exp_backoff_seconds(attempts: int) -> float:
        base = 2.0
        cap = 60.0
        return random.uniform(1.0, min(cap, base * (2 ** max(0, attempts))))

    # ==========================================
    # å¯«å…¥é‚è¼¯
    # ==========================================
    def _append_main_entry_row(entry: dict):
        def _action():
            ws = get_worksheet(SHEET_TABS["main"])
            if not ws: raise Exception("Failed to get main worksheet")

            all_vals = ws.get_all_values()
            if not all_vals: ws.append_row(EXPECTED_COLUMNS)

            row = []
            for col in EXPECTED_COLUMNS:
                val = entry.get(col, "")
                if isinstance(val, bool): val = str(val).upper()
                if col == "æ—¥æœŸ": val = str(val)
                row.append(val)
            ws.append_row(row)
        execute_with_retry(_action)

    def _append_appeal_row(entry: dict):
        def _action():
            ws = get_worksheet(SHEET_TABS["appeals"])
            if not ws: raise Exception("Failed to get appeals worksheet")

            all_vals = ws.get_all_values()
            if not all_vals: ws.append_row(APPEAL_COLUMNS)

            row = [str(entry.get(col, "")) for col in APPEAL_COLUMNS]
            ws.append_row(row)
        execute_with_retry(_action)

    def process_task(task: dict, max_attempts: int = 6) -> tuple[bool, str | None]:
        task_type = task["task_type"]
        payload = task["payload"]
        entry = payload.get("entry", {}) or {}

        try:
            if task_type == "main_entry":
                image_paths = payload.get("image_paths", []) or []
                filenames = payload.get("filenames", []) or []
                drive_links = []

                for path, fname in zip(image_paths, filenames):
                    if not path or not os.path.exists(path):
                        drive_links.append("UPLOAD_FAILED")
                        continue
                    with open(path, "rb") as f:
                        link = upload_image_to_drive(f, fname)
                    drive_links.append(link if link else "UPLOAD_FAILED")

                if drive_links:
                    entry["ç…§ç‰‡è·¯å¾‘"] = ";".join(drive_links)

                _append_main_entry_row(entry)
                return True, None

            elif task_type == "appeal_entry":
                image_info = payload.get("image_file")
                if image_info and image_info.get("path") and os.path.exists(image_info["path"]):
                    with open(image_info["path"], "rb") as f:
                        link = upload_image_to_drive(f, image_info["filename"])
                    entry["ä½è­‰ç…§ç‰‡"] = link if link else "UPLOAD_FAILED"
                else:
                    entry["ä½è­‰ç…§ç‰‡"] = entry.get("ä½è­‰ç…§ç‰‡", "")

                _append_appeal_row(entry)
                return True, None

            else:
                return True, None

        except Exception as e:
            return False, str(e)

    # [V5] å¤šåŸ·è¡Œç·’ä»»å‹™åŒ…è£å™¨
    def process_task_wrapper(task, max_attempts):
        task_id = task["id"]
        attempts = int(task["attempts"] or 0)
        payload = task["payload"]
        
        ok = False
        err_msg = None
        try:
            ok, err_msg = process_task(task, max_attempts=max_attempts)
        except Exception as e:
            err_msg = f"UNHANDLED: {e}\n{traceback.format_exc()}"
            ok = False

        # æ¸…ç†æš«å­˜
        try:
            image_paths = []
            if isinstance(payload, dict):
                if "image_paths" in payload: image_paths.extend(payload["image_paths"])
                if "image_file" in payload and "path" in payload["image_file"]:
                    image_paths.append(payload["image_file"]["path"])
            for p in image_paths:
                if p and os.path.exists(p): os.remove(p)
        except: pass

        if ok:
            update_task_status(task_id, "DONE", attempts, None)
            print(f"âœ… Task {task_id} å®Œæˆ (Thread)")
        else:
            if attempts >= max_attempts:
                update_task_status(task_id, "FAILED", attempts, err_msg or "unknown")
            else:
                update_task_status(task_id, "RETRY", attempts, err_msg or "unknown")

    # [V5] æ¥µé€Ÿç‰ˆ Background Worker (ThreadPool)
    def background_worker(stop_event: threading.Event | None = None):
        max_attempts = 6
        MAX_WORKERS = 4 # åŒæ™‚è™•ç† 4 å€‹è«‹æ±‚
        print(f"ğŸš€ æ¥µé€Ÿç‰ˆèƒŒæ™¯å·¥ä½œè€…å•Ÿå‹• (Workers: {MAX_WORKERS})...")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = []
            
            while True:
                if stop_event is not None and stop_event.is_set():
                    break

                # 1. æ¸…ç†å·²å®Œæˆçš„ Future
                done_futures = [f for f in futures if f.done()]
                for f in done_futures:
                    futures.remove(f)
                    try: f.result() 
                    except Exception as e: print(f"Thread Error: {e}")

                # 2. èƒŒå£“æ§åˆ¶ï¼šå¦‚æœæ‰€æœ‰ Worker éƒ½åœ¨å¿™ï¼Œå°±æš«åœ fetch
                if len(futures) >= MAX_WORKERS:
                    time.sleep(0.5)
                    continue

                # 3. ç²å–ä»»å‹™
                task = fetch_next_task(max_attempts=max_attempts)
                if not task:
                    time.sleep(1.0)
                    continue

                # 4. ä¸Ÿçµ¦ ThreadPool åŸ·è¡Œ
                print(f"âš¡ ä»»å‹™ {task['id']} å·²åˆ†æ´¾çµ¦åŸ·è¡Œç·’æ± ")
                future = executor.submit(process_task_wrapper, task, max_attempts)
                futures.append(future)

    @st.cache_resource
    def start_background_worker():
        stop_event = threading.Event()
        t = threading.Thread(target=background_worker, args=(stop_event,), daemon=True)
        t.start()
        return stop_event

    _worker_stop_event = start_background_worker()

    # ==========================================
    # 2. è³‡æ–™è®€å¯«é‚è¼¯ (å‰ç«¯)
    # ==========================================

    @st.cache_data(ttl=60)
    def load_main_data():
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws:
            return pd.DataFrame(columns=EXPECTED_COLUMNS)
        try:
            data = ws.get_all_records()
            df = pd.DataFrame(data)
            if df.empty:
                return pd.DataFrame(columns=EXPECTED_COLUMNS)

            for col in EXPECTED_COLUMNS:
                if col not in df.columns:
                    df[col] = ""

            if "ç´€éŒ„ID" not in df.columns:
                df["ç´€éŒ„ID"] = df.index.astype(str)
            else:
                df["ç´€éŒ„ID"] = df["ç´€éŒ„ID"].astype(str)

            if "ç…§ç‰‡è·¯å¾‘" in df.columns:
                df["ç…§ç‰‡è·¯å¾‘"] = df["ç…§ç‰‡è·¯å¾‘"].fillna("").astype(str)

            numeric_cols = ["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸"]
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)

            if "é€±æ¬¡" in df.columns:
                df["é€±æ¬¡"] = pd.to_numeric(df["é€±æ¬¡"], errors="coerce").fillna(0).astype(int)
      
        except Exception as e:
            st.error(f"è®€å–è³‡æ–™éŒ¯èª¤: {e}")
            return pd.DataFrame(columns=EXPECTED_COLUMNS)
        
        return df[EXPECTED_COLUMNS]

    def save_entry(new_entry, uploaded_files=None):
        if "æ—¥æœŸ" in new_entry and new_entry["æ—¥æœŸ"]:
            new_entry["æ—¥æœŸ"] = str(new_entry["æ—¥æœŸ"])

        image_paths = []
        file_names = []

        if uploaded_files:
            for i, up_file in enumerate(uploaded_files):
                if not up_file: continue
                try:
                    up_file.seek(0)
                    data = up_file.read()
                except Exception as e:
                    print(f"âš ï¸ è®€å–ä¸Šå‚³æª”å¤±æ•—: {e}")
                    continue

                if not data: continue

                size = len(data)
                if size > MAX_IMAGE_BYTES:
                    mb = size / (1024 * 1024)
                    st.warning(f"ğŸ“¸ æª”æ¡ˆã€Œ{up_file.name}ã€éå¤§ ({mb:.1f} MB)ï¼Œå·²ç•¥éã€‚")
                    continue

                safe_class = str(new_entry.get('ç­ç´š', 'unknown'))
                logical_fname = f"{new_entry['æ—¥æœŸ']}_{safe_class}_{i}.jpg"
                tmp_fname = f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}_{logical_fname}"
                local_path = os.path.join(IMG_DIR, tmp_fname)

                try:
                    with open(local_path, "wb") as f:
                        f.write(data)
                    image_paths.append(local_path)
                    file_names.append(logical_fname)
                except Exception as e:
                    print(f"âš ï¸ å¯«å…¥æš«å­˜æª”å¤±æ•—: {e}")

        if "ç´€éŒ„ID" not in new_entry or not new_entry["ç´€éŒ„ID"]:
            unique_suffix = uuid.uuid4().hex[:6]
            timestamp = datetime.now(TW_TZ).strftime("%Y%m%d%H%M%S")
            new_entry["ç´€éŒ„ID"] = f"{timestamp}_{unique_suffix}"

        payload = {
            "entry": new_entry,
            "image_paths": image_paths,
            "filenames": file_names,
        }
        
        try:
            task_id = enqueue_task("main_entry", payload)
            return True
        except Exception as e:
            st.error(f"âŒ å¯«å…¥ä½‡åˆ—å¤±æ•—: {e}")
            return False

    def save_appeal(entry, proof_file=None):
        image_info = None

        if proof_file:
            try:
                proof_file.seek(0)
                data = proof_file.read()
            except Exception as e:
                st.error(f"âŒ è®€å–ä½è­‰ç…§ç‰‡å¤±æ•—: {e}")
                return False

            if not data:
                st.error("âŒ ä½è­‰ç…§ç‰‡ç‚ºç©ºæª”æ¡ˆ")
                return False

            size = len(data)
            if size > MAX_IMAGE_BYTES:
                mb = size / (1024 * 1024)
                st.error(f"âŒ ä½è­‰ç…§ç‰‡éå¤§ ({mb:.1f} MB)ï¼Œè«‹å£“ç¸®åˆ° 10 MB ä»¥ä¸‹å†ä¸Šå‚³ã€‚(ç›®å‰ {mb:.1f} MB)")
                return False

            logical_fname = f"Appeal_{entry.get('ç­ç´š', '')}_{datetime.now(TW_TZ).strftime('%H%M%S')}.jpg"
            tmp_fname = f"{datetime.now(TW_TZ).strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}_{logical_fname}"
            local_path = os.path.join(IMG_DIR, tmp_fname)
            try:
                with open(local_path, "wb") as f:
                    f.write(data)
                image_info = {"path": local_path, "filename": logical_fname}
            except Exception as e:
                st.error(f"âŒ å¯«å…¥ä½è­‰æš«å­˜æª”å¤±æ•—: {e}")
                return False

        if "ç”³è¨´æ—¥æœŸ" not in entry or not entry["ç”³è¨´æ—¥æœŸ"]:
            entry["ç”³è¨´æ—¥æœŸ"] = datetime.now(TW_TZ).strftime("%Y-%m-%d")
        entry["è™•ç†ç‹€æ…‹"] = entry.get("è™•ç†ç‹€æ…‹", "å¾…è™•ç†")
        if "ç™»éŒ„æ™‚é–“" not in entry or not entry["ç™»éŒ„æ™‚é–“"]:
            entry["ç™»éŒ„æ™‚é–“"] = datetime.now(TW_TZ).strftime("%Y-%m-%d %H:%M:%S")
        if "ç”³è¨´ID" not in entry or not entry["ç”³è¨´ID"]:
            entry["ç”³è¨´ID"] = datetime.now(TW_TZ).strftime("%Y%m%d%H%M%S") + "_" + uuid.uuid4().hex[:4]
        if "ä½è­‰ç…§ç‰‡" not in entry:
            entry["ä½è­‰ç…§ç‰‡"] = ""

        payload = {
            "entry": entry,
            "image_file": image_info,
        }
        task_id = enqueue_task("appeal_entry", payload)
        st.success("ğŸ“© ç”³è¨´å·²æ’å…¥èƒŒæ™¯è™•ç†")
        return True


    @st.cache_data(ttl=60)
    def load_appeals():
        ws = get_worksheet(SHEET_TABS["appeals"])
        if not ws:
            return pd.DataFrame(columns=APPEAL_COLUMNS)

        try:
            records = ws.get_all_records()
            df = pd.DataFrame(records)
        except Exception:
            return pd.DataFrame(columns=APPEAL_COLUMNS)

        for col in APPEAL_COLUMNS:
            if col not in df.columns:
                if col == "è™•ç†ç‹€æ…‹":
                    df[col] = "å¾…è™•ç†"
                else:
                    df[col] = ""

        df = df[APPEAL_COLUMNS]
        return df

    def delete_rows_by_ids(record_ids_to_delete):
        ws = get_worksheet(SHEET_TABS["main"])
        if not ws: return False
        try:
            records = ws.get_all_records()
            rows_to_delete = []
            for i, record in enumerate(records):
                if str(record.get("ç´€éŒ„ID")) in record_ids_to_delete:
                    rows_to_delete.append(i + 2)
            
            rows_to_delete.sort(reverse=True)
            for row_idx in rows_to_delete:
                ws.delete_rows(row_idx)
                time.sleep(0.8)
        
            st.cache_data.clear()
            return True
        except Exception as e:
            st.error(f"åˆªé™¤å¤±æ•—: {e}")
            return False

    def update_appeal_status(appeal_row_idx, status, record_id):
        ws_appeals = get_worksheet(SHEET_TABS["appeals"])
        ws_main = get_worksheet(SHEET_TABS["main"])
        try:
            appeals_data = ws_appeals.get_all_records()
            target_row = None
            for i, row in enumerate(appeals_data):
                if str(row.get("å°æ‡‰ç´€éŒ„ID")) == str(record_id) and str(row.get("è™•ç†ç‹€æ…‹")) == "å¾…è™•ç†":
                    target_row = i + 2 
                    break
            if target_row:
                col_idx = APPEAL_COLUMNS.index("è™•ç†ç‹€æ…‹") + 1
                ws_appeals.update_cell(target_row, col_idx, status)
                if status == "å·²æ ¸å¯" and record_id:
                    main_data = ws_main.get_all_records()
                    main_target_row = None
                    for j, m_row in enumerate(main_data):
                        if str(m_row.get("ç´€éŒ„ID")) == str(record_id):
                            main_target_row = j + 2
                            break
                    if main_target_row:
                        fix_col_idx = EXPECTED_COLUMNS.index("ä¿®æ­£") + 1
                        ws_main.update_cell(main_target_row, fix_col_idx, "TRUE")
                st.cache_data.clear()
                return True, "æ›´æ–°æˆåŠŸ"
            else: return False, "æ‰¾ä¸åˆ°å°æ‡‰çš„ç”³è¨´åˆ—"
        except Exception as e: return False, str(e)

    @st.cache_data(ttl=21600)
    def load_roster_dict():
        ws = get_worksheet(SHEET_TABS["roster"])
        roster_dict = {}
        if ws:
            try:
                df = pd.DataFrame(ws.get_all_records())
                id_col = next((c for c in df.columns if "å­¸è™Ÿ" in c), None)
                class_col = next((c for c in df.columns if "ç­ç´š" in c), None)
                if id_col and class_col:
                    for _, row in df.iterrows():
                        sid = clean_id(row[id_col])
                        if sid: roster_dict[sid] = str(row[class_col]).strip()
            except: pass
        return roster_dict
        
    @st.cache_data(ttl=3600)
    def load_sorted_classes():
        ws = get_worksheet(SHEET_TABS["roster"])
        if not ws: return [], []
        try:
            df = pd.DataFrame(ws.get_all_records())
            class_col = next((c for c in df.columns if "ç­ç´š" in c), None)
            if not class_col: return [], []
            
            unique_classes = df[class_col].dropna().unique().tolist()
            unique_classes = [str(c).strip() for c in unique_classes if str(c).strip()]
            
            dept_order = {"å•†": 1, "è‹±": 2, "è³‡": 3, "å®¶": 4, "æœ": 5}
            
            def get_sort_key(name):
                grade = 99
                if "ä¸€" in name or "1" in name: grade = 1
                if "äºŒ" in name or "2" in name: grade = 2
                if "ä¸‰" in name or "3" in name: grade = 3
                
                dept_score = 99
                for k, v in dept_order.items():
                    if k in name:
                        dept_score = v
                        break
                return (grade, dept_score, name)
            
            sorted_all = sorted(unique_classes, key=get_sort_key)
            
            structured = []
            for c in sorted_all:
                grade_val = get_sort_key(c)[0]
                g_label = f"{grade_val}å¹´ç´š" if grade_val != 99 else "å…¶ä»–"
                structured.append({"grade": g_label, "name": c})
                
            return sorted_all, structured
        except Exception as e:
            print(f"Sorting Error: {e}")
            return [], []

    @st.cache_data(ttl=21600)
    def load_teacher_emails():
        ws = get_worksheet(SHEET_TABS["teachers"])
        email_dict = {}
        if ws:
            try:
                df = pd.DataFrame(ws.get_all_records())
                class_col = next((c for c in df.columns if "ç­ç´š" in c), None)
                mail_col = next((c for c in df.columns if "Email" in c or "ä¿¡ç®±" in c or "éƒµä»¶" in c), None)
                name_col = next((c for c in df.columns if "å°å¸«" in c or "å§“å" in c), None)
                if class_col and mail_col:
                    for _, row in df.iterrows():
                        cls = str(row[class_col]).strip()
                        mail = str(row[mail_col]).strip()
                        name = str(row[name_col]).strip() if name_col else "è€å¸«"
                        if cls and mail and "@" in mail:
                            email_dict[cls] = {"email": mail, "name": name}
            except: pass
        return email_dict

    @st.cache_data(ttl=21600)
    def load_inspector_list():
        ws = get_worksheet(SHEET_TABS["inspectors"])
        default = [{"label": "æ¸¬è©¦äººå“¡", "allowed_roles": ["å…§æƒæª¢æŸ¥"], "assigned_classes": [], "id_prefix": "æ¸¬"}]
        if not ws: return default
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return default
            inspectors = []
            id_col = next((c for c in df.columns if "å­¸è™Ÿ" in c or "ç·¨è™Ÿ" in c), None)
            role_col = next((c for c in df.columns if "è² è²¬" in c or "é …ç›®" in c), None)
            scope_col = next((c for c in df.columns if "ç­ç´š" in c or "ç¯„åœ" in c), None)
            if id_col:
                for _, row in df.iterrows():
                    s_id = clean_id(row[id_col])
                    s_role = str(row[role_col]).strip() if role_col else ""
                    allowed = []
                    if "çµ„é•·" in s_role: allowed = ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥", "æ™¨é–“æ‰“æƒ"]
                    elif "æ©Ÿå‹•" in s_role: allowed = ["å…§æƒæª¢æŸ¥", "å¤–æƒæª¢æŸ¥", "åƒåœ¾/å›æ”¶æª¢æŸ¥"]
                    else:
                        if "å¤–æƒ" in s_role: allowed.append("å¤–æƒæª¢æŸ¥")
                        if "åƒåœ¾" in s_role: allowed.append("åƒåœ¾/å›æ”¶æª¢æŸ¥")
                        if "æ™¨" in s_role: allowed.append("æ™¨é–“æ‰“æƒ")
                        if "å…§æƒ" in s_role: allowed.append("å…§æƒæª¢æŸ¥")
                    if not allowed: allowed = ["å…§æƒæª¢æŸ¥"]
                
                    s_classes = []
                    if scope_col and str(row[scope_col]):
                        raw = str(row[scope_col])
                        s_classes = [c.strip() for c in raw.replace("ã€", ";").replace(",", ";").split(";") if c.strip()]
                    prefix = s_id[0] if len(s_id) > 0 else "X"
                    inspectors.append({"label": f"å­¸è™Ÿ: {s_id}", "allowed_roles": allowed, "assigned_classes": s_classes, "id_prefix": prefix})
            return inspectors if inspectors else default
        except: return default

    @st.cache_data(ttl=60)
    def get_daily_duty(target_date):
        ws = get_worksheet(SHEET_TABS["duty"])
        if not ws: return [], "error"
        try:
            df = pd.DataFrame(ws.get_all_records())
            if df.empty: return [], "no_data"
            date_col = next((c for c in df.columns if "æ—¥æœŸ" in c), None)
            id_col = next((c for c in df.columns if "å­¸è™Ÿ" in c), None)
            loc_col = next((c for c in df.columns if "åœ°é»" in c), None)
            if date_col and id_col:
                df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.date
                t_date = target_date if isinstance(target_date, date) else target_date.date()
                today_df = df[df[date_col] == t_date]
                res = []
                for _, row in today_df.iterrows():
                    res.append({"å­¸è™Ÿ": clean_id(row[id_col]), "æƒåœ°å€åŸŸ": str(row[loc_col]).strip() if loc_col else "", "å·²å®Œæˆæ‰“æƒ": False})
                return res, "success"
            return [], "missing_cols"
        except: return [], "error"

    @st.cache_data(ttl=21600)
    def load_settings():
        ws = get_worksheet(SHEET_TABS["settings"])
        config = {"semester_start": "2025-08-25"}
        if ws:
            try:
                data = ws.get_all_values()
                for row in data:
                    if len(row)>=2 and row[0] == "semester_start": config["semester_start"] = row[1]
            except: pass
        return config

    def save_setting(key, val):
        ws = get_worksheet(SHEET_TABS["settings"])
        if ws:
            try:
                cell = ws.find(key)
                if cell: ws.update_cell(cell.row, cell.col+1, val)
                else: ws.append_row([key, val])
                st.cache_data.clear()
                return True
            except: return False
        return False

    def send_bulk_emails(email_list):
        sender_email = st.secrets["system_config"]["smtp_email"]
        sender_password = st.secrets["system_config"]["smtp_password"]
        if not sender_email or not sender_password: return 0, "Secrets æœªè¨­å®š Email"

        sent_count = 0
        try:
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(sender_email, sender_password)
            for item in email_list:
                try:
                    msg = MIMEMultipart()
                    msg['From'] = sender_email
                    msg['To'] = item['email']
                    msg['Subject'] = item['subject']
                    msg.attach(MIMEText(item['body'], 'plain'))
                    server.sendmail(sender_email, item['email'], msg.as_string())
                    sent_count += 1
                except Exception as inner_e:
                    print(f"å€‹åˆ¥å¯„é€å¤±æ•—: {inner_e}")
            server.quit()
            return sent_count, "ç™¼é€ä½œæ¥­çµæŸ"
        except Exception as e:
            return sent_count, str(e)

    def check_duplicate_record(df, check_date, inspector, role, target_class=None):
        if df.empty: return False
        try:
            df["æ—¥æœŸStr"] = df["æ—¥æœŸ"].astype(str)
            check_date_str = str(check_date)
            mask = (df["æ—¥æœŸStr"] == check_date_str) & (df["æª¢æŸ¥äººå“¡"] == inspector) & (df["è©•åˆ†é …ç›®"] == role)
            if target_class: mask = mask & (df["ç­ç´š"] == target_class)
            return not df[mask].empty
        except: return False

    # ==========================================
    # 3. ä¸»ç¨‹å¼ä»‹é¢
    # ==========================================
    SYSTEM_CONFIG = load_settings()
    ROSTER_DICT = load_roster_dict()
    INSPECTOR_LIST = load_inspector_list()
    TEACHER_MAILS = load_teacher_emails()
    
    all_classes, structured_classes = load_sorted_classes()
    if not all_classes:
        all_classes = ["æ¸¬è©¦ç­ç´š"]
        structured_classes = [{"grade": "å…¶ä»–", "name": "æ¸¬è©¦ç­ç´š"}]

    grades = sorted(list(set([c["grade"] for c in structured_classes])))

    def get_week_num(d):
        try:
            start = datetime.strptime(SYSTEM_CONFIG["semester_start"], "%Y-%m-%d").date()
            if isinstance(d, datetime): d = d.date()
            return max(0, ((d - start).days // 7) + 1)
        except: return 0

    now_tw = datetime.now(TW_TZ)
    today_tw = now_tw.date()

    st.sidebar.title("ğŸ« åŠŸèƒ½é¸å–®")
    app_mode = st.sidebar.radio("è«‹é¸æ“‡æ¨¡å¼", ["ç³¾å¯Ÿåº•å®¶ğŸ‘€", "ç­ç´šè² è²¬äººğŸ¥¸", "çµ„é•·ã„‰çª©ğŸ’ƒ"])

    with st.sidebar.expander("ğŸ”§ ç³»çµ±é€£ç·šè¨ºæ–·", expanded=False):
        if get_gspread_client(): 
            st.success("âœ… Google Sheets é€£ç·šæ­£å¸¸")
        else: 
            st.error("âŒ Sheets é€£ç·šå¤±æ•—")
            
        if "gcp_service_account" in st.secrets: 
            st.success("âœ… GCP æ†‘è­‰å·²è®€å–")
        else: 
            st.error("âš ï¸ æœªè¨­å®š GCP Service Account")
            
        if "system_config" in st.secrets and "drive_folder_id" in st.secrets["system_config"]:
            st.success("âœ… Drive è³‡æ–™å¤¾ ID å·²è¨­å®š")
        else:
            st.warning("âš ï¸ æœªè¨­å®š Drive è³‡æ–™å¤¾ ID")
                
    # --- æ¨¡å¼1: ç³¾å¯Ÿè©•åˆ† ---
    if app_mode == "ç³¾å¯Ÿåº•å®¶ğŸ‘€":
        st.title("ğŸ“ è¡›ç”Ÿç³¾å¯Ÿè©•åˆ†ç³»çµ±")
        if "team_logged_in" not in st.session_state: st.session_state["team_logged_in"] = False
        
        if not st.session_state["team_logged_in"]:
            with st.expander("ğŸ” èº«ä»½é©—è­‰", expanded=True):
                input_code = st.text_input("è«‹è¼¸å…¥éšŠä¼é€šè¡Œç¢¼", type="password")
                if st.button("ç™»å…¥"):
                    if input_code == st.secrets["system_config"]["team_password"]:
                        st.session_state["team_logged_in"] = True
                        st.rerun()
                    else: st.error("é€šè¡Œç¢¼éŒ¯èª¤")
        
        if st.session_state["team_logged_in"]:
            prefixes = sorted(list(set([p["id_prefix"] for p in INSPECTOR_LIST])))
            prefix_labels = [f"{p}é–‹é ­" for p in prefixes]
            if not prefix_labels: st.warning("æ‰¾ä¸åˆ°ç³¾å¯Ÿåå–®ï¼Œè«‹é€šçŸ¥è€å¸«åœ¨å¾Œå°å»ºç«‹åå–® (Sheet: inspectors)ã€‚")
            else:
                selected_prefix_label = st.radio("æ­¥é©Ÿ 1ï¼šé¸æ“‡é–‹é ­", prefix_labels, horizontal=True)
                selected_prefix = selected_prefix_label[0]
                filtered_inspectors = [p for p in INSPECTOR_LIST if p["id_prefix"] == selected_prefix]
                inspector_name = st.radio("æ­¥é©Ÿ 2ï¼šé»é¸èº«ä»½", [p["label"] for p in filtered_inspectors])
                current_inspector_data = next((p for p in INSPECTOR_LIST if p["label"] == inspector_name), None)
                allowed_roles = current_inspector_data.get("allowed_roles", ["å…§æƒæª¢æŸ¥"])
                
                allowed_roles = [r for r in allowed_roles if r != "æ™¨é–“æ‰“æƒ"]
                if not allowed_roles: allowed_roles = ["å…§æƒæª¢æŸ¥"] 
                assigned_classes = current_inspector_data.get("assigned_classes", [])
                
                st.markdown("---")
                col_date, col_role = st.columns(2)
                input_date = col_date.date_input("æª¢æŸ¥æ—¥æœŸ", today_tw)
                if len(allowed_roles) > 1: role = col_role.radio("è«‹é¸æ“‡æª¢æŸ¥é …ç›®", allowed_roles, horizontal=True)
                else: role = allowed_roles[0]
                col_role.info(f"ğŸ“‹ æ‚¨çš„è² è²¬é …ç›®ï¼š**{role}**")
                
                week_num = get_week_num(input_date)
                st.caption(f"ğŸ“… ç¬¬ {week_num} é€±")
                main_df = load_main_data()

                if role == "åƒåœ¾/å›æ”¶æª¢æŸ¥":
                    st.info("ğŸ—‘ï¸ å…¨æ ¡åƒåœ¾æª¢æŸ¥ (æ¯æ—¥æ¯ç­ä¸Šé™æ‰£2åˆ†)")
                    trash_cat = st.radio("é•è¦é …ç›®", ["ä¸€èˆ¬åƒåœ¾", "ç´™é¡", "ç¶²è¢‹", "å…¶ä»–å›æ”¶"], horizontal=True)
                    with st.form("trash_form"):
                        t_data = [{"ç­ç´š": c, "ç„¡ç°½å": False, "ç„¡åˆ†é¡": False} for c in all_classes]
                        edited_t_df = st.data_editor(pd.DataFrame(t_data), hide_index=True, height=400, use_container_width=True)
                        if st.form_submit_button("é€å‡º"):
                            base = {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ä¿®æ­£": False}
                            cnt = 0
                            for _, row in edited_t_df.iterrows():
                                vios = []
                                if row["ç„¡ç°½å"]: vios.append("ç„¡ç°½å")
                                if row["ç„¡åˆ†é¡"]: vios.append("ç„¡åˆ†é¡")
                                if vios:
                                    save_entry({**base, "ç­ç´š": row["ç­ç´š"], "è©•åˆ†é …ç›®": role, "åƒåœ¾åŸå§‹åˆ†": len(vios), "å‚™è¨»": f"{trash_cat}-{'ã€'.join(vios)}", "é•è¦ç´°é …": trash_cat})
                                    cnt += 1
                            st.success(f"å·²æ’å…¥èƒŒæ™¯è™•ç†ï¼š {cnt} ç­" if cnt else "ç„¡é•è¦"); st.rerun()
                else:
                    st.markdown("### ğŸ« é¸æ“‡å—æª¢ç­ç´š")
                    if assigned_classes:
                        radio_key = f"radio_assigned_{inspector_name}"
                        selected_class = st.radio(
                            "è«‹é»é¸æ‚¨çš„è² è²¬ç­ç´š", 
                            assigned_classes, 
                            key=radio_key
                        )
                    else:
                        g = st.radio("æ­¥é©Ÿ A: é¸æ“‡å¹´ç´š", grades, horizontal=True, key="radio_grade_select")
                        filtered_classes = [c["name"] for c in structured_classes if c["grade"] == g]
                        
                        if not filtered_classes:
                            st.warning("âš ï¸ æ­¤å¹´ç´šç„¡ç­ç´šè³‡æ–™")
                            selected_class = None
                        else:
                            selected_class = st.radio(
                                "æ­¥é©Ÿ B: é¸æ“‡ç­ç´š", 
                                filtered_classes, 
                                horizontal=True,
                                key=f"radio_class_select_{g}"
                            )
            
                    if selected_class:
                        st.markdown(f"ğŸ‘‰ ç›®å‰é–å®šè©•åˆ†å°è±¡ï¼š **<span style='color:red;font-size:1.2em'>{selected_class}</span>**", unsafe_allow_html=True)
                        if check_duplicate_record(main_df, input_date, inspector_name, role, selected_class):
                                st.warning(f"âš ï¸ æ³¨æ„ï¼šæ‚¨ä»Šå¤©å·²ç¶“è©•éã€Œ{selected_class}ã€äº†ï¼")
                        st.info(f"ğŸ“ æ­£åœ¨è©•åˆ†ï¼š**{selected_class}**")
                        with st.form("scoring_form", clear_on_submit=True):
                            in_s = 0; out_s = 0; ph_c = 0; note = ""
                            if role == "å…§æƒæª¢æŸ¥":
                                if st.radio("çµæœ", ["âŒ é•è¦", "âœ¨ ä¹¾æ·¨"], horizontal=True) == "âŒ é•è¦":
                                    in_s = st.number_input("å…§æƒæ‰£åˆ† (ä¸Šé™2åˆ†)", 0)
                                    note = st.text_input("èªªæ˜", placeholder="é»‘æ¿æœªæ“¦"); ph_c = st.number_input("æ‰‹æ©Ÿäººæ•¸ (ç„¡ä¸Šé™)", 0)
                                else: note = "ã€å„ªè‰¯ã€‘"
                            elif role == "å¤–æƒæª¢æŸ¥":
                                if st.radio("çµæœ", ["âŒ é•è¦", "âœ¨ ä¹¾æ·¨"], horizontal=True) == "âŒ é•è¦":
                                    out_s = st.number_input("å¤–æƒæ‰£åˆ† (ä¸Šé™2åˆ†)", 0)
                                    note = st.text_input("èªªæ˜", placeholder="èµ°å»Šåƒåœ¾"); ph_c = st.number_input("æ‰‹æ©Ÿäººæ•¸ (ç„¡ä¸Šé™)", 0)
                                else: note = "ã€å„ªè‰¯ã€‘"

                            is_fix = st.checkbox("ğŸš© ä¿®æ­£å–®")
                            files = st.file_uploader("ç…§ç‰‡(è‡ªå‹•ä¸Šå‚³é›²ç«¯)", accept_multiple_files=True)
                            if st.form_submit_button("é€å‡º"):
                                save_entry(
                                    {"æ—¥æœŸ": input_date, "é€±æ¬¡": week_num, "æª¢æŸ¥äººå“¡": inspector_name, "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ä¿®æ­£": is_fix, "ç­ç´š": selected_class, "è©•åˆ†é …ç›®": role, "å…§æƒåŸå§‹åˆ†": in_s, "å¤–æƒåŸå§‹åˆ†": out_s, "æ‰‹æ©Ÿäººæ•¸": ph_c, "å‚™è¨»": note},
                                    uploaded_files=files
                                )
                                st.toast(f"âœ… å·²æ’å…¥å„²å­˜ä½‡åˆ—ï¼š{selected_class}")
                                st.rerun()

    # --- æ¨¡å¼2: è¡›ç”Ÿè‚¡é•· ---
    elif app_mode == "ç­ç´šè² è²¬äººğŸ¥¸":
        st.title("ğŸ” ç­ç´šæˆç¸¾æŸ¥è©¢")
        df = load_main_data()
        
        appeals_df = load_appeals()
        appeal_map = {}
        if not appeals_df.empty:
            for _, a_row in appeals_df.iterrows():
                rid = str(a_row.get("å°æ‡‰ç´€éŒ„ID", "")).strip()
                if rid:
                    appeal_map[rid] = a_row.get("è™•ç†ç‹€æ…‹", "å¾…è™•ç†")

        if not df.empty:
            st.write("è«‹ä¾ç…§æ­¥é©Ÿé¸æ“‡ï¼š")
            g = st.radio("æ­¥é©Ÿ 1ï¼šé¸æ“‡å¹´ç´š", grades, horizontal=True)
            class_options = [c["name"] for c in structured_classes if c["grade"] == g]
            
            if not class_options:
                st.warning("æŸ¥ç„¡æ­¤å¹´ç´šç­ç´š")
                cls = None
            else:
                cls = st.radio("æ­¥é©Ÿ 2ï¼šé¸æ“‡ç­ç´š", class_options, horizontal=True)

            st.divider()
            
            if cls:
                c_df = df[df["ç­ç´š"] == cls].sort_values("ç™»éŒ„æ™‚é–“", ascending=False)
                three_days_ago = date.today() - timedelta(days=3)
                
                if not c_df.empty:
                    st.subheader(f"ğŸ“Š {cls} è¿‘æœŸç´€éŒ„èˆ‡ç”³è¨´ç‹€æ…‹")
            
                    for idx, r in c_df.iterrows():
                        total_raw = r['å…§æƒåŸå§‹åˆ†']+r['å¤–æƒåŸå§‹åˆ†']+r['åƒåœ¾åŸå§‹åˆ†']+r['æ™¨é–“æ‰“æƒåŸå§‹åˆ†']
                        phone_msg = f" | ğŸ“±æ‰‹æ©Ÿ: {r['æ‰‹æ©Ÿäººæ•¸']}" if r['æ‰‹æ©Ÿäººæ•¸'] > 0 else ""
                        
                        record_id = str(r['ç´€éŒ„ID']).strip()
                        appeal_status = appeal_map.get(record_id, None)
                
                        status_icon = ""
                        if appeal_status == "å·²æ ¸å¯": status_icon = "âœ… [ç”³è¨´æˆåŠŸ] "
                        elif appeal_status == "å·²é§å›": status_icon = "ğŸš« [ç”³è¨´é§å›] "
                        elif appeal_status == "å¾…è™•ç†": status_icon = "â³ [å¯©æ ¸ä¸­] "
                        elif str(r['ä¿®æ­£']) == "TRUE": status_icon = "ğŸ› ï¸ [å·²ä¿®æ­£] "

                        week_val = r.get('é€±æ¬¡', 0)
                        week_label = f"[ç¬¬{week_val}é€±] " if week_val and str(week_val) != "0" else ""

                        title_text = f"{status_icon}{week_label}{r['æ—¥æœŸ']} - {r['è©•åˆ†é …ç›®']} (æ‰£åˆ†: {total_raw}){phone_msg}"
                        
                        with st.expander(title_text):
                            if appeal_status == "å·²æ ¸å¯":
                                st.success("ğŸ‰ æ­å–œï¼è¡›ç”Ÿçµ„å·²æ ¸å¯æ‚¨çš„ç”³è¨´ï¼Œæœ¬ç­†æ‰£åˆ†å·²æ’¤éŠ·ã€‚")
                            elif appeal_status == "å·²é§å›":
                                st.error("ğŸ›‘ å¾ˆéºæ†¾ï¼Œæ‚¨çš„ç”³è¨´å·²è¢«é§å›ï¼Œç¶­æŒåŸåˆ¤ã€‚")
                            elif appeal_status == "å¾…è™•ç†":
                                st.warning("â³ ç”³è¨´æ¡ˆä»¶ç›®å‰æ­£åœ¨æ’éšŠå¯©æ ¸ä¸­ï¼Œè«‹è€å¿ƒç­‰å€™...")

                            st.write(f"ğŸ“ èªªæ˜: {r['å‚™è¨»']}")
                            st.caption(f"æª¢æŸ¥äººå“¡: {r['æª¢æŸ¥äººå“¡']}")
                            
                            raw_photo_path = str(r.get("ç…§ç‰‡è·¯å¾‘", "")).strip()
                            if raw_photo_path and raw_photo_path.lower() != "nan":
                                path_list = [p.strip() for p in raw_photo_path.split(";") if p.strip()]
                                valid_photos = [p for p in path_list if p != "UPLOAD_FAILED" and (p.startswith("http") or os.path.exists(p))]
                                if valid_photos:
                                    captions = [f"é•è¦ç…§ç‰‡ ({i+1})" for i in range(len(valid_photos))]
                                    st.image(valid_photos, caption=captions, width=300)
                                elif "UPLOAD_FAILED" in path_list: st.warning("âš ï¸ ç…§ç‰‡ä¸Šå‚³å¤±æ•—")

                            if total_raw > 2 and r['æ™¨é–“æ‰“æƒåŸå§‹åˆ†'] == 0:
                                st.info("ğŸ’¡ç³»çµ±æç¤ºï¼šå–®é …æ¯æ—¥æ‰£åˆ†ä¸Šé™ç‚º 2 åˆ† (æ‰‹æ©Ÿã€æ™¨æƒé™¤å¤–)ï¼Œæœ€çµ‚æˆç¸¾å°‡ç”±å¾Œå°è‡ªå‹•è¨ˆç®—ä¸Šé™ã€‚")

                            record_date_obj = pd.to_datetime(r['æ—¥æœŸ']).date() if isinstance(r['æ—¥æœŸ'], str) else r['æ—¥æœŸ']
            
                            if appeal_status:
                                pass 
                            elif record_date_obj >= three_days_ago and (total_raw > 0 or r['æ‰‹æ©Ÿäººæ•¸'] > 0):
                                st.markdown("---")
                                st.markdown("#### ğŸš¨ æˆ‘è¦ç”³è¨´")
                                form_key = f"appeal_form_{r['ç´€éŒ„ID']}_{idx}"
                                with st.form(form_key):
                                    reason = st.text_area("ç”³è¨´ç†ç”±", height=80, placeholder="è©³ç´°èªªæ˜...")
                                    proof_file = st.file_uploader("ä¸Šå‚³ä½è­‰ (å¿…å¡«)", type=["jpg", "png", "jpeg"], key=f"file_{idx}")
                                    if st.form_submit_button("æäº¤ç”³è¨´"):
                                        if not reason or not proof_file: 
                                            st.error("âŒ è«‹å¡«å¯«ç†ç”±ä¸¦ä¸Šå‚³ç…§ç‰‡")
                                        else:
                                            appeal_entry = {
                                                "ç”³è¨´æ—¥æœŸ": str(date.today()), 
                                                "ç­ç´š": cls, 
                                                "é•è¦æ—¥æœŸ": str(r["æ—¥æœŸ"]),
                                                "é•è¦é …ç›®": f"{r['è©•åˆ†é …ç›®']} ({r['å‚™è¨»']})", 
                                                "åŸå§‹æ‰£åˆ†": str(total_raw),
                                                "ç”³è¨´ç†ç”±": reason, 
                                                "è™•ç†ç‹€æ…‹": "å¾…è™•ç†",
                                                "ç™»éŒ„æ™‚é–“": datetime.now(TW_TZ).strftime("%Y-%m-%d %H:%M:%S"),
                                                "å°æ‡‰ç´€éŒ„ID": r['ç´€éŒ„ID']
                                            }
                                            if save_appeal(appeal_entry, proof_file): 
                                                st.success("âœ… ç”³è¨´å·²æäº¤ï¼è«‹é‡æ–°æ•´ç†é é¢æŸ¥çœ‹ç‹€æ…‹ã€‚")
                                                time.sleep(1.5)
                                                st.rerun()
                                            else: 
                                                st.error("æäº¤å¤±æ•—")
                            elif total_raw > 0 and not appeal_status:
                                st.caption("â³ Sorry Broï¼Œå·²è¶…é 3 å¤©ç”³è¨´æœŸé™ã€‚")
                else:
                    st.info("ğŸ‰ æœ€è¿‘æ²’æœ‰é•è¦ç´€éŒ„ï¼Œå°¼å€‘ç­å¾ˆè®šï¼")

    # --- æ¨¡å¼3: å¾Œå° ---
    elif app_mode == "çµ„é•·ã„‰çª©ğŸ’ƒ":
        st.title("âš™ï¸ ç®¡ç†å¾Œå°")
        
        # [SRE] ç›£æ§é¢æ¿
        metrics = get_queue_metrics()
        q_count = metrics["pending"] + metrics["retry"]
        oldest_age = metrics["oldest_pending_sec"]
        recent_errs = metrics["recent_errors"]
        
        with st.container(border=True):
            st.write("#### ğŸ“¡ SRE ç›£æ§é¢æ¿")
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("Pending Queue", q_count, delta="Safe" if q_count < 50 else "High Load", delta_color="inverse")
            m2.metric("Retry Tasks", metrics["retry"])
            m3.metric("Failed Tasks", metrics["failed"])
            m4.metric("Oldest Task Age", f"{int(oldest_age)}s", delta="Lagging" if oldest_age > 300 else "Normal", delta_color="inverse")

            if q_count > 100:
                st.error(f"ğŸ”¥ **ç³»çµ±éè¼‰è­¦å‘Š**ï¼šç©å£“ {q_count} ç­†è³‡æ–™ï¼")
            elif oldest_age > 300:
                st.warning(f"ğŸ¢ **å¯«å…¥å»¶é²è­¦å‘Š**ï¼šæ»¯ç•™ {int(oldest_age)} ç§’ã€‚")
            
            if recent_errs:
                with st.expander("æŸ¥çœ‹æœ€è¿‘éŒ¯èª¤æ—¥èªŒ (Top 5)"):
                    for err_msg, ts in recent_errs:
                        st.error(f"[{ts}] {err_msg}")

        pwd = st.text_input("ç®¡ç†å¯†ç¢¼", type="password")
        if pwd == st.secrets["system_config"]["admin_password"]:
            monitor_tab, tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "ğŸ‘€ é€²åº¦ç›£æ§", "ğŸ“Š æˆç¸¾ç¸½è¡¨", "ğŸ“ æ‰£åˆ†æ˜ç´°", "ğŸ“§ å¯„é€é€šçŸ¥", 
                "ğŸ“£ ç”³è¨´å¯©æ ¸", "âš™ï¸ ç³»çµ±è¨­å®š", "ğŸ“„ åå–®æ›´æ–°", "ğŸ§¹ æ™¨æƒé»å"
            ])
            
            with monitor_tab:
                st.subheader("ğŸ•µï¸ ä»Šæ—¥è©•åˆ†é€²åº¦ç›£æ§")
                
                # 1. è¨­å®šç›£æ§æ—¥æœŸ (é è¨­ä»Šå¤©)
                monitor_date = st.date_input("ç›£æ§æ—¥æœŸ", today_tw, key="monitor_date")
                st.caption(f"ğŸ“… æª¢æŸ¥ç›®æ¨™ï¼š{monitor_date} (å»ºè­°æ–¼ 16:30 å‰å®Œæˆ)")

                # 2. æº–å‚™è³‡æ–™
                df = load_main_data()
                
                # å–å¾—ä»Šæ—¥å·²å›å ±çš„äººå“¡åå–® (å»é‡)
                submitted_names = set()
                if not df.empty:
                    # è½‰æˆå­—ä¸²æ¯”å°ï¼Œç¢ºä¿æ ¼å¼ä¸€è‡´
                    df["æ—¥æœŸStr"] = df["æ—¥æœŸ"].astype(str)
                    target_str = str(monitor_date)
                    today_records = df[df["æ—¥æœŸStr"] == target_str]
                    submitted_names = set(today_records["æª¢æŸ¥äººå“¡"].unique())

                # 3. åˆ†é¡æª¢æŸ¥äººå“¡ (ä¸€èˆ¬è©•åˆ† vs æ©Ÿå‹•/çµ„é•·)
                # é‚è¼¯ï¼šæœ‰åˆ†é… "assigned_classes" çš„æ˜¯ç­ç´šè©•åˆ†å“¡ï¼Œæ²’æœ‰çš„æ˜¯æ©Ÿå‹•
                regular_inspectors = [] # æœ‰å›ºå®šç­ç´š
                mobile_inspectors = []  # æ©Ÿå‹•/çµ„é•· (ç„¡å›ºå®šç­ç´š)

                for p in INSPECTOR_LIST:
                    p_name = p["label"]
                    # åˆ¤æ–·æ˜¯å¦ç‚ºæ©Ÿå‹•ï¼šçœ‹ assigned_classes æ˜¯å¦ç‚ºç©º
                    is_mobile = len(p.get("assigned_classes", [])) == 0
                    
                    # å»ºç«‹ç‹€æ…‹ç‰©ä»¶
                    status_obj = {
                        "name": p_name,
                        "role_desc": "ã€".join(p.get("allowed_roles", [])),
                        "done": p_name in submitted_names
                    }
    
                    if is_mobile:
                        mobile_inspectors.append(status_obj)
                    else:
                        regular_inspectors.append(status_obj)

                # 4. é¡¯ç¤ºå„€è¡¨æ¿
                # --- è¨ˆç®—æ•¸æ“š ---
                total_regular = len(regular_inspectors)
                done_regular = sum(1 for x in regular_inspectors if x["done"])
                
                total_mobile = len(mobile_inspectors)
                done_mobile = sum(1 for x in mobile_inspectors if x["done"])

                # --- é¡¯ç¤ºé€²åº¦æ¢ ---
                c1, c2 = st.columns(2)
                with c1:
                    st.metric("ç­ç´šè©•åˆ†å“¡å®Œæˆç‡", f"{done_regular}/{total_regular}", delta=f"å°šç¼º {total_regular - done_regular} äºº")
                    if total_regular > 0:
                        st.progress(done_regular / total_regular)
                with c2:
                    st.metric("æ©Ÿå‹•/çµ„é•·å®Œæˆç‡", f"{done_mobile}/{total_mobile}", delta=f"å°šç¼º {total_mobile - done_mobile} äºº")
                    if total_mobile > 0:
                        st.progress(done_mobile / total_mobile)

                st.divider()

                # 5. é¡¯ç¤ºæœªå®Œæˆåå–® (å·¦å³ä¸¦åˆ—)
                col_reg, col_mob = st.columns(2)
                
                with col_reg:
                    st.write("#### ğŸ”´ ç­ç´šè©•åˆ†å“¡ (æœªå®Œæˆ)")
                    missing_reg = [x for x in regular_inspectors if not x["done"]]
                    if missing_reg:
                        for p in missing_reg:
                            st.error(f"âŒ {p['name']}")
                    else:
                        st.success("ğŸ‰ å…¨å“¡å®Œæˆï¼")

                    with st.expander("æŸ¥çœ‹å·²å®Œæˆåå–®"):
                        for p in regular_inspectors:
                            if p["done"]: st.write(f"âœ… {p['name']}")

                with col_mob:
                    st.write("#### ğŸŸ  æ©Ÿå‹•/çµ„é•· (æœªå®Œæˆ)")
                    st.caption("æ©Ÿå‹•äººå“¡è‹¥ä»Šæ—¥ç„¡é•è¦éœ€ç™»è¨˜ï¼Œå¯èƒ½ä¹Ÿä¸æœƒé€å‡ºè³‡æ–™ï¼Œè«‹æ–Ÿé…Œåƒè€ƒã€‚")
                    missing_mob = [x for x in mobile_inspectors if not x["done"]]
                    if missing_mob:
                        for p in missing_mob:
                            # æ©Ÿå‹•çµ„é¡¯ç¤ºè² è²¬é …ç›®ï¼Œæ–¹ä¾¿çµ„é•·åˆ¤æ–·ä»–ä»Šå¤©æ˜¯ä¸æ˜¯çœŸçš„æ²’äº‹
                            st.warning(f"âš ï¸ {p['name']} \n   (è² è²¬: {p['role_desc']})")
                    else:
                        st.success("ğŸ‰ å…¨å“¡å®Œæˆï¼")

                    with st.expander("æŸ¥çœ‹å·²å®Œæˆåå–®"):
                        for p in mobile_inspectors:
                            if p["done"]: st.write(f"âœ… {p['name']}")

            with tab1: # æˆç¸¾ç¸½è¡¨
                st.subheader("æˆç¸¾ç¸½è¡¨")
                df = load_main_data()
                all_classes_df = pd.DataFrame(all_classes, columns=["ç­ç´š"])
                if not df.empty:
                    valid_weeks = sorted(df[df["é€±æ¬¡"]>0]["é€±æ¬¡"].unique())
                    selected_weeks = st.multiselect("é¸æ“‡é€±æ¬¡", valid_weeks, default=valid_weeks[-1:] if valid_weeks else [], key='week_select_summary')
                    if selected_weeks:
                        wdf = df[df["é€±æ¬¡"].isin(selected_weeks)].copy()
                        daily_agg = wdf.groupby(["æ—¥æœŸ", "ç­ç´š"]).agg({
                            "å…§æƒåŸå§‹åˆ†": "sum", "å¤–æƒåŸå§‹åˆ†": "sum", "åƒåœ¾åŸå§‹åˆ†": "sum",
                            "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": "sum", "æ‰‹æ©Ÿäººæ•¸": "sum"
                        }).reset_index()
                        daily_agg["å…§æƒçµç®—"] = daily_agg["å…§æƒåŸå§‹åˆ†"].apply(lambda x: min(x, 2))
                        daily_agg["å¤–æƒçµç®—"] = daily_agg["å¤–æƒåŸå§‹åˆ†"].apply(lambda x: min(x, 2))
                        daily_agg["åƒåœ¾çµç®—"] = daily_agg["åƒåœ¾åŸå§‹åˆ†"].apply(lambda x: min(x, 2))
                        daily_agg["æ¯æ—¥ç¸½æ‰£åˆ†"] = (daily_agg["å…§æƒçµç®—"] + daily_agg["å¤–æƒçµç®—"] + 
                                              daily_agg["åƒåœ¾çµç®—"] + daily_agg["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"] + daily_agg["æ‰‹æ©Ÿäººæ•¸"])
                        violation_report = daily_agg.groupby("ç­ç´š").agg({
                            "å…§æƒçµç®—": "sum", "å¤–æƒçµç®—": "sum", "åƒåœ¾çµç®—": "sum",
                            "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": "sum", "æ‰‹æ©Ÿäººæ•¸": "sum", "æ¯æ—¥ç¸½æ‰£åˆ†": "sum"
                        }).reset_index()
                        violation_report.columns = ["ç­ç´š", "å…§æƒæ‰£åˆ†", "å¤–æƒæ‰£åˆ†", "åƒåœ¾æ‰£åˆ†", "æ™¨æƒæ‰£åˆ†", "æ‰‹æ©Ÿæ‰£åˆ†", "ç¸½æ‰£åˆ†"]
                        final_report = pd.merge(all_classes_df, violation_report, on="ç­ç´š", how="left").fillna(0)
                        final_report["ç¸½æˆç¸¾"] = 90 - final_report["ç¸½æ‰£åˆ†"]
                        final_report = final_report.sort_values("ç¸½æˆç¸¾", ascending=False)
                        st.dataframe(final_report, column_config={
                            "ç¸½æˆç¸¾": st.column_config.ProgressColumn("ç¸½æˆç¸¾", format="%d", min_value=60, max_value=90),
                            "ç¸½æ‰£åˆ†": st.column_config.NumberColumn("ç¸½æ‰£åˆ†", format="%d åˆ†")
                        }, use_container_width=True)
                        csv = final_report.to_csv(index=False).encode('utf-8-sig')
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ (CSV)", csv, f"report_weeks_{selected_weeks}.csv")
                    else: st.info("è«‹é¸æ“‡é€±æ¬¡")
                else: st.warning("ç„¡è³‡æ–™")

            with tab2: # è©³ç´°æ˜ç´°
                st.subheader("ğŸ“ é•è¦è©³ç´°æµæ°´å¸³")
                df = load_main_data()
                if not df.empty:
                    valid_weeks = sorted(df[df["é€±æ¬¡"]>0]["é€±æ¬¡"].unique())
                    s_weeks = st.multiselect("é¸æ“‡é€±æ¬¡", valid_weeks, default=valid_weeks[-1:] if valid_weeks else [], key='week_select_detail')
                    if s_weeks:
                        detail_df = df[df["é€±æ¬¡"].isin(s_weeks)].copy()
                        detail_df["è©²ç­†æ‰£åˆ†"] = detail_df["å…§æƒåŸå§‹åˆ†"] + detail_df["å¤–æƒåŸå§‹åˆ†"] + detail_df["åƒåœ¾åŸå§‹åˆ†"] + detail_df["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"] + detail_df["æ‰‹æ©Ÿäººæ•¸"]
                        detail_df = detail_df[detail_df["è©²ç­†æ‰£åˆ†"] > 0]
                        display_cols = ["æ—¥æœŸ", "ç­ç´š", "è©•åˆ†é …ç›®", "è©²ç­†æ‰£åˆ†", "å‚™è¨»", "æª¢æŸ¥äººå“¡", "é•è¦ç´°é …", "ç´€éŒ„ID"]
                        detail_df = detail_df[display_cols].sort_values(["æ—¥æœŸ", "ç­ç´š"])
                        st.dataframe(detail_df, use_container_width=True)
                        csv_detail = detail_df.to_csv(index=False).encode('utf-8-sig')
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ (CSV)", csv_detail, f"detail_log_{s_weeks}.csv")
                    else: st.info("è«‹é¸æ“‡é€±æ¬¡")
                else: st.info("ç„¡è³‡æ–™")

            with tab3: # å¯„é€é€šçŸ¥
                st.subheader("ğŸ“§ æ¯æ—¥é•è¦é€šçŸ¥")
                target_date = st.date_input("é¸æ“‡æ—¥æœŸ", today_tw)
                if "mail_preview" not in st.session_state: st.session_state.mail_preview = None
                if st.button("ğŸ” çµ±æ•´ç•¶æ—¥é•è¦"):
                    df = load_main_data()
                    try:
                        df["æ—¥æœŸObj"] = pd.to_datetime(df["æ—¥æœŸ"], errors='coerce').dt.date
                        day_df = df[df["æ—¥æœŸObj"] == target_date]
                    except: day_df = pd.DataFrame()
                    if not day_df.empty:
                        stats = day_df.groupby("ç­ç´š")[["å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸"]].sum().reset_index()
                        stats["å…§æƒ"] = stats["å…§æƒåŸå§‹åˆ†"].clip(upper=2)
                        stats["å¤–æƒ"] = stats["å¤–æƒåŸå§‹åˆ†"].clip(upper=2)
                        stats["åƒåœ¾"] = stats["åƒåœ¾åŸå§‹åˆ†"].clip(upper=2)
                        stats["ç•¶æ—¥ç¸½æ‰£åˆ†"] = stats["å…§æƒ"] + stats["å¤–æƒ"] + stats["åƒåœ¾"] + stats["æ™¨é–“æ‰“æƒåŸå§‹åˆ†"] + stats["æ‰‹æ©Ÿäººæ•¸"]
                        violation_classes = stats[stats["ç•¶æ—¥ç¸½æ‰£åˆ†"] > 0]
                        if not violation_classes.empty:
                            preview_data = []
                            for _, row in violation_classes.iterrows():
                                cls_name = row["ç­ç´š"]
                                t_info = TEACHER_MAILS.get(cls_name, {})
                                t_name = t_info.get('name', "âŒ ç¼ºåå–®")
                                t_email = t_info.get('email', "âŒ ç„¡æ³•å¯„é€")
                                status = "æº–å‚™å¯„é€" if "@" in t_email else "ç•°å¸¸"
                                preview_data.append({"ç­ç´š": cls_name, "ç•¶æ—¥ç¸½æ‰£åˆ†": row["ç•¶æ—¥ç¸½æ‰£åˆ†"], "å°å¸«å§“å": t_name, "æ”¶ä»¶ä¿¡ç®±": t_email, "ç‹€æ…‹": status})
                            st.session_state.mail_preview = pd.DataFrame(preview_data)
                            st.success(f"æ‰¾åˆ° {len(violation_classes)} ç­†é•è¦ç­ç´š")
                        else: st.session_state.mail_preview = None; st.info("ä»Šæ—¥ç„¡é•è¦")
                    else: st.session_state.mail_preview = None; st.info("ä»Šæ—¥ç„¡è³‡æ–™")

                if st.session_state.mail_preview is not None:
                    st.write("### ğŸ“¨ å¯„é€é è¦½æ¸…å–®"); st.dataframe(st.session_state.mail_preview)
                    if st.button("ğŸš€ ä¸€éµå¯„å‡ºï¼"):
                        mail_queue_list = []
                        for _, row in st.session_state.mail_preview.iterrows():
                            if row["ç‹€æ…‹"] == "æº–å‚™å¯„é€":
                                subject = f"ğŸ””({target_date})è¡›ç”Ÿçµ„è©•åˆ†å ±è¡¨ - {row['ç­ç´š']}"
                                content = f"è€å¸«æ‚¨å¥½ï¼š\n\né€™æ˜¯ä¾†è‡ªè¡›ç”Ÿçµ„ç³»çµ±è‡ªå‹•ç™¼é€ä¹‹æ¯æ—¥å ±è¡¨ã€‚\nä¾æ“šä»Šæ—¥({target_date}) çš„è©•åˆ†è¨˜éŒ„\nè¡›ç”Ÿè©•åˆ†ç¸½æ‰£åˆ†ç‚ºï¼š{row['ç•¶æ—¥ç¸½æ‰£åˆ†']} åˆ†ã€‚\né€™é‚Šè¦æ‹œè¨—è€å¸«é¼“å‹µåŠæé†’è² è²¬å­¸ç”Ÿï¼Œä¸€èµ·ä¾†ç‚ºå­¸æ ¡çš„ç’°å¢ƒåŠªåŠ›ä¸€ä¸‹ğŸª„\nçœŸå¿ƒæ„Ÿæ©è¾›è‹¦çš„å°å¸«\n\nå¦‚æœ‰ç–‘å•å¯è‡³è¡›ç”Ÿçµ„è©•åˆ†ç³»çµ±æŸ¥è©¢æ‰£åˆ†ç´°ç¯€å“¦!\n https://clvshygiene.streamlit.app/ \n\nå­¸å‹™è™•è¡›ç”Ÿçµ„æ•¬ä¸Š"
                                mail_queue_list.append({'email': row["æ”¶ä»¶ä¿¡ç®±"], 'subject': subject, 'body': content})
                        
                        if mail_queue_list:
                            with st.spinner("ğŸ“§ æ­£åœ¨å»ºç«‹ SMTP é€£ç·šä¸¦æ‰¹æ¬¡å¯„é€..."):
                                count, msg = send_bulk_emails(mail_queue_list)
                                if count > 0: st.success(f"âœ… æˆåŠŸå¯„å‡º {count} å°ä¿¡ä»¶ï¼ ({msg})")
                                else: st.error(f"âŒ å¯„é€å¤±æ•—: {msg}")
                            st.session_state.mail_preview = None
                        else: st.warning("æ²’æœ‰å¯å¯„é€çš„å°è±¡")

            with tab4: # ç”³è¨´å¯©æ ¸
                st.subheader("ğŸ“£ ç”³è¨´æ¡ˆä»¶å¯©æ ¸")
                appeals_df = load_appeals()
                pending = appeals_df[appeals_df["è™•ç†ç‹€æ…‹"] == "å¾…è™•ç†"]
                if not pending.empty:
                    st.info(f"å¾…å¯©æ ¸: {len(pending)} ä»¶")
                    for idx, row in pending.iterrows():
                        with st.container(border=True):
                            c1, c2 = st.columns([2, 1])
                            with c1:
                                st.markdown(f"**{row['ç­ç´š']}** | {row['é•è¦é …ç›®']} | æ‰£ {row['åŸå§‹æ‰£åˆ†']} åˆ†")
                                st.markdown(f"ç†ç”±ï¼š{row['ç”³è¨´ç†ç”±']}")
                            with c2:
                                url = row.get("ä½è­‰ç…§ç‰‡", "")
                                if url and url != "UPLOAD_FAILED": st.image(url, width=150)
                            b1, b2 = st.columns(2)
                            if b1.button("âœ… æ ¸å¯", key=f"ok_{idx}"):
                                succ, msg = update_appeal_status(idx, "å·²æ ¸å¯", row["å°æ‡‰ç´€éŒ„ID"])
                                if succ: st.success("å·²æ ¸å¯"); time.sleep(1); st.rerun()
                            
                            if b2.button("ğŸš« é§å›", key=f"ng_{idx}"):
                                succ, msg = update_appeal_status(idx, "å·²é§å›", row["å°æ‡‰ç´€éŒ„ID"])
                                if succ: st.warning("å·²é§å›"); time.sleep(1); st.rerun()
                else: st.success("ç„¡å¾…å¯©æ ¸æ¡ˆä»¶")
                with st.expander("æ­·å²æ¡ˆä»¶"): st.dataframe(appeals_df[appeals_df["è™•ç†ç‹€æ…‹"] != "å¾…è™•ç†"])

            with tab5: # ç³»çµ±è¨­å®š
                st.subheader("âš™ï¸ ç³»çµ±è¨­å®š")
                curr = SYSTEM_CONFIG.get("semester_start", "2025-08-25")
                nd = st.date_input("é–‹å­¸æ—¥", datetime.strptime(curr, "%Y-%m-%d").date())
                if st.button("æ›´æ–°é–‹å­¸æ—¥"): save_setting("semester_start", str(nd)); st.success("å·²æ›´æ–°")
                st.divider()
                st.markdown("### ğŸ—‘ï¸ è³‡æ–™ç¶­è­·")
                df = load_main_data()
                if not df.empty:
                    del_mode = st.radio("åˆªé™¤æ¨¡å¼", ["å–®ç­†åˆªé™¤", "æ—¥æœŸå€é–“åˆªé™¤"])
                    if del_mode == "å–®ç­†åˆªé™¤":
                        df_display = df.sort_values("ç™»éŒ„æ™‚é–“", ascending=False).head(50)
                        opts = {r['ç´€éŒ„ID']: f"{r['æ—¥æœŸ']} | {r['ç­ç´š']} | {r['è©•åˆ†é …ç›®']} (ID:{r['ç´€éŒ„ID']})" for _, r in df_display.iterrows()}
                        sel_ids = st.multiselect("é¸æ“‡è¦åˆªé™¤çš„ç´€éŒ„", list(opts.keys()), format_func=lambda x: opts[x], key='del_multiselect')
                        if st.button("ğŸ—‘ï¸ ç¢ºèªåˆªé™¤"):
                            if delete_rows_by_ids(sel_ids): st.success("åˆªé™¤æˆåŠŸ"); st.rerun()
                    elif del_mode == "æ—¥æœŸå€é–“åˆªé™¤":
                        c1, c2 = st.columns(2)
                        d_start = c1.date_input("é–‹å§‹"); d_end = c2.date_input("çµæŸ")
                        if st.button("âš ï¸ ç¢ºèªåˆªé™¤å€é–“è³‡æ–™"):
                            df["d_tmp"] = pd.to_datetime(df["æ—¥æœŸ"], errors='coerce').dt.date
                            target_ids = df[(df["d_tmp"] >= d_start) & (df["d_tmp"] <= d_end)]["ç´€éŒ„ID"].tolist()
                            if target_ids:
                                if delete_rows_by_ids(target_ids): st.success(f"å·²åˆªé™¤ {len(target_ids)} ç­†"); st.rerun()
                            else: st.warning("ç„¡è³‡æ–™")
                else: st.info("ç„¡è³‡æ–™")

            with tab6:
                st.info("è«‹è‡³ Google Sheets ä¿®æ”¹åå–®")
                if st.button("ğŸ”„ é‡æ–°è®€å–å¿«å–"): st.cache_data.clear(); st.success("OK")
                st.markdown(f"[é–‹å•Ÿè©¦ç®—è¡¨]({SHEET_URL})")

            with tab7: # æ™¨æƒç®¡ç†
                st.subheader("ğŸ§¹ æ™¨æƒè©•åˆ†")
                m_date = st.date_input("æ—¥æœŸ", today_tw, key="m_d")
                m_week = get_week_num(m_date)
                duty_list, status = get_daily_duty(m_date)
                if status == "success":
                    st.write(f"æ‡‰åˆ°: {len(duty_list)} äºº")
                    with st.form("m_form"):
                        edited = st.data_editor(pd.DataFrame(duty_list), hide_index=True, use_container_width=True)
                        score = st.number_input("æ‰£åˆ†", min_value=1, value=1)
                        if st.form_submit_button("é€å‡º"):
                            base = {"æ—¥æœŸ": m_date, "é€±æ¬¡": m_week, "æª¢æŸ¥äººå“¡": "è¡›ç”Ÿçµ„", "ç™»éŒ„æ™‚é–“": now_tw.strftime("%Y-%m-%d %H:%M:%S"), "ä¿®æ­£": False}
                            cnt = 0
                            for _, r in edited[edited["å·²å®Œæˆæ‰“æƒ"] == False].iterrows():
                                tid = clean_id(r["å­¸è™Ÿ"])
                                cls = ROSTER_DICT.get(tid, f"æŸ¥ç„¡({tid})")
                                save_entry({**base, "ç­ç´š": cls, "è©•åˆ†é …ç›®": "æ™¨é–“æ‰“æƒ", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†": score, "å‚™è¨»": f"æœªåˆ°-å­¸è™Ÿ:{tid}", "æ™¨æƒæœªåˆ°è€…": tid})
                                cnt += 1
                            st.success(f"å·²æ’å…¥èƒŒæ™¯ï¼š{cnt} äºº"); st.rerun()
                else: st.warning(f"ç„¡è¼ªå€¼è³‡æ–™ ({status})")

        else: st.error("å¯†ç¢¼éŒ¯èª¤")

except Exception as e:
    st.error("âŒ ç³»çµ±ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ï¼Œè«‹é€šçŸ¥ç®¡ç†å“¡ã€‚")
    print(traceback.format_exc())
